{"chunk_id": "DOC0094__00000", "doc_id": "DOC0094", "chunk_index": 0, "text": "MTH2206: LINEAR ALGEBRA\nEASTER SEMESTER 2025\nD.W. Ddumba & P. Musisi\nDepartment of Computing and Technology\nUganda Christian University", "word_count": 19, "start_char": 0, "end_char": 135}
{"chunk_id": "DOC0094__00001", "doc_id": "DOC0094", "chunk_index": 1, "text": "MTH2206: LINEAR ALGEBRA\nEASTER SEMESTER 2025\nD.W.D\n\ndumba & P.M\n\nusisi\nDepartment of Computing and Technology\nUganda Christian University\n\nContents\nMatrices\n1.1\nDefinitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2\nOther Special Types of Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.1\nDiagonal Matrix\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.2\nTri-Diagonal Matrix\n1.2.3\nTriangular Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.4\nIdempotent Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2.5\nInvertible or Non-Singular Matrix . . . . . . . . . . . . . . . . . . . . . .\n1.3\nOperations on Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.3.1\nAddition and Scalar Multiplication of matrices . . . . . . . . . . . . . . .\n1.3.2\nMultiplication of Matrix by Matrix . . . . . . . . . . . . . . . . . . . . .\n1.3.3\nTrace of a Square Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4\nProperties of Matrices Operations . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.4.1\nProperties of Matrix Addition and Scalar Multiplication\n. . . . . . . . .\n1.4.2\nProperties of Matrix Multiplication . . . . . . . . . . . . . . . . . . . . .\n1.4.3\nProperties of Matrix Transpose\n. . . . . . . . . . . . . . . . . . . . . . .\n1.4.4\nProperties of the Matrix Trace . . . . . . . . . . . . . . . . . . . . . . . .\n1.5\nDeterminants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5.1\nPermutations and Inversion of a Permutation\n. . . . . . . . . . . . . . .\n1.5.2\nMatrix Adjoint, Minors and Cofactors\n. . . . . . . . . . . . . . . . . . .\n1.5.3\nProperties of Determinants . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6\nMatrix Inverses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6.1\nInverse Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6.2\nDirect Method\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6.3\nAdjoint Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.6.4\nMethod of Elementary Row Operation(Gauss-Jordan Elimination Method) 26\n1.6.5\nProperties of Matrix Inverse . . . . . . . . . . . . . . . . . . . . . . . . .\n1.7\nMatrices Chapter Examples\n1.8\nMatrices Chapter Exercises\nSimultaneous Linear Systems\n2.1\nSolving Linear Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2\nA Linear System of Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3\nRow Reduction to Echelon Form . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3.1\nMethodology of Row Reduction for Solutions . . . . . . . . . . . . . . . .\n2.4\nExistence of a Solution to a Linear System . . . . . . . . . . . . . . . . . . . . .\n2.4.1\nUnique Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.4.2\nNo Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.4.3\nInfinitely Many Solutions . . . . . . . . . . . . . . . . . . . . . . . . . .", "word_count": 1041, "start_char": -2, "end_char": 3093}
{"chunk_id": "DOC0094__00002", "doc_id": "DOC0094", "chunk_index": 2, "text": "CONTENTS\n2.5\nComputer Algebra Systems\n2.6\nInput-Output Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.7\nAnalyzing Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.8\nAlgebra in Real World Problems . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.9\nLinear Systems Chapter Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n2.10 Linear Systems Chapter Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . 110\nVector Spaces and Vector Subspaces\n3.1\nVectors in Rn, Cn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n3.2\nVector Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n3.3\nScalar Multiplication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n3.3.1\nProperties of Vector Addition . . . . . . . . . . . . . . . . . . . . . . . . 125\n3.3.2\nProperties of Scalar Multiplication (Product)\n. . . . . . . . . . . . . . . 125\n3.4\nVector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n3.4.1\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n3.4.2\nVector Space\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n3.5\nVector Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\n3.6\nEnd of chapter Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\n3.7\nVector Spaces Chapter Examples\n. . . . . . . . . . . . . . . . . . . . . . . . . . 148\nLinear Dependance and Independence\n4.1\nLinear Combination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n4.2\nSpanning Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\n4.3\nLinear Dependence and Independence . . . . . . . . . . . . . . . . . . . . . . . . 152\n4.4\nLinear Dependence and Independence Chapter Examples . . . . . . . . . . . . . 154\n4.5\nLinear Dependence and Independence Chapter Exercises\n. . . . . . . . . . . . . 175\nEigenvalues and Eigenvectors\n5.1\nEigenvalues & Corresponding Eigenvectors. . . . . . . . . . . . . . . . . . . . . . 194\n5.1.1\nAlgebraic and Geometric Multiplicity of an Eigenvalue\n. . . . . . . . . . 201\n5.2\nSimilar Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\n5.2.1\nProperties of Similar Matrices . . . . . . . . . . . . . . . . . . . . . . . . 205\n5.3\nDiagonisable Matrices\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\n5.4\nEigen Values and Eigen Vectors Chapter Examples\n. . . . . . . . . . . . . . . . 217\n5.4.1\nProofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\n5.5\nEigen Values and Eigen Vectors Chapter Exercises . . . . . . . . . . . . . . . . . 240\nLinear Algebra By Python\nPage of 246", "word_count": 979, "start_char": 3093, "end_char": 5922}
{"chunk_id": "DOC0094__00003", "doc_id": "DOC0094", "chunk_index": 3, "text": "Chapter 1\nMatrices\n1.1\nDefinitions\nDefinition 1.1.1 An m × n matrix is a rectangular array of m × n numbers arranged in m\nhorizontal rows and n vertical columns enclosed in brackets. These numbers in the matrix are\ncalled elements (entries) of the matrix. Matrices are always denoted by capital letters(block\nletters) while matrix entries are denoted by small letters. A matrix A can be generally written\nas\nA =\n\n\n\n\n\n\n\n\n\n\na11\na12\n· · ·\na1n\na21\na22\n· · ·\na2n\n...\n· · ·\n...\n· · ·\n...\n· · ·\nam1\nam2\n. . .\namn\n\n\n\n\n\n\n\n\n\n\nor A =\n\na11\na12\n· · ·\na1n\na21\na22\n· · ·\na2n\n...\n· · ·\n...\n· · ·\n...\n· · ·\nam1\nam2\n. . .\namn\n\nOr more briefly (for notation) we have that A = (aij) or B = (bij) where aij (respectively bij)\nis an entry in the ith row and jth column of A (respectively B).\nDefinition 1.1.2 Square Matrix:\nAn m × n matrix A denoted by Am×n or Amn is said to be square if m = n (that is the number\nof rows is equal to the number of columns).\nDefinition 1.1.3 Equality of Matrices:\nIf two matrices A = (aij) and B = (bij) are both m × n then they are said to be equal if and\nonly if all corresponding entries of A and B are the same that is\naij = bij, ∀1 ≤i ≤m, 1 ≤j ≤n.\nExample 1.1.1\nLet\nA =\n\u0014 a11\na12\na21\na22\n\u0015\nand\nB =\n\u0014 4\n−1\n\u0015\n.\nThen\nA = B if and only if\na11 = 4,\na12 = 0,\na21 = 3,\na22 = −1.\nExample 1.1.2\nThe following matrices are all different. Explain!\n\u0014 1\n\u0015\n\u0014 4\n\u0015\n\u0014 4\n\u0015\n\u0014 1\n\u0015\n\u0014 0\n\u0015", "word_count": 341, "start_char": 5922, "end_char": 7327}
{"chunk_id": "DOC0094__00004", "doc_id": "DOC0094", "chunk_index": 4, "text": "hen\nA = B if and only if\na11 = 4,\na12 = 0,\na21 = 3,\na22 = −1.E\n\nxample 1.1.2\nThe following matrices are all different.E\n\nxplain!\n\u0014 1\n\u0015\n\u0014 4\n\u0015\n\u0014 4\n\u0015\n\u0014 1\n\u0015\n\u0014 0\n\u0015\n\n1.1. DEFINITIONS\nDefinition 1.1.4 Matrix Transpose:\nLet A = (aij) be an m × n matrix, then the transpose of A denoted by At or AT or A′ is an\nn × m matrix obtained from matrix A by interchanging its rows with columns.\nIn the (aij) notation we have that AT = (aij)T where (aij)T = (aji) ∀i, j. We can also write\nAT = (aji).\nNote 1.1.1 The transpose of matrix A is determined by interchanging the rows with columns\nof A that is if A is an n × m matrix then the transpose of A, denoted by AT, is an m × n\nmatrix that is obtained by interchanging the rows and columns of A. So, the first row of AT is\nthe first column of A, the second row of AT is the second column of A, etc. Likewise, the first\ncolumn of AT is the first row of A, the second column of AT is the second row of A, etc.\nExample 1.1.3\nThe transpose of a general 3 × 3 matrix\nA =\n\n\na11\na12\na13\na21\na22\na23\na31\na32\na33\n\nis AT =\n\n\na11\na21\na31\na12\na22\na32\na13\na23\na33\n\n\nExample 1.1.4\nThe transpose of the matrix A given by,\nA =\n\n\n−1\n\nis AT =\n\n\n−1\n\n\nDefinition 1.1.5 Symmetric Matrices:\nA square matrix A is said to be symmetric if its transpose matrix AT is equal to A that is\nAT = A.\nExample 1.1.5\nMatrix A in Example 1.1.4 is not symmetric since A ̸= AT.\nExample 1.1.6\n\n\n\n, then AT =\n\n\n\n. Hence AT = A, implying\nthat A is symmetric.\nExample 1.1.7\n\u0014 −7\n−6\n\u0015\nis symmetric.\nDefinition 1.1.6 Anti-Symmetric Matrices:\nA matrix A is said to be anti-symmetric (sometimes called skew-symmetric) if AT = −A.\nExample 1.1.8\nLet\nB =\n\n\n−2\n−1\n−3\n\nthen BT =\n\n\n−1\n−3\n−2\n\n\nThus BT = −B and B is anti-symmetric (skew symmetric).\nRemark 1.1.1\nSymmetric and Skew Symmetric Matrices\n1.) Given any matrix A, the matrices AAT and ATA are symmetric.\nPage 2 of 246", "word_count": 420, "start_char": 7169, "end_char": 9059}
{"chunk_id": "DOC0094__00005", "doc_id": "DOC0094", "chunk_index": 5, "text": "xample 1.1.8\nLet\nB =\n\n\n−2\n−1\n−3\n\nthen BT =\n\n\n−1\n−3\n−2\n\n\nThus BT = −B and B is anti-symmetric (skew symmetric).R\n\nemark 1.1.1\nSymmetric and Skew Symmetric Matrices\n1.) Given any matrix A, the matrices AAT and ATA are symmetric.P\n\nage 2 of 246\n\n1.1. DEFINITIONS\n2.) Let A be a square matrix. The matrix A + AT is symmetric.\n3.) Let A be a square matrix. The matrix A −AT is skew symmetric.\nDefinition 1.1.7 Identity or Unit matrix:\nAn identity matrix is an (n × n) square matrix whose leading diagonal is composed of 1’s and\nall other off diagonal elements are zeros. An identity matrix is of the form,\nIn =\n\n\n\n\n\n\n\n\n. . .\n. . .\n·\n·\n·\n. . .\n\n\n\n\n\n\n\n\n=\n\n\n\naij = 1,\n∀i = j\naij = 0,\n∀i ̸= j\nusually denoted as In or I with a nice property that I · A = A · I = A where A is an n × n\nmatrix.\nExample 1.1.9\nThe following is a 2 × 2 identity matrix\nI2 =\n\u00141\n\u0015\nExample 1.1.10\nThe following is a 3 × 3 identity matrix\nI3 =\n\n\n\n\nExample 1.1.11\nThe following is a 1 × 1 identity matrix\nI1 = 1\nExample 1.1.12\nThe following is a 4 × 4 identity matrix\nI4 =\n\n\n\n\nExample 1.1.13\nCheck the following matrix is Identity matrix?\nV =\n\n\n\n\nSolution :\nNo, It’s not an identity matrix, because it is of the order 3 × 4, which\nis not a square matrix.\n■\nPage 3 of 246", "word_count": 302, "start_char": 8810, "end_char": 10087}
{"chunk_id": "DOC0094__00006", "doc_id": "DOC0094", "chunk_index": 6, "text": "=\n\n\n\n\nSolution :\nNo, It’s not an identity matrix, because it is of the order 3 × 4, which\nis not a square matrix.\n■\nPage 3 of 246\n\n1.2\nOther Special Types of Matrices\n1.2.1\nDiagonal Matrix\nDefinition 1.2.1\nA square matrix A = (aij) is said to be a diagonal if\naij = 0 ∀i ̸= j.\nThis means that off diagonal elements are all equal to zero.\nDefinition 1.2.2\nA diagonal matrix is an n × n matrix in which the only nonzero entries lie\non the diagonal.\nExample 1.2.1\nThe matrices\n\n\n−1\n\nand\n\n\n\nare diagonal matrices.\n1.2.2\nTri-Diagonal Matrix\nDefinition 1.2.3 A square matrix A = (aij) is said to be a tri-diagonal if aij = 0 for |i−j| ≥2,\nthat is if every element in the ith row and jth column is zero when the absolute difference between\ni and j is greater or equal to two.\nExample 1.2.2\nA general 3 × 3 tri-diagonal matrix is of the form\nA =\n\n\na11\na12\na21\na22\na23\na32\na33\n\n\nExample 1.2.3\n\n\n−1\n\nis a tri-diagonal matrix.\n1.2.3\nTriangular Matrix\nDefinition 1.2.4 A triangular matrix is a square matrix whose non-zero elements lie on the\ndiagonal, and all the zero entries are either above or below the diagonal.\nExample 1.2.4 The matrices A =\n\n\n−1\n\nand B =\n\n\n−1\n\nare triangular matrices.\n1.2.3.1\nUpper Triangular Matrix\nDefinition 1.2.5\nAn upper triangular matrix is a type of triangular matrix A = (aij) where\naij = 0 ∀i > j.\nDefinition 1.2.6 An upper triangular matrix is a matrix in which any non-zero entries lie on\nor above the diagonal.\nPage 4 of 246", "word_count": 299, "start_char": 9954, "end_char": 11432}
{"chunk_id": "DOC0094__00007", "doc_id": "DOC0094", "chunk_index": 7, "text": "efinition 1.2.6 An upper triangular matrix is a matrix in which any non-zero entries lie on\nor above the diagonal.P\n\nage 4 of 246\n\nExample 1.2.5\nA general n × n upper triangular matrix is of the form,\n\na11\na12\n. . .\na1n\na22\n. . .\na2n\n·\n·\n·\n. . .\nann\n\nExample 1.2.6\nMatrix B in Example 1.2.4 on page (p. 4) is an upper triangular matrix.\nExample 1.2.7\nExamples of upper triangular matrices are\nC =\n\n\n−2\n\n,\nD =\n\n\n\n,\nE =\n\n\n\n\nExample 1.2.8\nThe matrix below is an upper triangular matrix\nA =\n\n\n\n\n1.2.3.2\nLower Triangular Matrix\nDefinition 1.2.7\nLet A = (aij) be a square matrix then the matrix A is said to be lower\ntriangular if\naij = 0, ∀i < j.\nDefinition 1.2.8\nA lower triangular matrix is a matrix in which any nonzero entries lie on\nor below the diagonal.\nExample 1.2.9\nThey generally take the form,\n\na11\n. . .\na21\na22\n. . .\n·\n·\n·\nan1\nan2\nan3\n. . .\nann\n\nExample 1.2.10\nSee matrix A in Example 1.2.4 on page (p. 4) is a lower triangular matrix.\nExample 1.2.11\nExamples of lower triangular matrices are\nF =\n\n\n\n,\nG =\n\n\n\n,\nH =\n\n\n\n\nPage 5 of 246", "word_count": 243, "start_char": 11303, "end_char": 12401}
{"chunk_id": "DOC0094__00008", "doc_id": "DOC0094", "chunk_index": 8, "text": "xample 1.2.11\nExamples of lower triangular matrices are\nF =\n\n\n\n,\nG =\n\n\n\n,\nH =\n\n\n\n\nPage 5 of 246\n\nExample 1.2.12\nThe matrix\nA =\n\n\n\n\nis neither upper nor lower Triangular matrix because it is not a square matrix.\n1.2.4\nIdempotent Matrix\nDefinition 1.2.9\nA matrix A = (aij) is said to be idempotent if\nA2 = AA = A\nExample 1.2.13\nA =\n\u0014 3\n−6\n−2\n\u0015\nis an idempotent matrix.\nExample 1.2.14\nExamples of idempotent matrices are idempotent matrices are:\nB =\n\n\n\n,\nC =\n\n\n−2\n−4\n−1\n−2\n−3\n\n,\nD =\n\u0014 1\n\u0015\nExercise 1.2.1\nShow that the matrix\n\n\n−2\n−4\n−1\n−2\n−3\n\nis not an idempotent matrix.\nExercise 1.2.2 Is the matrix A = 1\n\u0014 1 −cos θ\nsin θ\nsin θ\n1 + cos θ\n\u0015\nidempotent? Justify your answer.\n1.2.5\nInvertible or Non-Singular Matrix\nDefinition 1.2.10\nA square matrix A = (aij) is non-singular or invertible if and only if ∃an\nn × n matrix denoted by A−1 such that\nAA−1 = A−1A = I.\nNote 1.2.1\nI is the identity matrix, and A−1 will later be called the inverse of A.\nRemark 1.2.1\nIf A−1 does not exist then we say that A is singular or non invertible.\nPage 6 of 246", "word_count": 238, "start_char": 12286, "end_char": 13364}
{"chunk_id": "DOC0094__00009", "doc_id": "DOC0094", "chunk_index": 9, "text": "ote 1.2.1\nI is the identity matrix, and A−1 will later be called the inverse of A.R\n\nemark 1.2.1\nIf A−1 does not exist then we say that A is singular or non invertible.P\n\nage 6 of 246\n\nExample 1.2.15\nConsider the matrices A, B, C and I4, as well as their transposes, where\nA =\n\n\n\n\nB =\n\n\n−1\n\n\nC =\n\n\n\n.\nIdentify the diagonal of each matrix, and state whether each matrix is diagonal, upper triangular,\nlower triangular, or none of the above.\nWe first compute the transpose of each matrix.\nAT =\n\n\n\n\nBT =\n\n\n−1\n\n\nCT =\n\n\n\n\nNote that IT\n4 = I4.\nThe diagonals of A and AT are the same, consisting of the entries 1, 4 and 6. The diagonals of\nB and BT are also the same, consisting of the entries 3, 7 and −1. Finally, the diagonals of C\nand CT are the same, consisting of the entries 1, 4 and 6.\nThe matrix A is upper triangular; the only nonzero entries lie on or above the diagonal.\nLikewise, AT is lower triangular.\nThe matrix B is diagonal. By their definitions, we can also see that B is both upper and lower\ntriangular. Likewise, I4 is diagonal, as well as upper and lower triangular.\nFinally, C is upper triangular, with CT being lower triangular.\nRemark 1.2.2\nMake note of the definitions of diagonal and triangular matrices. We specify\nthat a diagonal matrix must be square, but triangular matrices don’t have to be. (“Most”\nof the time, however, the ones we study are.) Also, as we mentioned before in the example,\nby definition a diagonal matrix is also both upper and lower triangular. Finally, notice that\nby definition, the transpose of an upper triangular matrix is a lower triangular matrix, and\nvice-versa.\nExample 1.2.16\n\n\n−7\n−8\n−1\n−7\n\n, A is upper triangular and AT is\nlower triangular.\nExample 1.2.17\n\n\n\nis upper and lower triangular, it is diagonal,\nit is both symmetric and skew symmetric. It’s got it all.\nPage 7 of 246", "word_count": 367, "start_char": 13181, "end_char": 15050}
{"chunk_id": "DOC0094__00010", "doc_id": "DOC0094", "chunk_index": 10, "text": "xample 1.2.16\n\n\n−7\n−8\n−1\n−7\n\n, A is upper triangular and AT is\nlower triangular.E\n\nxample 1.2.17\n\n\n\nis upper and lower triangular, it is diagonal,\nit is both symmetric and skew symmetric.I\n\nt’s got it all.P\n\nage 7 of 246\n\n1.3\nOperations on Matrices\n1.3.1\nAddition and Scalar Multiplication of matrices\nDefinition 1.3.1\nLet A and B be matrices of the same size. The sum of A and B, written\nA + B is the matrix whose ij-th entry is aij + bij.\nLet A = (aij),\nB = (bij). Then\nC = A + B\n=\n(cij) = (aij + bij).\n(1.1)\nNote 1.3.1\nNote that cij = bij + aij and so A + B = B + A.\nRemark 1.3.1\nAlso if 0 is the zero matrix, then\n0 + A = A + 0 = A\nfor any matrix A.\nDefinition 1.3.2 Scalar multiplication of a matrix;\nLet A = (aij) be an m × n matrix. Multiplying through matrix A by a scalar α, you get\nαA\n=\nα(aij) = (αaij).\n(1.2)\nThis is equivalent to multiplying each entry of matrix A with the scalar α.\nAlternatively: Let k be a scalar. Then kA is a matrix whose ij-entry is kaij Therefore\nkA = (kaij).\nExample 1.3.1\nFor example, (−1)A = (−aij) and\nA + (−1)A = A −A = 0\nExample 1.3.2\nLet\nA =\n\u0012\n−1\n\u0013\n\u0012 −1\n−2\n−1\n\u0013\n.\nFind\n1.) A + 2B =\n\u0012\n−1\n\u0013\n+\n\u0012 −2\n−4\n−2\n\u0013\n=\n\u0012 −1\n−1\n\u0013\n2.) 3A′ −B′ =\n\n\n−3\n\n−\n\n\n−1\n−2\n−1\n\n=\n\n\n−5\n−2\n\n\n3.)\n(3A −B)′\n=\n\u0014\u0012\n−3\n\u0013\n−\n\u0012 −1\n−2\n−1\n\u0013\u0015′\n=\n\u0012\n−5\n−2\n\u0013′\n=\n\n\n−5\n−2\n\n\nNote that 3A′ −B′ = (3A −B)′.\nRemark 1.3.2\nSubtraction of two matrices A and B is defined using addition and scalar\nmultiplication that is: A −B = A + (−1)B.\nPage 8 of 246", "word_count": 349, "start_char": 14822, "end_char": 16287}
{"chunk_id": "DOC0094__00011", "doc_id": "DOC0094", "chunk_index": 11, "text": "emark 1.3.2\nSubtraction of two matrices A and B is defined using addition and scalar\nmultiplication that is: A −B = A + (−1)B.P\n\nage 8 of 246\n\nTheorem 1.3.1\nLet A and B be matrices of the same size whose entries are in a field F and\ns, t be scalars. Then\n(sA + tB)′ = sA′ + tB′.\nLet\nD\n=\nsA + tB = (saij + tbij)\nThen D′\n=\n(sA + tB)′ = (dji)\nwhere\ndji\n=\nsaji + tbji\nrecall that A′\n=\n(aji) and B′ = (bji)\nThen\nsA′ + tB′\n=\n(saji + tbji) = dji\nThus the ji-entry of D′ is equal to the ji-entry of SA′+tB′ for all i and j. Therefore\nD′ = (SA + tB)′ = SA′ + tB′.\n■\nExercise 1.3.1\nSolve the following matrix equation for a, b, c and d.\n\u0014\na −b\nb + c\n3d + c\n2a −4d\n\u0015\n=\n\u0014 8\n\u0015\na = 5, b = −3,\nc = 4,\nd = 1\nExample 1.3.3\n\u0012 1\n−3\n\u0013\n\u0012\n−5\n\u0013\n. Find A + B + (A + B)′\nNote that A + A′ =\n\u0012\n−1\n−1\n\u0013\nand B + B′ =\n\u0012 14\n−1\n−1\n\u0013\nSo that\nA + B + (A + B)′ = A + A′ + B + B′ =\n\u0012 16\n−2\n−2\n\u0013\nAlternatively use\nA + B\n=\n\u0012\n−3\n\u0013\n⇒\n(A + B) + (A + B′)\n=\n\u0012\n−3\n\u0013\n+\n\u0012 8\n−3\n\u0013\n=\n\u0012 16\n−2\n−2\n\u0013\nNote that, the sums A + A′,\nB + B′ are symmetric matrices.\nTheorem 1.3.2\nLet A be a square matrix. Then A + A′ is symmetric.\nLet A\n=\n(aij).\nThen A′ = (aji)\nNow A + A′\n=\n(aij + aji)\nClearly\naij + aji = bji = aji + aji ∀i, j\nit follows that A + A′ is symmetric.\n■\nPage 9 of 246", "word_count": 333, "start_char": 16146, "end_char": 17369}
{"chunk_id": "DOC0094__00012", "doc_id": "DOC0094", "chunk_index": 12, "text": "heorem 1.3.2\nLet A be a square matrix.T\n\nhen A + A′ is symmetric.L\n\net A\n=\n(aij).T\n\nhen A′ = (aji)\nNow A + A′\n=\n(aij + aji)\nClearly\naij + aji = bji = aji + aji ∀i, j\nit follows that A + A′ is symmetric.\n■\nPage 9 of 246\n\nTheorem 1.3.3 Let A, B and C be matrices and s and t scalars in a field F. Then\n1) A + B = B + A (Addition of matrices obeys the commutativity law)\n2) (A + B) + C = A + (B + C) (Addition of matrices satisfies the Associative law).\nLet A = (aij) and B = (bij), C = (cij). Then by definition\nA + B\n=\n(aij + bij)\n(A + B) + C\n=\n((aij + bij) + cij)\nBy associativity of scalars, (aij + bij) + cij = aij + (bij + cij)\nSo\n(A + B) + C\n=\n(aij + (bij + cij))\n=\n(aij) + (bij + cij)\n=\nA + (B + C)\n■\n3) A + 0 = A (Additive identity)\n4) A + (−A) = 0 (Additive inverse)\n5) (st)A = s(tA) (commutative law)\n6) (s + t)A = sA + tA (distributive law)\n7) t(A + B) = tA + tB (distributive law)\n8) 1 · A = A (1 is a multiplicative identity)\nExercise 1.3.2\nProve Theorem 1.3.3\n1.3.2\nMultiplication of Matrix by Matrix\nDefinition 1.3.3 The product C = AB (in this order) of an m × n matrix A = [ajk] times an\nr × p matrix B = [bjk] is defined if and only if r = n and is then the m × p matrix C = [cjk]\nwith entries\ncjk\n=\nn\nX\nl=1\najlblk = aj1b1k + aj2b2k + aj3b3k + · · · + ajnbnk\nj\n= 1, · · · , m\nk\n= 1, · · · , p.\n(1.3)\nExample 1.3.4 (Please verify)\nLet A\n=\n\u0014 4\n−1\n\u0015\nand\nB =\n\u0014 1\n\u0015\nThen AB\n=\n\u0014 4\n−1\n\u0015 \u0014 1\n\u0015\n=\n\u0014 1\n\u0015\nand BB′\n=\n\u0014 1\n\u0015 \n\n\n=\n\u0014 21\n\u0015\nPage 10 of 246", "word_count": 377, "start_char": 17151, "end_char": 18607}
{"chunk_id": "DOC0094__00013", "doc_id": "DOC0094", "chunk_index": 13, "text": "Example 1.3.5 Matrix Multiplication\nAB =\n\n\n−1\n−6\n−3\n\n\n\n\n−2\n−4\n\n=\n\n\n−2\n−16\n−9\n−37\n−28\n\n\nHere c11 = 3(2)+5(5)+(−1)(9) = 22 and so on. The entry in the box is c23 = 4(3)+0(7)+2(1) =\n14. The product BA is not defined.\nExample 1.3.6\nMultiplication of a Matrix and a Vector\n1.)\n\u0014 4\n\u0015 \u0014 3\n\u0015\n=\n\u0014 4(3) + 2(5)\n1(3) + 8(5)\n\u0015\n=\n\u0014 22\n\u0015\n2.) Whereas\n\u0014 3\n\u0015 \u0014 4\n\u0015\nis undefined.\nExample 1.3.7\nProducts of Row and Column Vectors\n1.)\n\u0002\n\u0003\n\n\n\n= [19]\n2.)\n\n\n\n\u0002\n\u0003\n=\n\n\n\n.\nExample 1.3.8\n\u0014\n\u0015 \u0014 −1\n−1\n\u0015\n=\n\u0014 0\n\u0015\nbut\n\u0014 −1\n−1\n\u0015 \u0014\n\u0015\n=\n\u0014\n−99\n−99\n\u0015\n.\nIt is interesting that this also shows that AB = 0 does not necessarily imply BA = 0 or A = 0\nor B = 0.\nExample 1.3.9\nComputing Products Columnwise\nTo obtain\nAB =\n\u0014\n−5\n\u0015 \u0014\n−1\n\u0015\n=\n\u0014\n−17\n−23\n\u0015\nCalculate the columns\n\u0014\n−5\n\u0015 \u0014\n−1\n\u0015\n=\n\u0014\n−17\n\u0015\n,\n\u0014\n−5\n\u0015 \u0014 0\n\u0015\n=\n\u0014 4\n\u0015\n,\n\u0014\n−5\n\u0015 \u0014 7\n\u0015\n=\n\u0014\n−23\n\u0015\nof AB and then write them as a single matrix, as shown in the first formula on the right.\nPage 11 of 246", "word_count": 249, "start_char": 18607, "end_char": 19536}
{"chunk_id": "DOC0094__00014", "doc_id": "DOC0094", "chunk_index": 14, "text": "age 11 of 246\n\nExample 1.3.10\n\n\n3 + 2i\n−i\n1 + i\n1 −i\n\n, B =\n\u0014 −i\ni\n\u0015\nand C =\n\u0014 −1 −i\n−i\n2i\n−5\n\u0015\n.\nThen\nBC\n=\n\u0014 5 + i\n4i −11\n3i −2\n−5i\n\u0015\nCA\n=\n\u0014 −23 −25i\n−1 −i\n69 −5i\n−5 + 9i\n\u0015\nand (1 + i)AB + (3 −4i)C′\n=\n\n\n25 −7i\n57 + 36i\n−1 −i\n−8 −6i\n6 + 3i\n−15 + 26i\n\n\nTheorem 1.3.4 Let A, B and C be conformable matrices over a field F and k a scalar.\nThen\n1) (AB)C = A(BC) (Associative property)\nLet D = AB and E = BC\nThen by definition,\nD\n=\n(dij)\nwhere dij =\nX\nk\naikbkj\nand E\n=\n(eij)\nwhere eij =\nX\nk′\nbik′ck′j\nThus\nF\n=\n(fij) = DC = (AB)C\nwhere fij\n=\nX\nk\ndikckj =\nX\nk\n\"X\ni′\naii′bi′k\n#\nckj\n=\nX\ni\naii′\nX\nk\nbi′kCkj\n=\nX\ni\naii′ei′j\nTherefore F\n=\n(fij) = AE = A(BC)\n■\n2) A(B + C) = AB + AC (Distributive property)\n3) (B + C)A = BA + CA\n4) k(AB) = (kA)B = A(kB)\nRemark 1.3.3\nFor AB = 0, a zero matrix, does not mean that A = 0 or B = 0 or both.\nExample 1.3.11 Let A =\n\u0014 1\n−1\n\u0015\n\u0014 2\n\u0015\n. Then\nAB\n=\n\u0014 1\n−1\n\u0015 \u0014 2\n\u0015\n=\n\u0014 4\n−1\n\u0015\nand\nBA\n=\n\u0014 2\n\u0015 \u0014 1\n−1\n\u0015\n=\n\u0014 2\n\u0015\nPage 12 of 246", "word_count": 278, "start_char": 19523, "end_char": 20476}
{"chunk_id": "DOC0094__00015", "doc_id": "DOC0094", "chunk_index": 15, "text": "xample 1.3.11 Let A =\n\u0014 1\n−1\n\u0015\n\u0014 2\n\u0015\n.T\n\nhen\nAB\n=\n\u0014 1\n−1\n\u0015 \u0014 2\n\u0015\n=\n\u0014 4\n−1\n\u0015\nand\nBA\n=\n\u0014 2\n\u0015 \u0014 1\n−1\n\u0015\n=\n\u0014 2\n\u0015\nPage 12 of 246\n\nNote 1.3.2\nIn general, Matrix multiplication is not commutative; that is, AB ̸= BA.\nIn\ngeneral, just because AX = BX, we cannot conclude that A = B. The commutativity AB = BA\nis possible only if when the matrices are equal or when the matrices A and B commute.\nExample 1.3.12\nFor conformable matrices A and B, consider\n(A −B)(A + B) = A2 −B2 + AB −BA\nThen\n(A −B)(A + B)\n=\nA2 −B2\n(1.4)\nif and only if A and B commute thus AB = BA. Note that the equality is always true for\nscalars.\nExercise 1.3.3\nLet X =\n\u0014 1\n\u0015\nand Y =\n\n\n−1\n\n⇒\nXY ′ =\n\u0014 25\n\u0015\n.\nFind directly Y ′X and compare it with XY ′ above.\nDefinition 1.3.4\nLet A be a square matrix. The powers of A are defined as\nA0 = I,\nA1 = A,\nA2 = AA,\nA2A, . . .\nLet f(x) be a polynomial. Then\nf(x)\n=\na0 + a1x + a2x2 + . . . + anxn\nand f(A)\n=\na0I + a1A + a2A2 + . . . + anAn\nIf f(A) = 0,\nA is called the root or zero of the polynomial f(x).\nExample 1.3.13\n\u0014 2\n−1\n\u0015\nand f(x) = x2 −x −8. Then A2 =\n\u0014 10\n\u0015\nand\nA3 =\n\u0014 26\n−1\n\u0015\n. So\nf(A)\n=\nA2 −A −8I =\n\u0014 10\n\u0015\n−\n\u0014 2\n−1\n\u0015\n−\n\u0014 8\n\u0015\n=\n\u0014 0\n\u0015\n.\nTherefore A is the zero of f(x).\nExample 1.3.14\n\u0014 2\n−1\n\u0015\n. Find the matrix X such that 2A + 3X = −4A..\nWe can use basic algebra techniques to manipulate this equation\nX = −2A =\n\u0014 −4\n−6\n−12\n\u0015\n.\n1.3.3\nTrace of a Square Matrix\nDefinition 1.3.5 Let A be an n × n square matrix, the trace of A denoted by tr(A) is the\nsum of all diagonal elements of A. That is, trace(A) =\nnP\ni=1\naii\nExample 1.3.15 Let A =\n\u0014 1\n−1\n\u0015\nThen AA′ =\n\u0014 5\n\u0015\n⇒\ntr(AA′) = 31,\nA′A =\n\n\n−1\n−1\n−4\n−4\n\n\n⇒\ntr(A′A) = 31\nPage 13 of 246", "word_count": 427, "start_char": 20354, "end_char": 22003}
{"chunk_id": "DOC0094__00016", "doc_id": "DOC0094", "chunk_index": 16, "text": "hat is, trace(A) =\nnP\ni=1\naii\nExample 1.3.15 Let A =\n\u0014 1\n−1\n\u0015\nThen AA′ =\n\u0014 5\n\u0015\n⇒\ntr(AA′) = 31,\nA′A =\n\n\n−1\n−1\n−4\n−4\n\n\n⇒\ntr(A′A) = 31\nPage 13 of 246\n\n1.4. PROPERTIES OF MATRICES OPERATIONS\nTheorem 1.3.5 Let A and B be conformable matrices. Then tr(AB) = tr(BA).\nLet C\n=\nAB = (Cij) where Cij =\nX\nk\naikbkj\nThen tr(C)\n=\ntr(AB) =\nX\ni\nCii =\nX\ni\nX\nk\naikbki\nSimilarly let D\n=\nBA\nThen tr(D)\n=\nX\ni\nX\nk\nbikaki\n(why?) =\nX\ni\nX\nk\nakibik\n(Why?) = tr(C)\nThus tr(AB)\n=\ntr(BA)\n1.4\nProperties of Matrices Operations\n1.4.1\nProperties of Matrix Addition and Scalar Multiplication\n1. A + B = B + A. i.e Matrix addition is commutative\n2. A + (B + C) = (A + B) + C. i.e Associativity of matrix addition\n3. A + 0 = 0 + A = A. where 0 is a zero matrix, a matrix with zero entries.\n4. A + (−A) = 0 where −A = (−1)A\n1.4.2\nProperties of Matrix Multiplication\n5. A(BC) = (AB)C. Associativity of matrix multiplication.\n6. A(B + C) = AB + AC. Distributivity from the left.\n7. (A + B)C = AC + BC. Distributivity from the right.\n8. α(βA) = αβ(A). where α, β are scalars.\n9. α(A + B) = αA + αB.\n10. A(αB) = α(AB) = (αA)B.\n1.4.3\nProperties of Matrix Transpose\n11. (AT)T = A.\n12. (A + B)T = AT + BT.\n13. (AB)T = BTAT.\n14. (αA)T = αAT.\n1.4.4\nProperties of the Matrix Trace\nLet A and B be n × n matrices. Then:\n15. tr(A ± B) = tr(A) ± tr(B)\n16. tr(kA) = k· tr(A)\n17. tr(AB) = tr(BA)\n18. tr(AT) = tr(A)\nPage 14 of 246", "word_count": 315, "start_char": 21853, "end_char": 23233}
{"chunk_id": "DOC0094__00017", "doc_id": "DOC0094", "chunk_index": 17, "text": "hen:\n15. tr(A ± B) = tr(A) ± tr(B)\n16. tr(kA) = k· tr(A)\n17. tr(AB) = tr(BA)\n18. tr(AT) = tr(A)\nPage 14 of 246\n\n1.5\nDeterminants\nThe determinant of an n × n matrix is the signed volume spanned by its column vectors. To\ncompute the determinant of any square matrix, one can use any of the two methods, namely\n1.) Permutations - Inversion technique/method and the\n2.) Cofactor method.\n1.5.1\nPermutations and Inversion of a Permutation\nDefinition 1.5.1 Permutation\nLet S = {1, 2, . . . , n} be a set containing the first n natural numbers. An ordered arrangement\n< i1i2 . . . in > of elements of set S is called a permutation of S.\nExample 1.5.1\nThe permutations for S = {1, 2, 3} are\n< 123 >,\n< 132 >, < 213 >, < 231 >, < 312 >, and < 321 >\nExercise 1.5.1\nWrite down the permutations for S = {1, 2, 3, 4}\nNote 1.5.1\nA set of n elements has n! permutations.\nNote 1.5.2\nWe denote the set of all permutations of set S by Sn where n is the number of\nelements in the set S, and thus\nS1\n=\n{< 1 >}\nS2\n=\n{< 12 > < 21 >}\nS3\n=\n{< 123 > < 132 > < 213 > < 231 > < 312 > < 321 >}\nDefinition 1.5.2 Inversion of Permutation\nA permutation < i1i2 . . . in > of set S is said to have an inversion if a larger integer it precedes\n(comes before) a smaller integer is. For example < 12 > has no inversion, < 21 > has one\ninversion because a larger number 2 comes before 1, < 321 > has three inversions, < 2, 3, 1 >\nhas two inversions, and < 1, 2, 3 > has no inversions.\nDefinition 1.5.3\nEven and Odd Permutation\nA permutation is even or odd depending on the total number of inversions, either even or\nodd.(Here we do consider zero to be even).\nExample 1.5.2\nThe < 1, 2 > is an even permutation since it has no inversion, where as\n< 1, 3, 2 > is an odd permutation since it has one inversion.\nDefinition 1.5.4 Determinant\nIf A = (aij) is an n × n matrix, the determinant of A denoted as |A| or det(A) is defined by\n|A| =\nX\nσ\n±a1i1a2i2 . . . anin\nwhere the σ denotes all permutations < i1 i2 . . . in > in the set S = {1, 2, . . . , n} (i.e the ij to\nbe substituted in the formula should be [in their order] got from each permutation).\nPage 15 of 246", "word_count": 459, "start_char": 23123, "end_char": 25248}
{"chunk_id": "DOC0094__00018", "doc_id": "DOC0094", "chunk_index": 18, "text": "age 15 of 246\n\nNote 1.5.3\nAlso that the + sign in the summation is taken when permutation is even, or −\nwhen the permutation is odd.\nExample 1.5.3 For n = 2 with A =\n\u0012 a11\na12\na21\na22\n\u0013\nand S2 = {< 1, 2 > < 2, 1 >} the determinant\nof A is\n|A|\n=\nΣ ± a1i1a2i2 = +a11a22 −a12a21\n(1.5)\nExample 1.5.4\nFor n = 3, where A =\n\n\na11\na12\na13\na21\na22\na23\na31\na32\na33\n\nand\nS3 = {< 123 > < 132 > < 213 > < 231 > < 312 >< 321 >},\nthen\n|A|\n=\nΣ ± a1i1a2i2a3i3\n=\n(1.6)\nExample 1.5.5 The determinant of A =\n\u0012 1\n\u0013\nis\n|A| = +a11a22 −a12a21 = (1)(7) −(2)(3) = 1.\nExample 1.5.6\nGiven A =\n\n\n\ncompute |A|.\nSolution\n= |A|\n=\nΣ ± a1i1a2i2a3i3\n=\n⇒|A|\n=\n(1)(0)(4) −(1)(1)(3) −(2)(3)(4) + (2)(1)(3) + (0)(3)(3) −(0)(0)(3) = −21\n1.5.2\nMatrix Adjoint, Minors and Cofactors\nDefinition 1.5.5 If A = (aij) is an n×n then Mij will denote (n−1)×(n−1) matrix obtained\nfrom A by deleting its ith row and jth column.\nIts determinant which we denote by |Mij| is called the minor of the element aij of A.\nDefinition 1.5.6 The Cofactor of aij denoted by Cij is given by\nCij = (−1)i+j|Mij|\nExample 1.5.7 Given A =\n\n\n\n. Find all the cofactors of the matrix A.\nC11\n=\n(−1)1+1\n\n= (1)(4) = 4\nC12\n=\n(−1)1+2\n\n= (−1)(4) = −4\nPage 16 of 246\n\nC13\n=\n(−1)1+3\n\nC21\n=\n(−1)2+1\n\n= (−1)(4) = −4\nC22\n=\n(−1)2+2\n\nC23\n=\n(−1)2+3\n\n= (−1)(−4) = 4\nC31\n=\n(−1)3+1\n\nC32\n=\n(−1)3+2\n\n= (−1)(8) = 8\nC33\n=\n(−1)3+3", "word_count": 298, "start_char": 25235, "end_char": 26582}
{"chunk_id": "DOC0094__00019", "doc_id": "DOC0094", "chunk_index": 19, "text": "ind all the cofactors of the matrix A.C\n\n11\n=\n(−1)1+1\n\n= (1)(4) = 4\nC12\n=\n(−1)1+2\n\n= (−1)(4) = −4\nPage 16 of 246\n\nC13\n=\n(−1)1+3\n\nC21\n=\n(−1)2+1\n\n= (−1)(4) = −4\nC22\n=\n(−1)2+2\n\nC23\n=\n(−1)2+3\n\n= (−1)(−4) = 4\nC31\n=\n(−1)3+1\n\nC32\n=\n(−1)3+2\n\n= (−1)(8) = 8\nC33\n=\n(−1)3+3\n\nThen the cofactor matrix of A is\n\n\nC11\nC12\nC13\nC21\nC22\nC23\nC31\nC32\nC33\n\n=\n\n\n−4\n−4\n−4\n−4\n−4\n−4\n\n\nDefinition 1.5.7 Determinant\nSuppose that A = (aij) is an n × n matrix, and let Cij denote the cofactor of the element aij\nwith i, j = 1, 2, . . . , n then\n(1)\n|A| =\nn\nX\nk=1\nakjCkj\nThat is summing along the jth column.\n(2)\n|A| =\nn\nX\nk=1\naikCik\nThat is summing along the ith row.\nExample 1.5.8\nCompute the determinant of the matrix A =\n\n\n\n.\nBut we know (Example 1.5.7) that the cofactor matrix of A is\n\n\n−4\n−4\n−4\n−4\n−4\n−4\n\nSumming\nalong the\n1st column ⇒|A|\n=\n(1)(4) + (3)(−4) + (2)(−4) = −16\n2nd column ⇒|A|\n=\n(2)(−4) + (2)(−4) + (0)(8) = −16\n3rd column ⇒|A|\n=\n(3)(−4) + (1)(−4) + (2)(−4) = −16\n1st row ⇒|A|\n=\n(1)(4) + (2)(−4) + (3)(−4) = −16\n2nd row ⇒|A|\n=\n(3)(−4) + (2)(−4) + (1)(4) = −16\n3rd row ⇒|A|\n=\n(2)(−4) + (0)(8) + (2)(−4) = −16\nPage 17 of 246", "word_count": 261, "start_char": 26321, "end_char": 27448}
{"chunk_id": "DOC0094__00020", "doc_id": "DOC0094", "chunk_index": 20, "text": "Same value of determinant no matter which row or column you consider. But preferably a row\nor column with more zeros is better.\nDefinition 1.5.8\nAdjoint\nThe transpose of the cofactor matrix of A is the adjoint of the matrix A. It is usually denoted\nby adj(A). For A =\n\na11\na12\n. . .\na1n\na21\na22\n. . .\na2n\n·\n·\n·\nan1\nan2\n. . .\nann\n\n, the Cofactor Matrix is\n\nC11\nC12\n. . .\nC1n\nC21\na22\n. . .\nC2n\n·\n·\n·\nCn1\nCn2\n. . .\nCnn\n\nThus\nAdj(A) =\n\nC11\nC21\n. . .\nCn1\nC12\nC22\n. . .\nCn2\n·\n·\n·\nC1n\nC2n\n·\nCnn\n\nExample 1.5.9\nCompute the adjoint of the matrix A =\n\n\n\n. The cofactor matrix\nof A is\n\n\n−4\n−4\n−4\n−4\n−4\n−4\n\n⇒adj(A) =\n\n\n−4\n−4\n−4\n−4\n−4\n−4\n\n\n1.5.3\nProperties of Determinants\n1) |AT| = |A|.\n2) Interchanging two rows or columns in a matrix gives the negative (determinant) of the\nprevious matrix.\n3) If two rows or columns of a matrix are equal, then its determinant is equal to zero.\n4) If any row or column in a matrix A is zero, then |A| = 0.\n5) If any row or column is a constant multiple of another row or column, then |A| = 0.\n6) A scalar k multiplying through a row or column of a matrix gives the determinant as k|A|.\nLet Cij be the cofactor of aij. Then expanding by the first row, we have\n\nka11\nka12\nka13\na21\na22\na23\na31\na32\na33\n\n=\nka11C11 + ka12C12 + ka13C13\n=\nk [a11C11 + a12C12 + a13C13]\n=\nk\n\na11\na12\na13\na21\na22\na23\na31\na32\na33\n\nProperty (6) also states that a factor common to all elements of a row (or column)\ncan be taken out as a factor of the determinant.\n■\nPage 18 of 246", "word_count": 341, "start_char": 27448, "end_char": 28941}
{"chunk_id": "DOC0094__00021", "doc_id": "DOC0094", "chunk_index": 21, "text": "In general, a scalar α multiplying through all rows or all columns |αA| = αn|A|\n7) The value of the determinant remains unchanged if any row or column is replaced by a linear\ncombination of any two rows or columns.\n8) The determinant of a triangular or diagonal matrix is given by the product of its diagonal\nelements.\n9) |AB| = |A||B|\n10) |A−1| = 1\n|A|;\n|A| ̸= 0 & A−1 is called the inverse of A.\n11) Let B be obtained from A by\n1.) multiplying a row (column) of A by a scalar k; then |B| = k|A|.\nIf Ri ←kRj on A\nThen every term in |A| is multiplied by k is\n|B|\n=\nX\nσ\n(sgn(σ))a1i1a2i2 . . . (kajij) . . . anin\n=\nk\nX\nσ\n(sgn(σ))a1i1a2i2 . . . ajij . . . ani1\n=\nk|A|.\n■\n2.) adding a multiple of a row (column) of A to another; then |B| = |A|\nRj ←Rj + cRk\n|B|\n=\nX\nσ\n(sgn(σ))a1σ(1)a2σ(2) . . . (cakσ(k) + ajσ(j)) . . . anσ(n)\n=\nc\nX\nσ\nsgn(σ)a1σ(1)a2σ(2) . . . am(σk)\njth\n. . . anσ(n)\nbecause jth row + kth row are the same.\n+\nX\nσ\nsgna1σ(1)a2σ(2) . . . anσ(n)\n3.) interchanging two rows (column) of A then |B| = −|A|\nOmitted but results can be demonstrated in case of 3 × 3 and 4 × 4\nmatrix\n■\nExercise 1.5.2\nCompute the determinants of\n1.) A =\n\n\n\n\n2.) B =\n\n\n\n\n3.) C =\n\n\n\n\n|A| = −21, |B| = 21, and |C| = −21. Check and explain why these answers (Property 2).\nPage 19 of 246\n\nExercise 1.5.3 Using the properties of determinants explain why determinants of\n1.)\n\n\n−1\n−2\n\n= 0\n2.)\n\n\n\n\n\n\n−1\n−1\n\n\n\n\n\n\n= −24\n3.)\n\n\n\n= 27\n4.)\n\n\n\n\n\n\n\n= 24\nExample 1.5.10\nUse the method of permutation to compute |A|\nA =\n\n\n−2\n−7\n\n\n|A|\n=\n=\n(−2)(5)(2) −(−2)(−7)(6) + (1)(−7)(1) −(1)(3)(2) + (4)(3)(6) −(4)(5)(1)\n=\n−137 + 72 = −65.\nExample 1.5.11 Compute the determinant using “linear combination of rows or columns”\nproperty.\n\n−3\n−2\n−2\n\nR2\n←\n2R1 + R2\nR3\n←\n−5R1 + R3\n=\n\n−3\n−2\n\nR3\n←\n2 R2 + R3\n=\n=\n\n−3\n−2\n\n= −17 triangular matrix, or factor scalar third row 1\n\n−3\n−2", "word_count": 427, "start_char": 28941, "end_char": 30810}
{"chunk_id": "DOC0094__00022", "doc_id": "DOC0094", "chunk_index": 22, "text": "xample 1.5.11 Compute the determinant using “linear combination of rows or columns”\nproperty.\n\n−3\n−2\n−2\n\nR2\n←\n2R1 + R2\nR3\n←\n−5R1 + R3\n=\n\n−3\n−2\n\nR3\n←\n2 R2 + R3\n=\n=\n\n−3\n−2\n\n= −17 triangular matrix, or factor scalar third row 1\n\n−3\n−2\n\n= −17\nRemark 1.5.1 For Gauss-Jordan row reduction (operation), any scalar multiplication is with\nthe pivot.\nExample 1.5.12 Compute the determinant using using “linear combination of rows or columns”\nproperty.\n\nR1\n←\nR1\nR2\n←\n−1\n2R1 + R2\nR3\n←\nR3\nR4\n←\nR4\n=\n\n−1\n−1\n\nR1\n←\nR1\nR2\n←\nR2\nR3\n←\n4R2 + R3\nR4\n←\n2R2 + R4\n=\n=\n\n−1\n−1\n−1\n\nR1\n←\nR1\nR2\n←\nR2\nR3\n←\nR3\nR4\n←\nR3 + R4\n=\n=\n\n−1\n−1\n−1\n\n= 6\n(why?)\nPage 20 of 246\n\nExample 1.5.13\nWe can combine Gauss-Jordan row-reduction and cofactor expansion to\ncalculate determinants of large matrices.\n\n=\n\n−\n\nNow 2\n\n=\n\n(2 column interchange)\n=\n\u001a\n+ 3\n\n\u001b\n=\n2(3 −6) = −6.\nAlso\n\n=\n\n−5\n−2\n−1\n\nby row reduction\n=\n\n−5\n−2\n−1\n\n=\n−12\nTherefore the required determinant = −6 + 12 = 6.\nExample 1.5.14\nGiven that A =\n\n\n−2\n−3\n\n. Find the adj (A).\nSince cofactors of A are\nC11\n=\n(−1)1+1\n\n−3\n= −11\nC12\n=\n(−1)1+2\n\n−3\n= 29\nC13\n=\n(−1)1+3\n\n= 1\nC21\n=\n(−1)2+1\n\n−2\n−3\n= −4\nC22\n=\n(−1)2+2\n\n−2\n−3\n= 7\nC23\n=\n(−1)2+3\n\n= −2\nC31\n=\n(−1)3+1\n\n−2\n= 2\nC32\n=\n(−1)3+2\n\n−2\n= −10\nC33\n=\n(−1)3+3\n\n= 1\nPage 21 of 246\n\nThe Matrix of cofactors is\n\n\n−11\n−4\n−2\n−10\n\n\nand thus the adjoint of A is\n\n\n−11\n−4\n−10\n−2\n\n\nThe Matrix adjoint is useful in finding the inverse of a non-singular matrix.\nExample 1.5.15 Given the matrix\nA =\n\n\n\n\nUsing the Permutation-inversion technique, and the cofactor minor technique.\nThe cofactors of A are\nC11 = (−1)2\n\n= 6\nC12 = (−1)3\n\n= 0\nC13 = (−1)4\n\n= −6\nC21 = (−1)3\n\n= −6\nC22 = (−1)4\n\n= 4\nC23 = (−1)5\n\n= 6\nC31 = (−1)4\n\n= −3\nC32 = (−1)5\n\n= −2\nC33 = (−1)6", "word_count": 391, "start_char": 30579, "end_char": 32287}
{"chunk_id": "DOC0094__00023", "doc_id": "DOC0094", "chunk_index": 23, "text": "he cofactors of A are\nC11 = (−1)2\n\n= 6\nC12 = (−1)3\n\n= 0\nC13 = (−1)4\n\n= −6\nC21 = (−1)3\n\n= −6\nC22 = (−1)4\n\n= 4\nC23 = (−1)5\n\n= 6\nC31 = (−1)4\n\n= −3\nC32 = (−1)5\n\n= −2\nC33 = (−1)6\n\n= 9\nThe Matrix of cofactors is\n\n\n−6\n−6\n−3\n−2\n\n\nThe determinant is given by\n|A| = 4(6) + 3(0) + 2(−6) = 12\nExample 1.5.16 Using properties of determinants, state the determinants of the following\nmatrices\n1.) A =\n\u0014 2\n\u0015\n: |A| Does not exist (DNE) 0r is undefined because the matrix is not\nsquare.\n2.) A =\n\n\n\n: |A| = 24\n3.) A =\n\n\n\n: |A| = 0 because two of the rows of the matrix A are equal.\nPage 22 of 246\n\n1.6\nMatrix Inverses\nDefinition 1.6.1 Inverse of a matrix\nThe matrix B is said to be the inverse of matrix A if\nAB = BA = I\n(1.7)\nI the identity matrix. We denote the inverse of A by A−1.\nNote 1.6.1\nIf matrix A has an inverse we say that A is invertible.\nTheorem 1.6.1\nIf A is invertible, then its inverse is unique.\nAssume A is invertible.\nSuppose, by way of contradiction, that the\ninverse of A is not unique, i.e., let B and C be two distinct inverses of A.\nThen, by definition of inverse, we have\nBA =\nI\n= AB\n(1.8)\nand\nCA =\nI\n= AC\n(1.9)\nIt follows that\nB = BI\nby definition of identity matrix,\nB = B(AC)\nby (1.9) above,\nB = (BA)C\nby associativity of matrix multiplication,\nB = IC\nby (1.8) above, and\nB = C\nby definition of identity matrix. Thus,\nB = C\nwhich contradicts the previous assumption that B ̸= C. So it must be that case that\nthe inverse of A is unique.\n■\nPage 23 of 246", "word_count": 330, "start_char": 32114, "end_char": 33589}
{"chunk_id": "DOC0094__00024", "doc_id": "DOC0094", "chunk_index": 24, "text": "hus,\nB = C\nwhich contradicts the previous assumption that B ̸= C.S\n\no it must be that case that\nthe inverse of A is unique.\n■\nPage 23 of 246\n\n1.6.1\nInverse Methodology\nThe inverse of a matrix could be determined by any of the following techniques\n(1) Direct method\n(2) Adjoint method\n(3) Method of elementary row operations.\n1.6.2\nDirect Method\nExample 1.6.1 Given a matrix A =\n\u0014\n−1\n\u0015\n, and if A−1 = B =\n\u0014 a\nb\nc\nd\n\u0015\n, find the inverse\nB.\nFrom definition of an inverse, equation (1.7)\nAB\n=\nI\n\u0014\n−1\n\u0015 \u0014 a\nb\nc\nd\n\u0015\n=\n\u0014 1\n\u0015\nTo have\na = 1\n3, b = −2\n3, c = 1\n3, d = 1\n3 ⇒\n\u0014 1/3\n−2/3\n1/3\n1/3\n\u0015\nNote 1.6.2 This method beomes increasingly difficult to use as the number of unknowns increase\nwith the increasing order of the matrix which makes it not preferable to other methods.\n1.6.3\nAdjoint Method\nTheorem 1.6.2\nadj(A).A = det(A)I\nwhere I the identity matrix and |A| ̸= 0.\nCorollary 1.6.1 If |A| ̸= 0 then\nA−1\n=\n|A| · adjA\n(1.10)\nFrom Theorem 1.6.2, adj(A).A = det(A)I. Dividing through by |A|,\n|A|\nA = I\nSince |A| ̸= 0 ⇒\nA−1 exists. Multiplying through by A−1 we get\n|A|\nAA−1 = IA−1\n⇒\n|A|\n= IA−1 = A−1 ⇒\nA−1 = adjA\n|A|\nfor |A| ̸= 0\n■\nRemark 1.6.1 From Corollary (1.6.1), equation (1.10), A−1 exists if and only if\n1) A is a square matrix\n2) |A| ̸= 0\nPage 24 of 246\n\nExample 1.6.2\n\n\n−1\n\n.\nThe co-factors are given by\nC11 = (−1)1+1\n\n= −1\nC12 = (−1)1+2\n\n−1\n= −1\nC13 = (−1)1+3\n\n−1\n= 1\nC21 = (−1)2+1\n\n= 1\nC22 = (−1)2+2\n\n−1\n= 1\nC23 = (−1)2+3\n\n−1\n= −5\nC31 = (−1)3+1\n\n= 1\nC32 = (−1)3+2\n\n= −3\nC33 = (−1)3+3", "word_count": 332, "start_char": 33449, "end_char": 34942}
{"chunk_id": "DOC0094__00025", "doc_id": "DOC0094", "chunk_index": 25, "text": "he co-factors are given by\nC11 = (−1)1+1\n\n= −1\nC12 = (−1)1+2\n\n−1\n= −1\nC13 = (−1)1+3\n\n−1\n= 1\nC21 = (−1)2+1\n\n= 1\nC22 = (−1)2+2\n\n−1\n= 1\nC23 = (−1)2+3\n\n−1\n= −5\nC31 = (−1)3+1\n\n= 1\nC32 = (−1)3+2\n\n= −3\nC33 = (−1)3+3\n\n= 3\nThe cofactor matrix is\n\n\n−1\n−1\n−5\n−3\n\n\n⇒\n\n\n−1\n−1\n−3\n−5\n\n\nWith\n|A| = (3)(−1) + (0)(1) + (−1)(1) = −4\nThen\nA−1 = adjA\n|A| = 1\n−4\n\n\n−1\n−1\n−3\n−5\n\n=\n\n\n1/4\n−1/4\n−1/4\n1/4\n−1/4\n3/4\n−1/4\n5/4\n−3/4\n\n\nTheorem 1.6.3\nAn n × n matrix is non singular if and only if |A| ̸= 0.\nSuppose that A is non singular, then A−1 exists such that\nAA−1 = A−1A = I\nBut\n|AA−1| = |A−1||A| = |I| = 1\nThen |A| ̸= 0.\n■\nExample 1.6.3\nFind the inverse of\nA =\n\n\n−2\n−6\n−2\n\n\n\n\n|A| = 96 , A−1 = 1\n\n\n−72\n−24\n\n\n\n\n\nPage 25 of 246", "word_count": 197, "start_char": 34734, "end_char": 35462}
{"chunk_id": "DOC0094__00026", "doc_id": "DOC0094", "chunk_index": 26, "text": "1.6.4\nMethod of Elementary Row Operation(Gauss-Jordan Elimination\nMethod)\nDefinition 1.6.2 An elementary row operation on A = (aij) is anyone of the following :\n1.) Interchanging any two rows of a matrix.\n2.) Multiplying any row of A by a non zero constant.\n3.) Replacing any row by a linear combination of the row itself and any other row of A.\nRemark 1.6.2\nLinear combination of rows involve summing and subtraction of rows. But\nnot their product or quotient.\n1.6.4.1\nProcess of computing the inverse using the elementary row operations.\nKey Idea 1.1\nFor A an n × n matrix\n1). Form the n × 2n matrix. i.e, (A : In).\n2). Apply elementary row operations to (A : In).\n3). Reduce (A : In) to a matrix of the form (In : B), then B will be the inverse matrix A.\nExample 1.6.4\nCompute A−1 using the elementary row operation method, given that\nA =\n\n\n−1\n\n\nThe n × 2n matrix (A : I) is given by\n\n\n−1\n|\n|\n|\n\n\nNow the aim is to shift the identity matrix to side of A.\n1.) Gauss-Jordan Elimination (Coefficients −aij\naii\nmultiplied on only the pivot):\n\n\n−1\n|\n|\n|\n\n\n• We begin with first column (whole) and we need a21 = 0, a31 = 0\n[Operations for first column we apply the pivot in R1 ].\nR1 →R1,\n3R1 + R3 →R3\n\n\n|\n|\n|\n\n\nPage 26 of 246", "word_count": 256, "start_char": 35462, "end_char": 36710}
{"chunk_id": "DOC0094__00027", "doc_id": "DOC0094", "chunk_index": 27, "text": "1 →R1,\n3R1 + R3 →R3\n\n\n|\n|\n|\n\n\nPage 26 of 246\n\n[But when looking for operations for second column, we only apply the pivot inR2 ]\nLet −2R2 + R1 →R1,\n−5\n3R2 + R3 →R3\n\n\n−1\n−4\n|\n−2\n|\n|\n−5\n\n\n[But when looking for operations for third column, only use the pivot in R3 ]\nLet −3\n4R3 + R1 →R1,\n4R3 + R2 →R2,\n\n−4\n|\n−3\n−3\n|\n−1\n|\n−5\n\n• To have\n(I, B)\nby 1\n3R1 →R1, R2 →R2, 3\n4R3 →R3 to have\n\n\n|\n3/12\n−3/12\n−3/12\n|\n1/4\n−1/4\n3/4\n|\n−1/4\n5/4\n−3/4\n\n\n⇒\n\n\n3/12\n−3/12\n−3/12\n1/4\n−1/4\n3/4\n−1/4\n5/4\n−3/4\n\n=\n\n\n1/4\n−1/4\n−1/4\n1/4\n−1/4\n3/4\n−1/4\n5/4\n−3/4\n\n\n2.) Gauss Elimination (Coefficients can be multiplied on any entry):\n\n\n−1\n|\n|\n|\n\n\n•We begin with first column (whole) and we need a21 = 0, a31 = 0\n[Operations for first column we apply the pivot in R1 ].\nR1 →R1,\nR1 + 3R3 →R3\n\n\n|\n|\n|\n\n\n[But when looking for operations for second column, we only apply the pivot inR2 ]\nLet R1 −2R2 →R1,\n5R2 −R3 →R3\n\n\n−1\n|\n−2\n|\n|\n−1\n−3\n\n\nPage 27 of 246", "word_count": 241, "start_char": 36652, "end_char": 37614}
{"chunk_id": "DOC0094__00028", "doc_id": "DOC0094", "chunk_index": 28, "text": "1 →R1,\nR1 + 3R3 →R3\n\n\n|\n|\n|\n\n\n[But when looking for operations for second column, we only apply the pivot inR2 ]\nLet R1 −2R2 →R1,\n5R2 −R3 →R3\n\n\n−1\n|\n−2\n|\n|\n−1\n−3\n\n\nPage 27 of 246\n\n[But when looking for operations for third column, only use the pivot in R3 ]\nLet 4R1 + R3 →R1,\n4R2 −R3 →R2,\n\n\n|\n−3\n−3\n|\n−1\n|\n−1\n−3\n\n\n• To have\n(I, B)\nby\n12R1 →R1, 1\n4R2 →R2, 1\n4R3 →R3 to have\n\n\n|\n3/12\n−3/12\n−3/12\n|\n1/4\n−1/4\n3/4\n|\n−1/4\n5/4\n−3/4\n\n\n⇒\n\n\n3/12\n−3/12\n−3/12\n1/4\n−1/4\n3/4\n−1/4\n5/4\n−3/4\n\n=\n\n\n1/4\n−1/4\n−1/4\n1/4\n−1/4\n3/4\n−1/4\n5/4\n−3/4\n\n\nNote 1.6.3\nAlways prove your inverse solution by checking whether, AA−1 = I\nDefinition 1.6.3\nA matrix that has undergone Gaussian elimination is said to be in echelon\nform.\nNote 1.6.4\nGauss-Jordan is a special case of Gaussian elimination.\nExample 1.6.5\nCompute A−1 given A =\n\n\n\n\n\n\n|\n|\n|\n\n\n1.) Gauss-Jordan Elimination (Coefficients multiplied on only the pivot):\n\n\n|\n|\n|\n\n\n•The first column looks okay since the non-zero term is only in a11.\nLet R1 →R1,\n\n\n|\n|\n|\n\n\n[But when looking for operations for second column,only use R2 ]\nLet −R2 + R1 →R1,\n−R2 + R3 →R3\n\n\n|\n−1\n|\n|\n−1\n\n\nPage 28 of 246", "word_count": 273, "start_char": 37428, "end_char": 38586}
{"chunk_id": "DOC0094__00029", "doc_id": "DOC0094", "chunk_index": 29, "text": "et R1 →R1,\n\n\n|\n|\n|\n\n\n[But when looking for operations for second column,only use R2 ]\nLet −R2 + R1 →R1,\n−R2 + R3 →R3\n\n\n|\n−1\n|\n|\n−1\n\n\nPage 28 of 246\n\n[But when looking for operations for third column,only use R3 ]\nLet −R3 + R1 →R1,\n\n\n|\n−1\n|\n|\n−1\n\n\n• To have (I, B)\nwe use 1\n2R1 →R1, 1\n2R2 →R2, 1\n2R3 →R3 to have\n\n\n|\n1/2\n−1/2\n|\n1/2\n|\n−1/2\n1/2\n\n\n⇒\n\n\n1/2\n−1/2\n1/2\n−1/2\n1/2\n\n\n2.) Gauss Elimination (Coefficients can be multiplied on any entry):\n\n\n|\n|\n|\n\n\n•The first column looks okay since the non-zero term is only in a11.\nLet R1 →R1,\n\n\n|\n|\n|\n\n\n[But when looking for operations for second column,only use R2 ]\nLet R1 −R2 →R1,\nR3 −R2 →R3\n\n\n|\n−1\n|\n|\n−1\n\n\n[But when looking for operations for third column,only use R3 ]\nLet R1 −R3 →R1,\n\n\n|\n−1\n|\n|\n−1\n\n\n• To have (I, B)\nwe use 1\n2R1 →R1, 1\n2R2 →R2, 1\n2R3 →R3 to have\n\n\n|\n1/2\n−1/2\n|\n1/2\n|\n−1/2\n1/2\n\n\n⇒\n\n\n1/2\n−1/2\n1/2\n−1/2\n1/2\n\n\nPage 29 of 246\n\nExample 1.6.6\nDetermine the inverse A−1 of\nA =\n\n\n−1\n−1\n−1\n\n\nusing the Gauss-Jordan row reduction technique.\n[A|I]\n=\n\n\n−1\n−1\n−1\n\n\nR1\n⇝\nR1\n3R1 + R2\n⇝\nR2\n−R1 + R3\n⇝\nR3\n=\n\n\n−1\n−1\n\n\n−0.5R2 + R1\n⇝\nR1\nR2\n⇝\nR2\n−R2 + R3\n⇝\nR3\n=\n\n−1\n−3\n−1\n−1\n−5\n−4\n−1\n\n−3\n10R3 + R1\n⇝\nR1\n5R3 + R2\n⇝\nR2\nR3\n⇝\nR3\n=\n\n\n−1\n−1\n−3\n−13\n−2\n−5\n−4\n−1\n\n\n−R1\n⇝\nR1\n2R2\n⇝\nR2\n−1\n5R3\n⇝\nR3\n=\n\n−7\n−13\n−1\n−1\n\n=\n\n\n−0.7\n0.2\n0.3\n−1.3\n−0.2\n0.7\n0.8\n0.2\n−0.2\n\n\nThe last three columns constitute A−1. Check:\n\n\n−1\n−1\n−1\n\n\n\n\n−0.7\n0.2\n0.3\n−1.3\n−0.2\n0.7\n0.8\n0.2\n−0.2\n\n=\n\n\n\n\nHence AA−1A−1A = I\nPage 30 of 246", "word_count": 414, "start_char": 38431, "end_char": 39958}
{"chunk_id": "DOC0094__00030", "doc_id": "DOC0094", "chunk_index": 30, "text": "heck:\n\n\n−1\n−1\n−1\n\n\n\n\n−0.7\n0.2\n0.3\n−1.3\n−0.2\n0.7\n0.8\n0.2\n−0.2\n\n=\n\n\n\n\nHence AA−1A−1A = I\nPage 30 of 246\n\nRemark 1.6.3\nFor sure AA−1 = I.\nExample 1.6.7\nCompute A−1 given A =\n\n\n−1\n\nusing the Gaussian elimination row\nreduction (not Gauss-Jordan elimination).\n=\n\n\n−1\n|\n|\n|\n\n\nR1\n⇝\nR1\nR2 −2R1\n⇝\nR2\nR3 −4R1\n⇝\nR3\n=\n\n\n−1\n−1\n|\n|\n−2\n|\n−4\n\n\nR1\n⇝\nR1\nR2\n⇝\nR2\nR3 + R2\n⇝\nR3\n=\n\n\n−1\n−1\n−1\n|\n|\n−2\n|\n−6\n\n\n2R3 + R1\n⇝\nR1\nR3 −R2\n⇝\nR2\nR3\n⇝\nR3\n=\n\n\n−1\n|\n−11\n|\n−4\n|\n−6\n\n\nR1\n⇝\nR1\nR2\n⇝\nR2\n−R3\n⇝\nR3\n(I : B)\n=\n\n\n|\n−11\n|\n−4\n|\n−1\n−1\n\n\n⇒\n\n\n−11\n−4\n−1\n−1\n\n\nExercise 1.6.1\n\n\n−1\n\n, determine\n1.) |A|, using\n(a) Permutation-inversions technique\n(b) Cofactors.\n|A| = −1\n2.) A−1, using\n(a) A−1 = 1\n|A|adj(A)\n(b) Row reduction (Gauss-Jordan elimination\nor Gauss elimination).\nA−1 =\n\n\n−3\n−6\n−7\n−2\n\n\nPage 31 of 246", "word_count": 222, "start_char": 39845, "end_char": 40665}
{"chunk_id": "DOC0094__00031", "doc_id": "DOC0094", "chunk_index": 31, "text": "−1 =\n\n\n−3\n−6\n−7\n−2\n\n\nPage 31 of 246\n\n1.6.5\nProperties of Matrix Inverse\n1.) If A−1 is invertible, then\n(A−1)−1 = A\n2.) If AB is invertible, then\n(AB)−1 = B−1A−1\nLet x = (AB)−1 then\n(AB)x\n=\n(AB)(AB)−1 = I\n(1.11)\nBut also\n(AB)x\n=\nA(Bx)\n(1.12)\nThus (1.11) will become\n(AB)x\n=\nI\nA(Bx)\n=\nI\nA−1A(Bx)\n=\nA−1I\nI(Bx)\n=\nA−1\nBx\n=\nA−1\nB−1Bx\n=\nB−1A−1\nx\n=\nB−1A−1\n⇒(AB)−1 = B−1A−1\n■\n3.) If AT is invertible, then\n(AT)−1 = (A−1)T\nAssume A is invertible, then A−1 exists and we have,\n(A−1)TAT\n=\n(AA−1)T = IT = I and\nAT(A−1)T\n=\n(A−1A)T = IT = I\nso AT is invertible and (AT)−1 = (A−1)T.\n■\n4.) For αA invertible for any nonzero scalar α, then (αA)−1 = 1\nαA−1.\n5.) The inverse of a diagonal matrix is obtained by inverting the diagonal elements.\n6.) If a product AB is not invertible, then A or B is not invertible.\n7.) If A or B are not invertible, then AB is not invertible.\nExercise 1.6.2 Use both the methods of inverses and properties of inverses to determine A−1\nfor A =\n\n\n−4\n\n.\nA−1 =\n\n\n1/2\n1/3\n−1/4\n\n\nExercise 1.6.3\n\n\n−1\n\n.\n\nA−1 =\n\n\n1/4\n−1/4\n−1/4\n1/4\n−1/4\n1/4\n−1/4\n5/4\n−3/4\n\n\n\n.\nPage 32 of 246", "word_count": 243, "start_char": 40626, "end_char": 41728}
{"chunk_id": "DOC0094__00032", "doc_id": "DOC0094", "chunk_index": 32, "text": "−1 =\n\n\n1/2\n1/3\n−1/4\n\n\nExercise 1.6.3\n\n\n−1\n\n.\n\nA−1 =\n\n\n1/4\n−1/4\n−1/4\n1/4\n−1/4\n1/4\n−1/4\n5/4\n−3/4\n\n\n\n.P\n\nage 32 of 246\n\nExample 1.6.8 Find the inverse A−1 for the matrix\nA =\n\n\n\n\n1.) Using the Cofactor-Adjoint technique.\nFrom Example 1.5.15, the cofactor matrix of A was given as\n\n\n−6\n−6\n−3\n−2\n\n\n⇒\n\n\n−6\n−3\n−2\n−6\n\n\n⇒\nA−1 = 1\n|A|adj(A) = 1\n\n\n−6\n−3\n−2\n−6\n\n=\n\n\n1/2\n−1/2\n−1/4\n1/3\n−1/6\n−1/2\n1/2\n3/4\n\n\n2.) Using Gaussian elimination row-reduction\n[A : I]\n=\n\n\n|\n|\n|\n\n\nR1 ⇝R1\nR1 −4R2 ⇝R2\nR1 −2R3 ⇝R3\n\n\n|\n−9\n−2\n|\n−4\n−2\n|\n−2\n\n\n3R1 + R2 ⇝R1\nR2 ⇝R2\n3R3 + R2 ⇝R3\n\n\n|\n−4\n−9\n−2\n|\n−4\n−8\n|\n−4\n−6\n\n\n2R1 + R3 ⇝R1\n4R2 −R3 ⇝R2\nR3 ⇝R3\n\n\n|\n−12\n−6\n−36\n|\n−12\n−8\n|\n−4\n−6\n\n\n24R1 ⇝R1\n−1\n36R2 ⇝R2\n−1\n8R3 ⇝R3\n[I : B]\n=\n\n\n|\n1/2\n−1/2\n−1/4\n|\n1/3\n−1/6\n|\n−1/2\n1/2\n3/4\n\n\n⇒\nA−1 =\n\n\n1/2\n−1/2\n−1/4\n1/3\n−1/6\n−1/2\n1/2\n3/4\n\n\nNote 1.6.5\nThe value for an inverse is always the same for both methods.\nPage 33 of 246", "word_count": 256, "start_char": 41597, "end_char": 42526}
{"chunk_id": "DOC0094__00033", "doc_id": "DOC0094", "chunk_index": 33, "text": "age 33 of 246\n\n1.7\nMatrices Chapter Examples\nExample 1.7.1\nCompute the determinant of each of the following matrices. Indicate clearly\nthe method being used.\n1.) Method of cofactors and adjoints\nA =\n\n\n−3\n−3\n−1\n−6\n−2\n−1\n\n\nThe determinant can be got by\ndet A\n=\n−7 det\n\n\n−3\n−3\n−1\n−2\n−1\n\n\n(along the second row)\n=\n−7(4) det\n\n\n−3\n−2\n−1\n\n\n(along the fourth row)\n=\n−7(4)(2) det\n\u0014 2\n−1\n\u0015\n(along the first row)\n=\n−7(4)(2)(−2) = 112\n2.)\nA =\n\n\nb\nb2\nb\nb2\nb3\nb2\nb3\nb4\n\n\n(where b is any real number).\nWe can do row operations: Add −b times the first row to the second row and −b2 times the\nfirst row plus the second row. This gives\n\n\nb\nb2\n\n\nTherefore det A = 0. Thus, the original matrix is not invertible, since its determinant is\nzero.\nExample 1.7.2\nLet\nA =\n\n\n\n\nB =\n\n\n\n\nC =\n\n\nx\n\n\n1.) Find det A and give a reason for your answer.\ndet A = 0 because two rows are equal.\nPage 34 of 246", "word_count": 213, "start_char": 42513, "end_char": 43439}
{"chunk_id": "DOC0094__00034", "doc_id": "DOC0094", "chunk_index": 34, "text": "hus, the original matrix is not invertible, since its determinant is\nzero.E\n\nxample 1.7.2\nLet\nA =\n\n\n\n\nB =\n\n\n\n\nC =\n\n\nx\n\n\n1.) Find det A and give a reason for your answer.\ndet A = 0 because two rows are equal.P\n\nage 34 of 246\n\n2.) Find the cofactor C11 and then find det B.\nThe cofactor C11 = −1. Then det B = det A −C11 = 1.\n3.) Find detC for any value of x. You could use linearity in row 1.\ndet C = xC11 + det B = −x + 1. Check this answer (zero), for x = 1 when C = A.\nExample 1.7.3\n\n\na\nb\nc\nd\ne\nf\ng\nh\ni\n\nand assume that det(A) = 10. Find\n1.) det(3A)\n2.) det (2A−1)\n3.) det (2A2)\n4.) det\nNotice that A is a 3 × 3 matrix. Therefore,\ndet(3A)\n=\n33 det(A) = 270\ndet\n\u00002A−1\u0001\n=\n23 det\n\u0000A−1\u0001\n=\ndet(A) = 8\ndet\n\u00002A2\u0001\n=\n23 det\n\u0000A2\u0001\n= 23 det (A)2 = 800\ndet\n=\n33 det\n\u0000(AT)−1\u0001\n=\ndet (AT) =\ndet (A) = 27\n5.) det\n\n\na\ng\nd\nb\nh\ne\ng\ni\nf\n\n\nNotice that we have\nA =\n\n\na\nb\nc\nd\ne\nf\ng\nh\ni\n\n\nR2→R3\n−−−−−−−→\nInterchange\nB =\n\n\na\nb\nc\ng\nh\ni\nd\ne\nf\n\n\nand BT =\n\n\na\ng\nd\nb\nh\ne\ng\ni\nf\n\n\nAs a result, we have det(BT) = det(B) = (−1) det(A) = −10.\nExample 1.7.4\nSpecify whether the matrix has an inverse without trying to compute the\ninverse A =\n\n\n\n\n.\nSolution :\n|A| = −12 ̸= 0 ⇒\n∃A−1\n■\nExample 1.7.5\nSuppose A =\n\n\n\n. Which one of the following statements is true ?\nPage 35 of 246", "word_count": 337, "start_char": 43192, "end_char": 44493}
{"chunk_id": "DOC0094__00035", "doc_id": "DOC0094", "chunk_index": 35, "text": "xample 1.7.4\nSpecify whether the matrix has an inverse without trying to compute the\ninverse A =\n\n\n\n\n.S\n\nolution :\n|A| = −12 ̸= 0 ⇒\n∃A−1\n■\nExample 1.7.5\nSuppose A =\n\n\n\n.W\n\nhich one of the following statements is true ?P\n\nage 35 of 246\n\nA. A−1 does not exist.\nB. The third row of A−1 is [−1\n−1 1].\nC. The second row of A−1 is [1 2\n−1].\nD. The first row of A−1 is [2 0\n−1].\nE. The second column of A−1 is [0 2\n−1]T.\nF. All of B, C, D, E are true.\nB\nExample 1.7.6\n\n\n−1\nx\n\n. For which value(s) of x is A invertible?\nA. x ̸= −1\nB. x ̸= 1\nC. x ̸= 0\nD. x = −1\nE. x = 1\nF. x ̸= ±1\nA\nExample 1.7.7\nIf three n × n matrices A, B and C satisfy AB −BA = C, then ABA is\nalways equal to :\nA. A2B −C\nB. A2B −CA\nC. BA2 + CA\nD. A2B\nE. A2B + AC\nF. A2B + BC\nC\nExample 1.7.8\nLet\nA =\n\u0014\n−4\n−5\n\u0015\n\u0014 7\nk\n\u0015\n.\nFor which values of k does AB = BA hold?\nk = 9\nExample 1.7.9\n\n\n\nCompute\n1.) |A|, using\n(a) Permutation-inversions scheme\n(b) Cofactors.\n|A| = −12\n2.) A−1, using\n(a) A−1 = 1\n|A|adj(A)\n(b) Row reduction.\nA−1 =\n\n\n−1/3\n1/4\n1/3\n1/3\n1/6\n−7/12\n1/3\n−1/3\n1/16\n\n\nPage 36 of 246", "word_count": 269, "start_char": 44243, "end_char": 45320}
{"chunk_id": "DOC0094__00036", "doc_id": "DOC0094", "chunk_index": 36, "text": "or which values of k does AB = BA hold?\nk = 9\nExample 1.7.9\n\n\n\nCompute\n1.) |A|, using\n(a) Permutation-inversions scheme\n(b) Cofactors.\n|A| = −12\n2.) A−1, using\n(a) A−1 = 1\n|A|adj(A)\n(b) Row reduction.A\n\n−1 =\n\n\n−1/3\n1/4\n1/3\n1/3\n1/6\n−7/12\n1/3\n−1/3\n1/16\n\n\nPage 36 of 246\n\n1.8\nMatrices Chapter Exercises\nExercise 1.8.1\nDefine the subtraction of two matrices A and B.\nExercise 1.8.2\nIf A, B and C are conformable matrices then show that\nA + (B + C) = (A + B) + C.\nExercise 1.8.3\nIf A is an m × p, B is a p × q, and C is a q × n, then show that\n(AB)C = A(BC).\nExercise 1.8.4\nIf A is an m × p, B is an m × p, and C is a p × n, then show that\n(A + B)C = AC + BC.\nExercise 1.8.5\nIf r, s ∈R then show that\n1.) r(sA) = (rs)A\n2.) (r + s)A = rA + sA\n3.) A(rB) = r(AB)\nwhere A is an m × p matrix and B is a p × n matrix\nExercise 1.8.6\nGiven that A and B matrices and r ∈R show that,\n1.) (A′)′ = A\n2.) (rA)′ = rA′\n3.) (A + B)′ = A′ + B′\nExercise 1.8.7 Show that there exists a unique m × n matrix 0 such that A + 0 = A for any\nm × n matrix A.\nExercise 1.8.8\nShow that for each m × n matrix A, there exists a unique m × n matrix −A\nsuch that A + (−A) = 0.\nExercise 1.8.9\nLet A and B be arbitrary n × n matrices. Is it true that\n(A −B)(A + B) = A2 −B2\nExercise 1.8.10\nProve that (AB)′ = B′A′ for A, B conformable matrices.\nExercise 1.8.11\nIf A is an idempotent matrix. Prove that\n1.) An = A\n∀n ∈Z+.\n2.) I −A is idempotent where I is an identity matrix of same order as A. (Is A −I also\nidempotent?).\nExercise 1.8.12\nIf A and B are idempotent matrices. Is AB also idempotent? if not under\nwhat condition(s) will AB be idempotent.\nExercise 1.8.13 If A and B are invertible n × n matrices, Is it true that the inverse of A + B\nis A−1 + B−1?\nExercise 1.8.14\nLet A be an n × n square invertible matrix. Prove that\ndet(A−1) =\nExercise 1.8.15 Find the matrix A such that\n\u0014\n−5\n\u0015\nExercise 1.8.16\nLet A be a 5 × 5 matrix with determinant 6. What is the determinant of\nA−1 (determinant of the inverse of A)?\nPage 37 of 246", "word_count": 459, "start_char": 45045, "end_char": 47047}
{"chunk_id": "DOC0094__00037", "doc_id": "DOC0094", "chunk_index": 37, "text": "xercise 1.8.14\nLet A be an n × n square invertible matrix.P\n\nrove that\ndet(A−1) =\nExercise 1.8.15 Find the matrix A such that\n\u0014\n−5\n\u0015\nExercise 1.8.16\nLet A be a 5 × 5 matrix with determinant 6.W\n\nhat is the determinant of\nA−1 (determinant of the inverse of A)?P\n\nage 37 of 246\n\nA. 6.\nB. 0.\nC. 1/6.\nD. 30.\nE. 25/6.\nF. 1.\nto\nC\nExercise 1.8.17\nLet A be a 5 × 5 matrix with determinant 6, and let B be a 5 × 5 matrix\nwith determinant 4. What is the determinant of AB?\nA. 24.\nB. 10.\nC. 0.\nD. 1/6.\nE. 1/4.\nF. 1.\nto\nA\nExercise 1.8.18\nSuppose A is an n × n matrix, prove that det[adj(A)] = (det A)n−1\nExercise 1.8.19 What is the size of the matrix B if the product AB has been computed and\nA is m × n matrix?\nExercise 1.8.20\nFor A and b matrices show that r(A + B) = rA + rB for r a real number.\nWhat is known about the sizes of A and B?\nExercise 1.8.21 If A and B are symmetric matrices of the same order, show that ATBT +AB\nis also symmetric.\nExercise 1.8.22\nState any two axioms of inverse of a matrix.\nExercise 1.8.23\nFor a symmetric matrix A and a skew-symmetric matrix B, show that the\nmatrix AB −BA is also symmetric.\n(AB −BA)T = (AB)T −(BA)T = BTAT −ATBT = −BA −A(−B) = AB −BA.\nExercise 1.8.24 True or False? Every nonzero square matrix has an inverse.\nFalse\nExercise 1.8.25\n\n\n−4\nk2 + 3\n2k\n\n. Find the values of k such that tr(A) = 7.\n(k + 3)(k −1) = 0 ⇒k = −3 or k = 1\nPage 38 of 246", "word_count": 303, "start_char": 46772, "end_char": 48159}
{"chunk_id": "DOC0094__00038", "doc_id": "DOC0094", "chunk_index": 38, "text": "xercise 1.8.24 True or False?E\n\nvery nonzero square matrix has an inverse.F\n\nalse\nExercise 1.8.25\n\n\n−4\nk2 + 3\n2k\n\n.F\n\nind the values of k such that tr(A) = 7.\n(k + 3)(k −1) = 0 ⇒k = −3 or k = 1\nPage 38 of 246\n\nExercise 1.8.26\nLet A be a 5 × 5 matrix with determinant 6, and let B be a 5 × 5 matrix\nwith determinant 4. What is the determinant of A + B?\nA. 24.\nB. 10.\nC. 0.\nD. 1/6.\nE. 1/4.\nF. 1.\nto\nG\nExercise 1.8.27\n−A?\nA. 3.\nB. -3.\nC. 1/3.\nD. 0.\nE. 1.\nF. -1.\nto\nA\nExercise 1.8.28\n2A?\nA. 6.\nB. 3.\nC. 24.\nD. 48.\nE. 12.\nF. 196,608.\nto\nD\nExercise 1.8.29\nAT (the transpose of A)?\nA. 3T.\nB. 3.\nC. 12.\nD. 1/3.\nE. 27.\nF. 81.\nto\nB\nExercise 1.8.30\nLet A be a 4 × 4 matrix with determinant 3. Let B be the matrix formed\nby swapping the second and third rows of A. What is det(B)?\nA. 3.\nB. 0.\nC. 1/3.\nD. -3.\nE. 6.\nF. 2.\nto\nD\nPage 39 of 246\n\nExercise 1.8.31\nIf A is a 3 × 5 matrix, then the determinant of A is\nA. A number (possibly non-zero).\nB. 35.\nC. Zero.\nD. 53.\nE. A 5 × 3 matrix.\nF. Undefined.\nG. A 3 × 5 matrix.\nF\nExercise 1.8.32\nFind the row reduced echelon form of the matrix below:\nA =\n\n\n−2\n−4\n−2\n−2\n−2\n−4\n\n\n\n\n5/4\n−11/8\n\n\nExercise 1.8.33\nFind the determinant of the matrix below. Specify whether the matrix has\nan inverse without trying to compute the inverse.\n\n\n−2\n−2\n−2\n−2\n−2\n−2\n−1\n−3\n−1\n\n\nRow reduce the given matrix to an upper triangular matrix\n\n\n−2\n−2\n−2\n−2\n−2\n−2\n−1\n−3\n−1\n\n\n∼\n\n\n−2\n−2\n−2\n−4\n−2\n−2\n−4\n\n\nAs a result, the determinant is −32 which is not 0. Therefore, the given matrix is invertible.\nExercise 1.8.34\n\n\n−2\n−6\n−2\n\n;\n\nA−1 = 1\n\n\n−72\n−24\n\n\n\n\nPage 40 of 246", "word_count": 386, "start_char": 47947, "end_char": 49578}
{"chunk_id": "DOC0094__00039", "doc_id": "DOC0094", "chunk_index": 39, "text": "herefore, the given matrix is invertible.E\n\nxercise 1.8.34\n\n\n−2\n−6\n−2\n\n;\n\nA−1 = 1\n\n\n−72\n−24\n\n\n\n\nPage 40 of 246\n\nExercise 1.8.35\nShow that det(A) = 0 where\n\n\na\nb\n−a\nc\n−b\n−c\n\n\nNote that A = −AT. Then we get\n=\ndet((−1)AT)\n=\n(−1)3 det(AT)\n=\n(−1)3 det(A)\n=\n−det(A), i.e.,\n2 det(A) = 0\n→\ndet(A) = 0.\nOR Calculate the determinant with respect to any column or any row of your choice.\nExercise 1.8.36\nFind the inverse of the following matrix A =\n\n\n\n.\nA−1 = 1\n\n\n−6\n−3\n\n\nExercise 1.8.37\n1.) An n × n matrix A is called orthogonal if AAT = I. If A is orthogonal show that\ndet(A) = ±1.\nBy the properties of determinant,\ndet(AAT) = det(A) det(AT) = det(A) det(A) = det(A)2 = det(I) = 1.\nSo, det(A) = ±1.\n2.) An n × n matrix A is called skew-symmetric if AT = −A. Show that if A is skewsymmetric and n is an odd positive integer, then A is not invertible.\nBy the properties of determinant,\ndet(AT) = det(−A) ⇒det(A) = det(−A) ⇒det(A) = (−1)n det(A) ⇒det(A) = −det(A).\nSo, we get det(A) = 0 which implies that A is not invertible. Note that −A means that\nevery row of A is multiplied by −1.\n3.) Let A and B be two non-singular symmetric matrices that commute. Show that A−1B and\nA−1B−1 are symmetric.\nExercise 1.8.38\nSpecify whether the matrix has an inverse without trying to compute the\ninverse\n\n\n−1\n−1\n−1\n−1\n\n\nPage 41 of 246\n\nWe use the definition of determinant. We calculate the determinant across the 2nd rows and\n3rd column.\n\n−1\n−1\n−1\n−1\n\n=\n(−1)\n\n−1\n−1\n−1\n\n=\n(−1)\n\n(−1)\n\n−1\n−1\n\n\n\n=\n(−1)\n\u0012\n(−1)\n\u0012\n(−1)\n\n−1\n−1", "word_count": 326, "start_char": 49456, "end_char": 50995}
{"chunk_id": "DOC0094__00040", "doc_id": "DOC0094", "chunk_index": 40, "text": "e calculate the determinant across the 2nd rows and\n3rd column.\n\n−1\n−1\n−1\n−1\n\n=\n(−1)\n\n−1\n−1\n−1\n\n=\n(−1)\n\n(−1)\n\n−1\n−1\n\n\n\n=\n(−1)\n\u0012\n(−1)\n\u0012\n(−1)\n\n−1\n−1\n\n\u0013\u0013\n=\n(−1)(−1)(−1)[(1) −(1)]\n=\nSince we have the determinant is 0, the matrix is not invertible.\nExercise 1.8.39 Find the inverse of the matrix A using the inverse formula (cofactor-adjoint)\nwhere A =\n\n\n−1\n−1\n−2\n\n\nA−1 =\n\n\n−1\n−1\n−2\n−1\n−1\n\n\nExercise 1.8.40\nCompute the determinant of the matrix\n\n\n\n\n\n\n\n\nby using row operations (Hint: Recall the determinant of an upper triangular matrix).\nExercise 1.8.41\nLetA =\n\n\na\na −1\n2a\n(a −1)(a2 −4)\na\na\n\n. Determine those values of a for\nwhich A is invertible.\nTriangular. if and only if a ̸= 0 and a ̸= 1 and a ̸= 2 and a ̸= −2.\nExercise 1.8.42\n\n\na\nb\nc\nd\ne\nf\ng\nh\ni\n\nand assume that det(A) = 2. Find\n1.) det(−2A)\n2.) det\n\u0000 1\n2A−1\u0001\n3.) det (2A2)\n4.) det\n5.) det\n\n\na\ng\nd\nb\nh\ne\nc + 2a\ni + 2g\nf + 2d\n\n\ndet(C) = det(BT) = det(B) = (−1) det(A) = −2\nPage 42 of 246", "word_count": 232, "start_char": 50845, "end_char": 51822}
{"chunk_id": "DOC0094__00041", "doc_id": "DOC0094", "chunk_index": 41, "text": "ind\n1.) det(−2A)\n2.) det\n\u0000 1\n2A−1\u0001\n3.) det (2A2)\n4.) det\n5.) det\n\n\na\ng\nd\nb\nh\ne\nc + 2a\ni + 2g\nf + 2d\n\n\ndet(C) = det(BT) = det(B) = (−1) det(A) = −2\nPage 42 of 246\n\nExercise 1.8.43\nLet\nA =\n\n\n−1\n\n,\nB =\n\n\n−2\n−4\n\n.\nVerify directly that A(AB) = A2B.\nExercise 1.8.44\nFind the determinant of the matrix A =\n\n\n\n\nWe apply the row operations to A to have\n\n\n\n\n⇒\ndet A = 1\nExercise 1.8.45\nFind x, assuming\ndet\n\n\nx2\nx\n−5\n\n= 0\nCalculate the determinant according to the third row: x = 0 or x = 2\nExercise 1.8.46 Let A and B be 4 × 4 matrices with det(A) = −1 and det(B) = 2. Find the\ndeterminant det(B−1AB).\nWe have\ndet(B−1AB)\n=\ndet(B−1) det(A) det(B)\n=\ndet(B) det(A) det(B)\n=\n=\n−1\nExercise 1.8.47\nState whether the following are true or false. If true, explain why, if false,\ngive a numerical example to illustrate.\n1.) If A and B are 2 by 2 matrices, then det(A + B) is always equal to det A + det B.\nFalse: A =\n\u0014 1\n\u0015\n,\nB =\n\u0014 0\n\u0015\n⇒0 + 0 ̸= 1\n2.) If a 13 × 13 matrix A satisfies then A2 = 0, then A is not invertible.\nTrue. Assume A invertible, A = A−1A2 = 0 ⇒det A = 0 ⇒, A invertible\nPage 43 of 246", "word_count": 270, "start_char": 51657, "end_char": 52783}
{"chunk_id": "DOC0094__00042", "doc_id": "DOC0094", "chunk_index": 42, "text": "alse: A =\n\u0014 1\n\u0015\n,\nB =\n\u0014 0\n\u0015\n⇒0 + 0 ̸= 1\n2.) If a 13 × 13 matrix A satisfies then A2 = 0, then A is not invertible.T\n\nrue.A\n\nssume A invertible, A = A−1A2 = 0 ⇒det A = 0 ⇒, A invertible\nPage 43 of 246\n\nExercise 1.8.48\nIf C =\n\u0014 0\n\u0015\nand D is a 3 × m matrix then the second row of the\nmatrix CD is\nA. not defined unless m = 2.\nB. the same as the first row of D.\nC. the same as the second row of D.\nD. the sum of the first and the third row of D.\nE. the sum of twice the second row of D and the third row of D.\nF. twice the first row of D.\nD\nExercise 1.8.49 Which of the following statements are false?\n1.) For all invertible n × n matrices A and B, det(A−1BA) = det B\n2.) For all invertible n × n matrices A and B, det(A−1B−1AB) = 1\n3.) For all n × n matrices A and B,\n\u0000ATBT\u0001T = AB\n4.) For all invertible n × n matrices A and B, (ABA−1)−1 = A−1B−1A\n5.) For all n × n matrices A and B, det(ATB) = det(BTA)\nA. (1) and (3)\nB. (2) and (3)\nC. (3) and (4)\nD. (2) and (4)\nE. (2) and (5)\nF. (1) and (5)\n(1), True:\n(2), True:\n(3), False :\n\u0000ATBT\u0001T = BA.\n(4), False : (ABA−1)−1 = AB−1A−1.\n(5), True :\nIts possible that AB ̸= BA and A−1B−1A ̸= AB−1A−1\nC\nExercise 1.8.50\nLet A and B denote matrices, not necessarily square, and which have more\nthan 1 row and more than 1 column, and let x denote a column vector (i.e., a k × 1 matrix for\nsome k).\nState whether each of the following is (always) true, or is (possibly) false\n• If you say the statement may be false, you must give an explicit example - with numbers!\n(Hint: Try an example with 2 or 3 rows or columns.)\n• If you say the statement is true, you must give a clear explanation - by quoting a theorem\npresented in class, any by giving other valid proof.\nPage 44 of 246", "word_count": 386, "start_char": 52584, "end_char": 54294}
{"chunk_id": "DOC0094__00043", "doc_id": "DOC0094", "chunk_index": 43, "text": "age 44 of 246\n\n1.) If A is m × n and rankA = m, then the system Ax = 0 has a unique solution.\nFalse: A =\n\u0014 1\n\u0015\n2.) If AB = 0 then either A = 0 or B = 0.\nFalse: A = B =\n\u0014 0\n\u0015\n3.) If B has a column of zeros then AB has a column of zeros.\nTrue\nWrite B with column entries where the jth column is zeros.\nB = [c1 c2\n· · ·\n0 cj+1\n· · ·\ncn]\nThen\nAB = [Ac1 Ac2\n· · ·\nA · 0 Acj+1\n· · ·\nAcn] = [Ac1 Ac2\n· · ·\n0 Acj+1\n· · ·\nAcn]\nThat is, if the jth column of B is zero, then the jth column of AB is zero as well.\nExercise 1.8.51\nIf two n × n matrices A and B satisfy AT = B−1 and BT = −B−1 then\n(ABA)T is always\nA. −B3\nB. B2A\nC. −B−3\nD. B−3\nE. B3\nF. AB2\nC\nExercise 1.8.52\nDetermine the value(s) of λ for which the matrix\nA =\n\n\nλ\n−1\n−1\nλ\n−1\n−1\nλ\n\n\nis invertible.\nInvertible if |A| ̸= 0, since already a square matrix. λ ̸= 0 and λ ̸=\n√\n2 and λ ̸= −\n√\nPage 45 of 246", "word_count": 230, "start_char": 54281, "end_char": 55138}
{"chunk_id": "DOC0094__00044", "doc_id": "DOC0094", "chunk_index": 44, "text": "−3\nE.B\n\n3\nF.A\n\nB2\nC\nExercise 1.8.52\nDetermine the value(s) of λ for which the matrix\nA =\n\n\nλ\n−1\n−1\nλ\n−1\n−1\nλ\n\n\nis invertible.I\n\nnvertible if |A| ̸= 0, since already a square matrix. λ ̸= 0 and λ ̸=\n√\n2 and λ ̸= −\n√\nPage 45 of 246\n\nExercise 1.8.53\nAssume that B is a 3 × 3 matrix with the property that B2 = B. Which of\nthe following statements about the matrix B must be true:\nA. AB is invertible\nB. det(B) = 0\nC. det(B5) = det(B)\nD. None of the above must be true\nC\nTwo examples of matrices that satisfy B2 = B are B = I3 and B = 03×3 where 03×3 is the 3×3\nmatrix with all zero entries. So (A) is false because the 0 matrix satisfies the property but is\nnot invertible. Similarly (B) is false because the identity matrix satisfies the property but the\ndeterminant of the identity is 1 not 0. (C) is true because\nB5 = (BB)(BB)B = (B)(B)B = (BB)B = (B)B = BB = B\nso B5 = B and hence in particular det(B5) = det(B).\nExercise 1.8.54\nTrue or False? If A and B are both invertible n × n matrices, then AB is\ninvertible.\nTrue: One way to see this is to note that if A and B are invertible then each of their determinants\nare nonzero. But then\ndet(AB) = det(A)det(B)\nis also nonzero since its a product of two non zero numbers. Hence since det(AB) is nonzero,\nit follows that AB is invertible.\nExercise 1.8.55\nTrue or False? Let A and B be n × n matrices. Assume that\nAB = In.\nThen,\nBA = In\nTrue: Since AB = In it follows from the invertible matrix theorem (the theorem that gives\nall the many equivalences for a matrix being invertible) that A and similarly B are invertible.\nMoreover, the equation AB = In says that B = A−1 Hence in this case BA = (A−1)A = In.\nExercise 1.8.56\nCompute the inverse of the matrix A =\n\n\n\n\nExercise 1.8.57\nIf E is a 3 × 3 matrix of the form\nE =\n\n\nx\ny\nz\n−3\n\n.\nGiven det(E) = 5, compute the determinant of the following matrix\nF =\n\n\nx\ny\nz\n−3 + 4x\n7 + 4y\n2 + 4z\n\n.\nPage 46 of 246", "word_count": 417, "start_char": 54905, "end_char": 56821}
{"chunk_id": "DOC0094__00045", "doc_id": "DOC0094", "chunk_index": 45, "text": "iven det(E) = 5, compute the determinant of the following matrix\nF =\n\n\nx\ny\nz\n−3 + 4x\n7 + 4y\n2 + 4z\n\n.P\n\nage 46 of 246\n\nExercise 1.8.58\nLet the matrices\nX =\n\u0014 1\n\u0015\n,\nY =\n\u0014 −3\n\u0015\n1.) Compute X−1\nX−1 =\n\u0014\n−1\n−1\n\u0015\n.\n2.) Compute XY X−1\nXY X−1 =\n\u0014 1\n\u0015 \u0014 −3\n\u0015 \u0014\n−1\n−1\n\u0015\n=\n\u0014 −2\n−1\n\u0015 \u0014\n−1\n−1\n\u0015\n=\n\u0014 −11\n−11\n\u0015\n3.) Compute det(XY X−1)\ndet\n\u0014 −11\n−11\n\u0015\n= (−11)(10) −(9)(−11) = −110 + 99 = −11\n4.) What is the relationship between det(Y ), and det(XY X−1) and why?\ndet(Y ) = det\n\u0014 −3\n\u0015\n= (−3)(2) −(5)(1) = −6 −5 = −11\nSo det(XY X−1) = det(Y ). This is not a coincidence. In fact,\ndet(XY X−1) = det(X) det(Y ) det(X−1) = det(X) det(X−1) det(Y )\n= det(XX−1) det(Y ) = det(I2) det(Y ) = 1 ∗det(Y ) = det(Y )\nExercise 1.8.59\nWhat is the reduced row echelon form of the matrix\n\n\n−1\n−1\n\n?\nA.\n\n\n−1\n−1\n\n\nB.\n\n\n−1\n−1\n\n\nC.\n\n\n−1\n\n\nD.\n\n\n−1\n−1\n\n\nE. none of the preceding.\nPage 47 of 246\n\nExercise 1.8.60\nWhat is the determinant of the matrix\n\n\n\n\nA. −120\nB. −24\nC. 0\nD. 24\nE. 120\nExercise 1.8.61\nWhat is the first row of the inverse of the matrix\n\n\n\n\nA. [0\n−2\n1]\nB. [0\n−3\n−6]\nC. [0\n−3]\nD. [2\n0]\nE. The inverse does not exist.\nExercise 1.8.62\nIf\n\na\nb\nc\nd\ne\nf\ng\nh\ni\nj\nk\nl\nm\nn\no\np\n\n= 3, find\n\nb\nf −2n\nn\n5j −b\na\ne −2m\nm\n5i −a\nc\ng −2o\no\n5k −c\nd\nh −2p\np\n5l −d", "word_count": 336, "start_char": 56700, "end_char": 57956}
{"chunk_id": "DOC0094__00046", "doc_id": "DOC0094", "chunk_index": 46, "text": "he inverse does not exist.E\n\nxercise 1.8.62\nIf\n\na\nb\nc\nd\ne\nf\ng\nh\ni\nj\nk\nl\nm\nn\no\np\n\n= 3, find\n\nb\nf −2n\nn\n5j −b\na\ne −2m\nm\n5i −a\nc\ng −2o\no\n5k −c\nd\nh −2p\np\n5l −d\n\nExercise 1.8.63\nFind the row echelon form of the following matrices.\nA =\n\n\n−4\n−6\n−9\n−8\n\n,\nB =\n\n\n−4\n−3\n−2\n\n,\nC =\n\n\n\n\nThe row echelon form\nA =\n\n\n−4\n−6\n−9\n−8\n\n∼\n\n\n−4\n\n\nB =\n\n\n−4\n−3\n−2\n\n∼\n\n\n\n∼\n\n\n\n\nC =\n\n\n\n∼\n\n\n−4\n−8\n−12\n−5\n−10\n−17\n\n∼\n\n\n17/5\n\n∼\n\n\n2/5\n\n\nExercise 1.8.64\nFind the reduced row echelon form of the following matrix\n\n\n\n\n\n\n\n∼\n\n\n\n∼\n\n\n\n∼\n\n\n\n\n∼\n\n\n\n∼\n\n\n\n∼\n\n\n\n∼\n\n\n−1\n\n\nPage 48 of 246", "word_count": 203, "start_char": 57801, "end_char": 58422}
