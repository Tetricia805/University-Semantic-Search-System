{"chunk_id": "DOC0132__00000", "doc_id": "DOC0132", "chunk_index": 0, "text": "Chapter 1\nIntroduction\nMost real mathematical problems do not have analytical solutions. However, they do have\nreal solutions. In order to obtain these solutions we must use other methods such as graphical\nrepresentations, or numerical analysis. Numerical analysis is the mathematical method that\nuses numerical approximations to obtain numerical answers to the problem. Numerical analysis\nalso considers the accuracy of an approximation, and when the approximation is good enough.\nNumerical answers are useful because we use numbers to build our world, not with the exact\nanalytical solution, such as\neπ\n√\nThe ever-increasing advances in computer technology has enabled many in science and engineering to apply numerical methods to simulate physical phenomena. Numerical methods are\noften divided into elementary ones such as finding the root of an equation, integrating a function or solving a linear system of equations to intensive ones like the finite element method.\nIntensive methods are often needed for the solution of practical problems and they often require the systematic application of a range of elementary methods, often thousands or millions\nof times over. In the development of numerical methods, simplifications need to be made to\nprogress towards a solution: for example general functions may need to be approximated by\npolynomials and computers cannot generally represent numbers exactly anyway. As a result,\nnumerical methods do not usually give the exact answer to a given problem, or they can only\ntend towards a solution getting closer and closer with each iteration. Numerical methods are\ngenerally only useful when they are implemented on computer using a computer programming language .\nThe study of the behavior of numerical methods is called numerical analysis. This is a mathematical subject that considers the modeling of the error in the processing of numerical methods\nand the subsequent re-design of methods.\nNumerical analysis involves the study of methods of computing numerical data. In many problems this implies producing a sequence of approximations; thus the questions involve the rate\nof convergence, the accuracy (or even validity) of the answer, and the completeness of the response. (With many problems it is difficult to decide from a program’s termination whether\nother solutions exist.) Since many problems across mathematics can be reduced to linear algebra, this too is studied numerically; here there are significant problems with the amount of time\nnecessary to process the initial data. Numerical solutions to differential equations require the\ndetermination not of a few numbers but of an entire function; in particular, convergence must\nbe judged by some global criterion. Other topics include numerical simulation, optimization,\nand graphical analysis, and the development of robust working code.\nNumerical linear algebra topics: Solutions of linear systems AX = B, eigenvalues and eigenvec-", "word_count": 446, "start_char": 0, "end_char": 2948}
{"chunk_id": "DOC0132__00001", "doc_id": "DOC0132", "chunk_index": 1, "text": "umerical solutions to differential equations require the\ndetermination not of a few numbers but of an entire function; in particular, convergence must\nbe judged by some global criterion.O\n\nther topics include numerical simulation, optimization,\nand graphical analysis, and the development of robust working code.N\n\numerical linear algebra topics: Solutions of linear systems AX = B, eigenvalues and eigenvec-\n\ntors, matrix factorizations. Calculus topics: numerical differentiation and integration, interpolation, solutions of nonlinear equations f(x) = 0. Statistical topics: polynomial approximation,\ncurve fitting.\nFurther information on the elementary methods can be found in books on numerical methods\nor books on numerical analysis. Dedicated text books can be found on each of the intensive\nmethods. Details of available books can be accessed through www.science-books.net .\nNeed help understanding numerical methods?\n1. What is the use of numerical methods in real life application?\n2. Need a brief explanation of numerical methods\n3. Fixed Point Iteration, Linear Interpolation and Newton-Raphson Method, what are the\ndifferences to their uses?\nBest Answer\n1. um, everywhere? From a cash machine, to calculating how much chemicals to put to\nproduce laundry detergent, to construction of buildings and bridges.\n2. The ever-increasing advances in computer technology has enabled many in science and\nengineering to apply numerical methods to simulate physical phenomena.\nNumerical\nmethods are often divided into elementary ones such as finding the root of an equation,\nintegrating a function or solving a linear system of equations to intensive ones like the\nfinite element method. Intensive methods are often needed for the solution of practical\nproblems and they often require the systematic application of a range of elementary\nmethods, often thousands or millions of times over. In the development of numerical\nmethods, simplifications need to be made to progress towards a solution: for example\ngeneral functions may need to be approximated by polynomials and computers cannot\ngenerally represent numbers exactly anyway.\nAs a result, numerical methods do not\nusually give the exact answer to a given problem, or they can only tend towards a solution\ngetting closer and closer with each iteration. Numerical methods are generally only useful\nwhen they are implemented on computer using a computer programming language .\n3. Visit these sites: http://math.fullerton.edu/mathews/n2003/FixedPointMod.html\nhttp://en.wikipedia.org/wiki/Linear-interpolation\nhttp://mathworld.wolfram.com/NewtonsMethod.html\nOther answers\n2. Numerical Methods refers to procedures to find approximate solutions when exact solutions cannot be found in a straightforward manner.\n3. Linear interpolation assumes that if two points on a graph are given, any point in between\nthem can be found by connecting the original two points by a straight line.\nNewton Raphson is a method to find approximate solutions to an equation through an\niterative process where each calculated value is used as the starting point for the next\ncalculated value. NRM requires that you can evaluate the first derivative of that equation.\nPage 2 of 196", "word_count": 467, "start_char": 2540, "end_char": 5748}
{"chunk_id": "DOC0132__00002", "doc_id": "DOC0132", "chunk_index": 2, "text": "ewton Raphson is a method to find approximate solutions to an equation through an\niterative process where each calculated value is used as the starting point for the next\ncalculated value.N\n\nRM requires that you can evaluate the first derivative of that equation.P\n\nage 2 of 196\n\n1.1. WHAT IS NUMERICAL ANALYSIS?\n1.1\nWhat is Numerical Analysis?\n- It is a way to do highly complicated mathematics problems on a computer.\n- it is also known as a technique widely used by scientists and engineers to solve their\nproblems.\n1.2\nTwo issues of Numerical Analysis:\n- How to compute? This corresponds to algorithmic aspects;\n- How accurate is it? That corresponds to error analysis aspects.\n1.3\nAdvantages and Disadvantages of Numerical Analysis:\nAlthough numerical solutions are just an approximation, an estimate of an exact solution\n(numerical values are ”near” solutions or often referred to as inexact solutions) due to\n1.) truncation errors,\n2.) round off errors,\n3.) chop off errors,\nOther than the truncation errors involved in numerical methods, numerical algorithms are\ncomputationally involved, calling for powerful computing abilities and machines. The schemes\nare usually multi steps and multi terms.\nHowever, numerical techniques are widely applied in solving real world problem.\n1.3.1\nHard or impossible classical solutions\nIt can obtain numerical answers of the problems that have very hard analytical techniques or\nsometimes impossible to solve (no ”exact or classical” solution).\nExample 1.3.1\nFinding the classical solution to an integral\n\u0002\nis quite very hard if not impossible.\nExample 1.3.2\nSolving a simple looking first order ordinary differential equation\ndy\ndx = x2 + y2\nanalytically is not easy at all.\nPage 3 of 196", "word_count": 275, "start_char": 5470, "end_char": 7203}
{"chunk_id": "DOC0132__00003", "doc_id": "DOC0132", "chunk_index": 3, "text": "xample 1.3.1\nFinding the classical solution to an integral\n\u0002\nis quite very hard if not impossible.E\n\nxample 1.3.2\nSolving a simple looking first order ordinary differential equation\ndy\ndx = x2 + y2\nanalytically is not easy at all.P\n\nage 3 of 196\n\n1.4. IMPORTANT NOTES:\n1.3.2\nTabulated data\nUsually we only have tabulated data when faced with complex real world models, and do not\nhave an explicitly defined function.\nExample 1.3.3\nTo compute the area under the curve defined by the table below\nx\nf(x)\n-3\nwill be analytically impossible since we do not know the explicit definition of f(x) that was\nused to generate the table above. To compute\n\u0002 7\nwill not be possible.\nThe table above was actually generated by f(x) = x2 −4 which we did not know prior, and\ntoo hard to interpolate.\n1.4\nImportant Notes:\n1.) Numerical analysis solution is always numerical.\n2.) Results from numerical analysis is an approximation.\n1.5\nNumerical Errors\nWhen we get into the real world from an ideal world and finite to infinite, errors arise.\n1.5.1\nSources of Errors:\n1.) Mathematical problems involving quantities of infinite precision.\n2.) Numerical methods bridge the precision gap by putting errors under firm control.\n3.) Computer can only handle quantities of finite precision.\n1.5.2\nTypes of Errors:\n1.5.2.1\nTruncation error\nTruncation error is a consequence of doing only a finite number of steps in a calculation that\nwould require an infinite number of steps to do exactly. A simple example of a calculation\nthat will be affected by truncation error is the evaluation of an infinite sum using the NSum\nfunction. The computer certainly isn’t going to compute values for all of the terms in an infinite\nsum. The terms that are left out lead to truncation error.\nTruncation Error: The essence of any numerical method is that it is approximate-this usually\noccurs because of truncation, e.g., cos x ∼= 1 −x2\n2 or terminating an infinite sequence of operations after a finite number have been performed.\nIt is not possible by numerical techniques alone to get an accurate estimate of the size of the\nPage 4 of 196", "word_count": 358, "start_char": 6958, "end_char": 9057}
{"chunk_id": "DOC0132__00004", "doc_id": "DOC0132", "chunk_index": 4, "text": "t is not possible by numerical techniques alone to get an accurate estimate of the size of the\nPage 4 of 196\n\n1.5. NUMERICAL ERRORS\ntruncation error in a result. It is possible for any purely numerical algorithm, including the\nalgorithms used by numerical functions in Mathematica, to produce incorrect results, and to\ndo so without warning. The only way to be certain that results from functions like NIntegrate\nand NDSolve are correct is to do some independent analysis, possibly including detailed investigation of the algorithm that was used to do the calculation. Such investigations are an\nimportant part of the field of numerical analysis.\nFor example, after using Taylor expansion\nex = 1 + x\n1! + x2\n2! + x3\n3! + · · ·\ncos x = 1 −x2\n2! + x4\n4! −x6\n6! + x8\n8! −· · ·\nsin x = x −x3\n3! + x5\n5! −x7\n7! + x9\n9! + · · ·\nYou could realize that there are many terms you have truncated off in the expansion, thats\nwhy · · ·\n1.5.2.2\nRound off errors\nNumbers can be stored only up to a fixed finite number of digits: Additional digits may be\nrounded or chopped. Rounding error is sometimes characterized by ξmachine, the largest (positive) number that the machine (computer) cannot distinguish between 1 and 1+ ξmachine.\nRoundoff error, or representation error, is the error associated with the fact that the computer\nkeeps only a finite number of digits in calculations with inexact numbers. Since it is not possible (except in special cases) to represent all of the digits in numbers like 1/3 or π or\n√\n2,\ncomputers store only the first few digits in numerical approximations of these numbers. In\ntypical situations, the computer will store only the first 16 decimal digits or the first 53 binary\ndigits. The remaining digits are discarded. The discarded digits lead to errors in the result.\nOne of the more conspicuous symptoms of roundoff error is the appearance of tiny non-zero\nnumbers in results that would otherwise be zero.\nAlthough the ability to reduce the effects of roundoff error by raising the precision of a calculation is certainly very useful, it is far from a universal solution to all problems with numerical\nerror.\n1.) 1.8625 to three decimal places, it becomes 1.863\n2.) 1.8625 to two decimal places, it becomes 1.86\n3.) 1.8625 to one decimal place, it become 1.9\n1.5.2.3\nHuman Errors\nSuch as Computing tools/machines, Mathematical equation/model, propagated error.\nPage 5 of 196", "word_count": 424, "start_char": 8949, "end_char": 11347}
{"chunk_id": "DOC0132__00005", "doc_id": "DOC0132", "chunk_index": 5, "text": "age 5 of 196\n\nChapter 2\nNumerical Techniques of Integration\nThere are two main reasons for you to need to do numerical integration: analytical integration\nmay be impossible or infeasible, or you may wish to integrate tabulated data rather than known\nfunctions. In this section we outline the main approaches to numerical integration. Which is\npreferable depends in part on the results required, and in part on the function or data to be\nintegrated.\nThis will be useful when we cannot find an elementary antiderivative for f(x) or if the function\nis defined using data obtained from some experiment.\nNumerical integration is the numerical approximation of the integral of a function.\nFor a\nfunction of one variable, it amounts to finding the area under the graph of the function. That\nis finding I where\nI =\n\u0002 b\na\nf(x) dx\nMethods generally replace the integral by a weighted sum of n weights and n function evaluations, so that\nI =\nn\nX\ni=1\nWif(xi) dx\nFor a function of two variables it is equivalent to finding an approximation to the volume under\nthe surface. Numerical integration is often also referred to as quadrature or sometimes cubature\nfor functions of two or more variables. Returning to the one variable case, numerical integration\ninvolves finding the approximation to an integral of a function f(x) through its evaluation at\na set of discrete points. There are two distinct approaches to this. Firstly methods like the\ntrapezium rule or Simpson’s rule determine the integral through evaluating f(x) at regularly\nspaced points. These are generally referred to as Newton-Cotes formulae.\nAlternative methods termed Gaussian Quadrature methods have arisen that select irregularlyplaced evaluation points, chosen to determine the integral as accurately as possible with a given\nset of points.\nGaussian Quadrature methods are important as they often lead to very efficient methods. In\nnumerical integration the efficiency of the method relates to the accuracy obtained with respect\nto the number of evaluations of the function f(x). In intensive methods such as the boundary\nelement method integrations may need to be performed millions of times so the efficiency of\nthe methods needs to be considered sometimes.", "word_count": 360, "start_char": 11335, "end_char": 13553}
{"chunk_id": "DOC0132__00006", "doc_id": "DOC0132", "chunk_index": 6, "text": "n\nnumerical integration the efficiency of the method relates to the accuracy obtained with respect\nto the number of evaluations of the function f(x).I\n\nn intensive methods such as the boundary\nelement method integrations may need to be performed millions of times so the efficiency of\nthe methods needs to be considered sometimes.\n\n2.1. MANUAL METHOD\n2.1\nManual Method\nIf you were to perform the integration by hand, one approach is to superimpose a grid on\na graph of the function to be integrated, and simply count the squares, counting only those\ncovered by 50% or more of the function. Provided the grid is sufficiently fine, a reasonably\naccurate estimate may be obtained.\n2.2\nTrapezoidal/Trapezium rule\n2.2.1\nComposite Trapezoidal Rule\nTo derive the rule, we use the following figure\nWe divide [a, b] into n equal subintervals, each a Trapezium with width h = (b −a)\nn\nI =\n\u0002 b\na\n\u0002 x1\nx0\nf(x)dx +\n\u0002 x2\nx1\nf(x)dx + . . . +\n\u0002 xi+1\nxi\nf(x)dx + . . . +\n\u0002 xn\nxn−1\nf(x)dx.\nApplying the trapezium equation, we get compute the total areas of all the n trapeziums\nI = h\n2 [f(x0) + f(x1)] + h\n2 [f(x1) + f(x2)] + · · · + h\n2 [f(xn−2) + f(xn−1)] + h\n2 [f(xn−1) + f(xn)]\nI = h\n(2.1)\n2.2.2\nTrapezoidal Rule Truncation Error\nEtrunc = −h3\n12[f ′′(c1) + f ′′(c2) + . . . + f ′′(cn)]\n12n2\n= M(b −a)h2\n(2.2)\nsuch that the second derivative f ′′ is continuous on [a, b] and that\n|f ′′(ξ)| < M ∀ξ ∈[a, b]\n(2.3)\nand\nn\nPage 7 of 196", "word_count": 280, "start_char": 13223, "end_char": 14638}
{"chunk_id": "DOC0132__00007", "doc_id": "DOC0132", "chunk_index": 7, "text": "Example 2.2.1\nI =\n\u0002 1\nx2dx\nusing the composite Trapezoidal rule with step length h = 0.2\nSolution\nSince\nI =\n\u0002 1\nf(x)dx = h\n= h\n2 [f(0) + f(1) + 2 {f(0.2) + f(0.4) + f(0.6) + f(0.8)}]\n= 0.2\n\u0002\n(0)2 + (1)2 + 2\n\b\n(0.2)2 + (0.4)2 + (0.6)2 + (0.8)2 \u0003\n= 0.3400\nAnalytical solution is\n\u0002 1\nx2dx =\n\u0014x3\n\u00151\n= 1\nAbsolute error committed is\n0.340 −1\n≃0.00667\nWe have noted that the error obtained is much smaller than that obtained with the pure\nTrapezoidal rule in the previous example.\nIn fact the smaller the error, i.e the better the\napproximation.\nThe truncation error is\n12n2\n= 2(1)3\n(12)52 = 0.00667\nSince\nf ′′(x) = 2, |f ′′(x)| < 2 on [0, 1]\nExample 2.2.2 Approximate the integral\nI =\n\u0002 2\n−2\ne−x2\n2 dx\nby the composite Trapezoidal rule with h = 1.0, the exact value of the integral I to 4 decimal\nplaces is 2.3925.\nSince h = 1.0, then,\nI = h\n= (1.0)\n\u0014\ne−(−2)2\n+ e−(2)2\n2 + 2\n\u001a\ne−(−1)2\n+ e−(0)2\n2 + e−(1)2\n\u001b\u0015\n= 0.5 [0.13534 + 0.13534 + 2 {0.60653 + 1.00000 + 0.60653}]\n= 2.3484\nwith absolute error of |2.3925 −2.3484| = 0.0441.\nPage 8 of 196\n\nExample 2.2.3\nNumerically estimate\n\u0002 2\nx + 1 dx\nusing\n1.) Trapezium rule\nh\n2[f0 + f1] = 1\n\u00141\n2 + 1\n\u0015\n= 0.416\n2.) Composite Trapezium rule with h = 0.2\nI = h\n≃h\n2 [f(1.0) + f(2.0) + 2 {f(1.2) + f(1.4) + f(1.6) + f(1.8)}]\n≃(0.2)\n\u0014\n1 + 1 +\n1 + 2 + 2\n\u001a\n1 + 1.2 +\n1 + 1.4 +\n1 + 1.6 +\n1 + 1.8\n\u001b\u0015\n≃0.2\n\u00141\n2 + 1\n3 + 2\n\u001a 1\n2.2 + 1\n2.4 + 1\n2.6 + 1\n2.8\n\u001b\u0015\n≃0.4059\nExample 2.2.4 Evaluate\n\u0002 3\n(2x + 3) dx\nby the Trapezium rule with four intervals (5 ordinates).\nI = h\n≃h\n2 [f(0) + f(3.0) + 2 {f(0.75) + f(1.5) + f(2.25)}]\n≃0.75\n[3 + 9 + 2 {4.5 + 6 + 7.5}]\n≃18.0000\nThe classical (analytical, exact) solution is given by\n\u0002 3\n(2x + 3) dx = x2 + 3x", "word_count": 385, "start_char": 14638, "end_char": 16306}
{"chunk_id": "DOC0132__00008", "doc_id": "DOC0132", "chunk_index": 8, "text": "= h\n≃h\n2 [f(0) + f(3.0) + 2 {f(0.75) + f(1.5) + f(2.25)}]\n≃0.75\n[3 + 9 + 2 {4.5 + 6 + 7.5}]\n≃18.0000\nThe classical (analytical, exact) solution is given by\n\u0002 3\n(2x + 3) dx = x2 + 3x\n\n= 18\nTo have the absolute error as\n|18 −18| = 0.0000\nThe truncation error is\n12n2\n= (0)(3)3\n(12)42 = 0.0000\nSince\nf ′′(x) = 0, |f ′′(x)| < 0 for [0, 3]\nExample 2.2.5\nEvaluating\n\u0002 3\nsin x dx by the Trapezium rule with 100 points, it gives the\nanswer as 1.5302437923\nBut can you think of a way of programing this easily??\nPage 9 of 196\n\nExample 2.2.6\n\u0002 3\nsin x2 dx by the Trapezium algorithm\nn\nSum of areas of Trapezoids\n0.43358\n0.70404\n0.75723\n0.76954\n0.77256\n0.77331\n0.77350\n0.77355\n0.77356\n0.77356\n0.77356 appears to be a reasonable estimate of our integral.\nExample 2.2.7\nUsing the Trapezoidal scheme, approximate\n\u0002 1\n√\n2x + 1 dx with h = 0.25.\nx\n0.25\n0.5\n0.75\n√2x + 1\n1.22\n1.41\n1.58\n1.73\nA = h\n= h\n2 [f(0) + f(1) + 2 {f(0.25) + f(0.5) + f(0.75)}] + Etrunc\n≈1\n2(0.25) [1 + 1.73 + 2 {1.22 + 1.41 + 1.58}]\n= 1.39\nAnalytically (the classical or exact value) is\n\u0002 1\n(2x + 1)\n2 dx =\n\u00141\n3(2x + 1)\n\u00151\n= 1.3987\nThe error committed by the Trapezoidal rule is 0.0087\n1.) Repeat the problem with h = 0.2\n2.) Repeat the problem with h = 0.1\nExercise 2.2.1 Compute the approximate value of\n\u0002 1\n(x2 + 1)−1dx by using the Trapezoidal\nrule with ten subintervals. Then compare with the actual value of the integral. Determine the\ntruncation error bound and compare with the actual error.\nExercise 2.2.2\nIf the Trapezoidal rule is used to compute\n\u0002 5\nsin xdx with h = 0.01, obtain\nan upper bound error.\nExercise 2.2.3\nHow large must n be if the Trapezoidal rule is to estimate\n\u0002 2\nexp{−x2} dx\nwith an error not exceeding 10−6?\nPage 10 of 196", "word_count": 350, "start_char": 16125, "end_char": 17833}
{"chunk_id": "DOC0132__00009", "doc_id": "DOC0132", "chunk_index": 9, "text": "xercise 2.2.2\nIf the Trapezoidal rule is used to compute\n\u0002 5\nsin xdx with h = 0.01, obtain\nan upper bound error.E\n\nxercise 2.2.3\nHow large must n be if the Trapezoidal rule is to estimate\n\u0002 2\nexp{−x2} dx\nwith an error not exceeding 10−6?P\n\nage 10 of 196\n\nExample 2.2.8\nNumerically approximate\n\u0002 2\n\u0002\n\u00002√x\n\u0001\u0003\ndx\nby using the Trapezoidal algorithm with\n1.) n = 4 ⇒h = 1\nI = h\n≈1\n2(0.5)\nh\u0010\n√\n0)\n\u0011\n+\n\u0010\n√\n2)\n\u0011\n+\nn\u0010\n√\n0.5)\n\u0011\n+\n\u0010\n√\n1)\n\u0011\n+\n\u0010\n√\n1.5)\n\u0011oi\n≈1\n2(0.5)\nh\n3 + 2 + cos(2\n√\n2) + 2\nh\n√\n2) + (2 + cos 2) + (2 + cos\n√\n6)\nii\n≈3.4971\n2.) n = 8 ⇒h = 1\nI = h\n= 1\nh\u0010\n√\n0)\n\u0011\n+\n\u0010\n√\n2)\n\u0011\n+\nn\u0010\n√\n0.25)\n\u0011\n+\n\u0010\n√\n0.5)\n\u0011\n+\n\u0010\n√\n0.75)\n\u0011\n+\n\u0010\n√\n1)\n\u0011\n+\n\u0010\n√\n1.25)\n\u0011\n+\n\u0010\n√\n1.5)\n\u0011\n+\n\u0010\n√\n1.75)\n\u0011oi\n≈3.4693\n3.) Compute the analytical value of the definite integral.\n4.) Considering your results in part 3.) above, state any two reasons on how to reduce the\nerrors in numerical integration.\nIncreasing the number of subintervals\nAvoiding round off errors by computing final solution at once\nNote 2.2.1\nFor trigonometric functions, the calculator is to be set in radians.\nExercise 2.2.4\nConsider the integral\n\u0002 1\nsin\n\u0012x2\n2 π\n\u0013\ndx. Suppose that we wish to integrate\nnumerically with error < 10−5. What interval width h is needed if the Trapezoidal rule is to\nbe used?\nExample 2.2.9\nHow large should we take n in order to guarantee that the Trapezoidal rule\nused in approximation of the integral\n\u0002 2\nx + 1dx is accurate to within 0.0001.\nPage 11 of 196", "word_count": 320, "start_char": 17580, "end_char": 19000}
{"chunk_id": "DOC0132__00010", "doc_id": "DOC0132", "chunk_index": 10, "text": "hat interval width h is needed if the Trapezoidal rule is to\nbe used?E\n\nxample 2.2.9\nHow large should we take n in order to guarantee that the Trapezoidal rule\nused in approximation of the integral\n\u0002 2\nx + 1dx is accurate to within 0.0001.P\n\nage 11 of 196\n\nUsing the Truncation error of Trapezoidal, (2.2) on page (p. 7). Since\nx + 1 ⇒f ′′(x) =\n(1 + x)3 on [0, 2] ⇒M = 2. Therefore,\n12n2\n= 2(2)3\n12n2 = 0.0001 ⇒n = 115.47 = 115\n■\nExercise 2.2.5\n\u0002 3\nx dx by the Trapezoidal rule with an error of utmost 0.1.\nExample 2.2.10\nFind the area under the curve using trapezoidal rule formula which passes\nthrough the following points:\nx\n0.5\n1.5\ny\nUsing Trapezoidal Rule Formula,\nArea = h\n\u0014\ny0 + yn + 2(y1 + y2 + y3 + ..... + yn−1)\n\u0015\n= 0.5\n\u0014\n5 + 11 + 2(6 + 9)\n\u0015\n= 11.5\nTherefore, the area under the curve is 11.5 sq units.\n■\nExample 2.2.11\nUsing Trapezoidal Rule Formula find the area under the curve y = x2\nbetween x = 0 and x = 4 using the step size of 1.\nArea = h\n\u0014\ny0 + yn + 2(y1 + y2 + y3 + ..... + yn−1)\n\u0015\n= 1\n\u0014\n0 + 16 + 2(1 + 4 + 9)\n\u0015\n= 22\nTherefore, the area under the curve is 22 sq units.\n■\nExample 2.2.12\nFind the area under the curve using the trapezoidal rule formula which\npasses through the following points:\nx\n0.5\n1.5\ny\nThe area under the curve is 13.25 sq units.\n■\nPage 12 of 196", "word_count": 284, "start_char": 18745, "end_char": 20031}
{"chunk_id": "DOC0132__00011", "doc_id": "DOC0132", "chunk_index": 11, "text": "2.3\nSimpson’s Rule\nNote 2.3.1 We can obtain the Simpson’s rule by various ways. One of the most popular ways\nis from Lagrange’s quadratic interpolation polynomial. The Simpson’s rule approximates the\narea under the curve y = f(x) from x0 to x2 by the area under a parabolic curve.\nInterpolating f(x) by a Lagrange polynomial of degree 2 i.e. P2(x) then\nf(x) = P2(x) + Etrunc(x)\nSo\n\u0002 x2\nx0\n\u0002 x2\nx0\nP2(x)dx +\n\u0002 x2\nx0\nEtrunc(x)dx\n(2.4)\nResults\nSumming up all the three cases, equation (2.4) becomes\n\u0002 x2\nx0\nP2(x)dx = h\n3[f0 + 4f1 + f2] + Etrunc(x)\nThus\n\u0002 x2\nx0\nP2(x)dx = h\n3[f0 + 4f1 + f2]\n(2.5)\nRelation equation (2.5) is the Simpson’s rule for approximating the integral. The integral\nfor the error in equation (2.4), becomes\n\u0002 x2\nx0\nEtrunc(x)dx =\n\u0002 x2\nx0\n(x −x0)(x −x1)(x −x2)\n3!\nf (4)(c(x))dx\nThis can be shown (with difficulty!, for n = 2) to be\n−Mh5\n= −1\n90M\n\u0012b −a\n\u00135\nThat the fourth derivative f 4 is continuous on [a, b] and that |f 4(x)| < M for all x in [a, b].\nExample 2.3.1\nUse Simpson’s rule (n = 2) to approximate the integral I =\n\u0002 1\nx2dx.\nSolution Since\nI =\n\u0002 1\nf(x)dx ≃h\n3[f(x0) + 4f(x1) + f(x2)]\nBut\nx0 = 0,\nx1 = 1\n2,\nx2 = 1,\nh = (1 −0)\n= 1\n2.\nTherefore\nI ≃1\n\u0014\nf(0) + 4f\n\u00121\n\u0013\n+ f(1)\n\u0015\n= 1\n\"\n02 + 4\n\u00121\n\u00132\n+ 12\n#\n= 1\n3 = 0.33\nBut the exact value of the integral is 1\n3 = 0.333. It should not surprise you that the Simpson”\nrule has generated the exact value of the integral. In fact the general result is that for f(x) a\npolynomial of degree two or less, the Simpson” rule will always generate the exact value of the\nintegral. This will later be stated as a theorem.\nPage 13 of 196", "word_count": 338, "start_char": 20031, "end_char": 21625}
{"chunk_id": "DOC0132__00012", "doc_id": "DOC0132", "chunk_index": 12, "text": "t should not surprise you that the Simpson”\nrule has generated the exact value of the integral.I\n\nn fact the general result is that for f(x) a\npolynomial of degree two or less, the Simpson” rule will always generate the exact value of the\nintegral.T\n\nhis will later be stated as a theorem.P\n\nage 13 of 196\n\n2.3.1\nComposite Simpson’s 1/3 Rule\nThe composite Simpson’s 1/3 rule is commonly referred to as the Simpson’s rule.\nDefinition 2.3.1 Simpson’s 1/3 rule: The Simpson’s algorithm for a definite integral\n\u0002 b\na\nis given by\n\u0001 b\na f(x) dx ≈h\n\u0014\nf(x0) + 4f(x1) + 2f(x2) + 4f(x3) + 2f(x4) + 4f(x5) + 2f(x6) + · · · + 2f(xn−2) + 4f(xn−1) + f(xn)\n\u0015\n(2.6)\n\u0001 b\na f(x) dx = h\n\u0014\nf(x0) + 2 Pn/2−1\nj=1\nf(x2j) + 4 Pn/2\nj=1 f(x2j−1) + f(xn)\n\u0015\n(2.7)\nRemark 2.3.1 Simpson’s 1/3 rule: After first and last points, others take on coefficients (4, 2)\nrepeatedly till second last point.\nAlternatively, the expansion of (2.7) gives or factorisation of (2.6):\nA = h\n\u0014\nf(x0) + f(xn) + 2\n\u001a\nf(x2) + f(x4) + . . . + f(x2n−2)\n\u001b\n+ 4\n\u001a\nf(x1) + f(x3) + . . . + f(x2n−1)\n\u001b\u0015\n+ ET\n(2.8)\nRemark 2.3.2\nSimpson’s 1/3 rule requires an even number of subintervals.\nRemark 2.3.3\nSimpson’s 1/3 rule: After first and last points, others take on coefficients\n(4, 2, 4, 2, . . .) repeatedly till second last point.\n2.3.2\nSimpson’s Rule Truncation Error\nThe truncation error in Simpson’s rule is given by\nEtrunc = −h5\n90[f (4)(c1) + f (4)(c2) + . . . + f (4)(cn)] = −h5\n90f (4)(c2) × n = −(b −a)h4\nf (4) (ξ)\nwhere a ≤ξ ≤b. Therefore\nEtrunc = (b −a)h4\nf (4) (ξ) , ξ ∈[a, b]\n(2.9)\nAlternatively, the truncation error is given by\nEtrunc = (b −a)5\n180n4 f (4) (ξ) , ξ ∈[a, b]\nsince\nn\nPage 14 of 196", "word_count": 335, "start_char": 21320, "end_char": 22971}
{"chunk_id": "DOC0132__00013", "doc_id": "DOC0132", "chunk_index": 13, "text": "herefore\nEtrunc = (b −a)h4\nf (4) (ξ) , ξ ∈[a, b]\n(2.9)\nAlternatively, the truncation error is given by\nEtrunc = (b −a)5\n180n4 f (4) (ξ) , ξ ∈[a, b]\nsince\nn\nPage 14 of 196\n\nExample 2.3.2\nUse S2 to approximate\n\u0002 1\nx3 dx. Estimate a bound for the error in S2.\nSince [0,1] is divided into two subintervals S2, each subinterval has\nlength ∆x = 1 −0\n= 1\n2. The endpoints of these subintervals are\n\u001a\n0, 1\n2, 1\n\u001b\n. If we\nset f(x) = x3, then\nS2 = 1\n3 · 1\n\u0014\nf(0) + 4 f\n\u00121\n\u0013\n+ f(1)\n\u0015\n= 1\n\u0012\n0 + 4 · 1\n8 + 1\n\u0013\n= 1\n4.\nSince f (4)(x) = 0 and consequently we see that\nEtrunc ≤(b −a)h4\n(0) = 0\nThis bound indicates that the value obtained through Simpson’s rule is exact. A\nquick check will verify that, in fact,\n\u0002 1\nx3 dx = 1\n4.\n■\nExample 2.3.3\n\u0002 2\n√\n1 + exdx using Simpson’s rule by taking n = 4.\nn\n= 2 −0\n= 0.5\nSo the 4 subintervals are [0, 0.5], [0.5, 1], [1, 1.5], and [1.5, 2].\n\u0002 2\n√\n1 + exdx\n≈0.5\n\u0014\nf (0) + 4f (0.5) + 2f (1) + 4f(1.5) + f(2)\n\u0015\n= 0.5\n\u0012\n1.414213562 + 6.509957014 + 3.85656937+\n+ 9.36520288 + 2.896386731\n\u0013\n= 4.0070549278\n■\nRemark 2.3.4\nThe composite Simpson’s rule is commonly referred to as the Simpson’s rule.\nPage 15 of 196", "word_count": 261, "start_char": 22801, "end_char": 23932}
{"chunk_id": "DOC0132__00014", "doc_id": "DOC0132", "chunk_index": 14, "text": "age 15 of 196\n\nExample 2.3.4\nUse the Simpson’s method to compute the integral\nI =\n\u0002 2\n−2\ne−x2\n2 dx\nUsing step size h = 1.0. Recall the exact value of I to 4 decimal places is 2.3925.\nUsing the Simpson’s rule with h = 1.0\n⇒\nn = 4, an even number of subintervals, using\nEquation (2.8), we have,\nI = h\nI ≃1.0\n\u0014\ne−(−2)2\n+ e−(2)2\n2 + 2\n\u001a\ne−(0)2\n\u001b\n+ 4\n\u001a\ne−(−1)2\n+ e−(1)2\n\u001b\u0015\nI ≃2.3743\nThe absolute error committed is |2.3925 −2.3743| = 0.0182. We note that the error is much\nsmaller than that obtained when using Trapezoidal rule in the Example 2.2.2 on page (p. 8)\nthough same step size is used.\nNote 2.3.2\nSimpson’s rule (2.8) only work for even number of subintervals.\nExample 2.3.5\nDetermine the definite integral\n\u0002 2\nx dx using Simpson with n = 6.\n\u0002 2\nx dx = h\n3 [f(x0) + f(xn) + 2 {f(x2) + f(x4) + . . . + f(x2n−2)} + 4 {f(x1) + f(x3) + . . . + f(x2n−1)}] +\n≈1\n\u0014\n1 + 1\n2 + 2\n\u001a3\n4 + 3\n\u001b\n+ 4\n\u001a6\n7 + 2\n3 + 6\n\u001b\u0015\n≈14411\n20790 ≈0.6931697\nExample 2.3.6\n\u0002 3\ndx\nx + 1 using Simpson’s rule with n = 4.\n\u0002 3\ndx\nx + 1 = h\n3 [f(x0) + f(xn) + 2 {f(x2) + f(x4) + . . . + f(x2n−2)} + 4 {f(x1) + f(x3) + . . . + f(x2n−1)}]\n≈0.25\n[f(2) + f(3) + 2 {f(2.5)} + 4 {f(2.25) + f(2.75)}]\n≈0.25\n\u00141\n3 + 1\n4 + 2\n\u001a 1\n3.5\n\u001b\n+ 4\n\u001a 1\n3.25 +\n3.75\n\u001b\u0015\n≈0.2876831\n1.) Compute its exact value and hence the error committed\n\u0002 3\ndx\nx + 1 = ln(x + 1)|3\n2 = 0.287682\n⇒Absolute error = |0.287682 −0.2876831| ≈0.00036\n2.) Repeat the problem above using h = 0.1.\n3.) Comment on the effect of h on the numerical solutions.\n4.) Repeat the problem using the Trapezoidal rule.\nWhich of the two techniques is more\naccurate?\nPage 16 of 196", "word_count": 362, "start_char": 23919, "end_char": 25506}
{"chunk_id": "DOC0132__00015", "doc_id": "DOC0132", "chunk_index": 15, "text": "hich of the two techniques is more\naccurate?P\n\nage 16 of 196\n\nNote 2.3.3 For f(x) a trigonometric function, we use (Your calculator should be in) Radians.\nExample 2.3.7\nIt is required to obtain\n\u0002 2\nex2dx exact to 4 decimal places. What should h\nbe for Simpson’s rule.\nSince the error term is −(b −a)\nh4f (4) (ξ), with f(x) = ex2, then\nf ′(x) = 2xex2\nf ′′(x) = 2(ex2 + 2xex2) = 2ex2(1 + 2x2) = ex2(2 + 4x2)\nf ′′′(x) = 2xex2(2 + 4x2) + 8xex2\n= ex2(4x + 8x3 + 8x)\n= ex2(12x + 8x3)\nf (iv)(x) = 8ex2(2x4 + 5x2 + 1)\n< 424e4\nSo\n−(b −a)\nh4f (4) (ξ) = 2h4\n\u0000424e4\u0001\n< (0.5)10−4\nto have h < 0.057, say choose h = 0.05.\nExercise 2.3.1 Compute an approximate value of\n\u0002 1\n(x2+1)−1dx using Composite Simpson’s\nrule with\n1.) h = 0.1\nCompare with the actual value of the integral in each case. Next, determine the truncation\nerror bound and compare with the actual error.\nExercise 2.3.2 If the Simpson’s rule is used to compute\n\u0002 5\nsin xdx with h = 0.75, obtain an\nupper bound on the error.\nExercise 2.3.3\nEstablish the composite Simpson’s rule over (n −1) even subintervals\n\u0002 b\na\nf(x)dx = h\n3[(f(a) + f(b)) + 4\n(n−1)\nX\ni=1\nf(a + (2i −1)h) + 2\n(n−3)\nX\ni=1\nf(a + 2ih)] + Etrunc\nwhere, h = (b −a)\n(n −1) and Etrunc = −(b −a)\nh4f (4)(ξ) for some ξ ∈[a, b].\nExercise 2.3.4\nConsider the integral\n\u0002 1\nsin\n\u0012πx2\n\u0013\ndx. Suppose that we wish to integrate\nnumerically with error < 10−5. What interval width h is needed if the Simpson’s rule is to be\nused?\nExercise 2.3.5\nCompute\n\u0002 2\n(x3 + 1)dx by using h = 1\n4 and compare with the exact value of\nthe integral.\nPage 17 of 196", "word_count": 320, "start_char": 25446, "end_char": 26992}
{"chunk_id": "DOC0132__00016", "doc_id": "DOC0132", "chunk_index": 16, "text": "uppose that we wish to integrate\nnumerically with error < 10−5.W\n\nhat interval width h is needed if the Simpson’s rule is to be\nused?E\n\nxercise 2.3.5\nCompute\n\u0002 2\n(x3 + 1)dx by using h = 1\n4 and compare with the exact value of\nthe integral.P\n\nage 17 of 196\n\nExample 2.3.8\n1.) Solve the integral\n\u0002 2\n\u0002\n\u00002√x\n\u0001\u0003\ndx in Example 2.2.8 on page (p.\n11) using the\nSimpson’s algorithm with n = 4.\nI = h\n≈1\nh\u0010\n√\n0)\n\u0011\n+\n\u0010\n√\n2)\n\u0011\n+ 2\nn\u0010\n√\n1)\n\u0011o\n+4\nn\u0010\n√\n0.5)\n\u0011\n+\n\u0010\n√\n1.5)\n\u0011oi\n≈1\nh\n3 + 2 + cos(2\n√\n2) + 2 {(2 + cos 2)} + 4\nn\n√\n2) + (2 + cos\n√\n6)\noi\n≈1\nh\n5 + cos(2\n√\n2) + 2 {(2 + cos 2)} + 4\nn\n√\n2) + (2 + cos\n√\n6)\noi\n≈3.46008250981\n≈3.46008\n2.) Show that using the Simpson’s scheme with n = 8, the integral is I ≈3.46000.\nI = h\n≈1\nh\u0010\n√\n0)\n\u0011\n+\n\u0010\n√\n2)\n\u0011\n+2\nn\u0010\n√\n0.5)\n\u0011\n+\n\u0010\n√\n1)\n\u0011\n+\n\u0010\n√\n1.5)\n\u0011o\n+4\nn\u0010\n√\n0.25)\n\u0011\n+\n\u0010\n√\n0.75)\n\u0011\n+\n\u0010\n√\n1.25)\n\u0011\n+\n\u0010\n√\n1.75)\n\u0011oi\n≈3.460002979\n≈3.46000\n3.) The classical value is given by\n\u0002 2\n\u0002\n\u00002√x\n\u0001\u0003\ndx = 2x + (0.5) cos\n\u00002√x\n\u0001\n+ √x sin\n\u00002√x\n\u0001\n= 3.46000\n4.) What is the effect of the size of n, the number of subintervals? The more the subintervals,\nthe more accurate the numerical approximations.\n5.) Which of the two numerical schemes is more superior? The Simpson’s rule is more accurate\ncompared to the Trapezoidal method that estimated the definite integral to\n(a) I = 3.4971 for n = 4, and\n(b) I = 3.4693 for n = 8\nas computed in Example 2.2.8 on page (p. 11).\nPage 18 of 196\n\nExample 2.3.9 Evaluate\n\u0002 4\n\u00001 + x2\u0001\ndx with n = 4, using\n1.) Classical techniques\n\u0002 4\n\u00001 + x2\u0001\ndx = x + x3", "word_count": 363, "start_char": 26737, "end_char": 28233}
{"chunk_id": "DOC0132__00017", "doc_id": "DOC0132", "chunk_index": 17, "text": "age 18 of 196\n\nExample 2.3.9 Evaluate\n\u0002 4\n\u00001 + x2\u0001\ndx with n = 4, using\n1.) Classical techniques\n\u0002 4\n\u00001 + x2\u0001\ndx = x + x3\n\n= 76\n3 ≈25.3333\n2.) Simpson’s scheme formula for even number of subintervals, Equation (2.8)\nI = h\n≈1\n\u0014\nf(0) + f(4) + 2 {f(2)} + 4 {f(1) + f(3)}\n\u0015\n≈1\n\u0014\n1 + 17 + 2 {5} + 4 {2 + 10}\n\u0015\n≈76\n≈25.3333\nHaving used the correct formula, the Simpson’s approximation is very close, if not equal to\nthe analytical, exact solutions in part 1.) above.\n3.) Trapezoidal method\nI = h\n≈1\n\u0014\nf(0) + f(4) + 2 {f(1) + f(2) + f(3)}\n\u0015\n≈1\n\u0014\n1 + 17 + 2 {2 + 5 + 10}\n\u0015\n≈52\n≈26.0000\nRemark 2.3.5\nThe inferior Trapezoidal algorithm 3.) generate a less accurate solution compared to Simpson rule formula in 2.) which is a superior method.\nPage 19 of 196\n\nExample 2.3.10\n\u0002 2\nex3dx using Simpson’s rule by taking n = 4.\nn\n= 2 −1\nSo the 4 subintervals are [1, 1.25], [1.25, 1.5], [1.5, 1.75], and [1.75, 2].\n\u0002 2\n≈0.25\n[f (1) + 4f (1.25) + 2f (1.5) + 4f(1.75) + f(2)]\n3 (2.71828182845905 + 28.2027463392796\n+ 58.4485675624699 + 850.36813958881\n+ 2980.95798704173)\n= 326.724643530062\n■\nExample 2.3.11\n\u0002 2\nsin √x dx using Simpson’s rule by taking n = 8.\nn\n= 2 −0\nSo the 8 sub-intervals are [0, 0.25], [0.25, 0.5], [0.5, 0.75], [0.75, 1], [1, 1.25], [1.25, 1.5], [1.5, 1.75],\nand [1.75, 2].\n\u0002 2\n≈0.25\n[f (0) + 4f (0.25) + 2f (0.5) + 4f (0.75) + 2f (1) + 4f (1.25) + 2f (1.5) + 4f(1.75) + f(2)]\n3 (0 + 1.91770215441681 + 1.29927387816012\n+ 3.04703992566516 + 1.68294196961579\n+ 3.59696858641514 + 1.88143866748289\n+ 3.87769904361669 + 0.987765945992735)\n= 1.52423584761378\n■\nPage 20 of 196", "word_count": 316, "start_char": 28112, "end_char": 29686}
{"chunk_id": "DOC0132__00018", "doc_id": "DOC0132", "chunk_index": 18, "text": "Example 2.3.12\nUsing Trapezoidal rule compute the integral\n1\u0001\nex2dx, where the table for\nthe values of y = ex2 is given below:\nx\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\ny\n1.00000\n1.01005\n1.04081\n1.09417\n1.17351\n1.28402\n1.43332\n1.63231\n1.89648\n2.2479\n2.71\nHere, h = 0.1, n = 10,\ny0 + y10\n= 1.0 + 2.71828\n= 1.85914,\nand\nX\ni=1\nyi = 12.81257.\nsuch that the area by Trapezoidal’s rule is given by\nA = h\n2 [y0 + y10 + 2 {y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9}]\nA = h\n\u0014y0 + y10\n+ {y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9}\n\u0015\nThus,\n\u0002\nex2dx = 0.1 × [1.85914 + 12.81257] = 1.467171\n■\nExample 2.3.13\nUsing the table for the values of y = ex2 as is given in Example 2.3.12,\ncompute the integral\n1\u0001\nex2dx, by Simpson’s rule.\nHere, h = 0.1, n = 10, thus we have an even number of subintervals.\nFurther,\ny0 + y10 = 1.0 + 2.71828 = 3.71828,\nX\ni=1, i−odd\nyi = y1 + y3 + y5 + y7 + y9 = 7.26845,\nX\ni=2, i−even\nyi = y2 + y4 + y6 + y8 = 5.54412.\nsuch that the area by Simpson’s rule is given by\nA = h\n3 [y0 + y10 + 2 {y2 + y4 + y6 + y8} + 4 {y1 + y3 + y5 + y7 + y9}]\nThus,\n\u0002\nex2dx = 0.1\n3 × [3.71828 + 2 × 5.54412 + 4 × 7.268361] = 1.46267733\n■\nPage 21 of 196", "word_count": 282, "start_char": 29686, "end_char": 30831}
{"chunk_id": "DOC0132__00019", "doc_id": "DOC0132", "chunk_index": 19, "text": "Example 2.3.14 Compute the integral\n1\u0001\n0.05\nf(x)dx , where the table for the values of y = f(x)\nis given below:\nx\n0.05\n0.1\n0.15\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\ny\n0.0785\n0.1564\n0.2334\n0.3090\n0.4540\n0.5878\n0.7071\n0.8090\n0.8910\n0.9511\n0.9877\n1.000\nNote that here the points are not given to be equidistant, so as\nsuch we can not use any of the above two formulae. However, we notice that the\ntabular points 0.05, 0.10, 0, 15 and 0.20 are equidistant and so are the tabular points\n0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 and 1.0 . Now we can divide the interval in two\nsubinterval: [0.05, 0.2] and [0.2, 1.0] ; thus,\n\u0002\n0.05\n0.2\n\u0002\n0.05\nf(x)dx +\n\u0002\n0.2\nf(x)dx.\nThe integrals then can be evaluated in each interval. We observe that the second set\nhas odd number of points (even subintervals). Thus, the first integral is evaluated by\nusing Trapezoidal rule and the second one by Simpson’s rule (of course, one could\nhave used Trapezoidal rule in both the subintervals).\nFor the first integral h = 0.05 and for the second one h = 0.1. Thus, first part by\nTrapezoidal scheme,\n0.2\n\u0002\n0.05\nf(x)dx = 0.05\n× [0.0785 + 0.3090 + 2 (0.1564 + 0.2334)] = 0.0291775,\nand, second part by Simpson’s rule,\n1.0\n\u0002\n0.2\nf(x)dx = 0.1\n3 × [(0.3090 + 1.0000) + 2 × (0.5878 + 0.8090 + 0.9511)\n+4 × (0.4540 + 0.7071 + 0.8910 + 0.9877)]\n= 0.6054667,\nwhich gives,\n\u0002\n0.05\nf(x)dx = 0.0291775 + 0.6054667 = 0.6346442\nIt may be mentioned here that in the above integral, f(x) = sin\n\u0010π\n2 x\n\u0011\nand that the\nvalue of the integral is 0.6346526 . It will be interesting for the reader to compute\nthe two integrals using Trapezoidal rule and compare the values.\n■\nPage 22 of 196", "word_count": 317, "start_char": 30831, "end_char": 32466}
{"chunk_id": "DOC0132__00020", "doc_id": "DOC0132", "chunk_index": 20, "text": "t will be interesting for the reader to compute\nthe two integrals using Trapezoidal rule and compare the values.\n■\nPage 22 of 196\n\n2.4\nMid-Point Rule\nIf f is continuous on [a, b] and f(x) ≥0 ∀x ∈(a, b), we partition [a, b] into n subintervals of\nequal lengths.\nDefinition 2.4.1\nIf mi is the midpoint of the ith interval then\n\u0002 b\na\nn\nX\ni=1\n(∆xi)f(mi)\n(2.10)\nExample 2.4.1\n\u0002\nq\nsin4 (x) + 7 dx\nwith\nn = 4\nusing the midpoint rule.\nThe midpoint rule (also known as the midpoint approximation) uses\nthe midpoint of a subinterval for computing the height of the approximating rectangle:\nb\u0001\na\nf(x) dx ≈∆x\n\u0014\nf\n\u0000 x0+x1\n\u0001\n+ f\n\u0000 x1+x2\n\u0001\n+ f\n\u0000 x2+x3\n\u0001\n+ · · · + f\n\u0000 xn−2+xn−1\n\u0001\n+ f\n\u0000 xn−1+xn\n\u0001\u0015\nwhere\n∆x = b −a\nn\nWe have that\nq\nsin4 (x) + 7\na = 1\nb = 3\nand\nn = 4\n∆x = 3 −1\n= 1\nDivide the interval\n[1, 3]\ninto\nn = 4\nsubintervals of the length\n∆x = 1\nwith the following endpoints:\na = 1\nPage 23 of 196", "word_count": 201, "start_char": 32337, "end_char": 33223}
{"chunk_id": "DOC0132__00021", "doc_id": "DOC0132", "chunk_index": 21, "text": "3 = b\nNow, just evaluate the function at the midpoints of the subintervals.\nf\n\u0013\n= f\n\u00121 + 3\n\u0013\n= f\n\u00125\n\u0013\n=\ns\nsin4\n\u00125\n\u0013\n+ 7 ≈2.794821922941848\nf\n\u0013\n= f\n\u0012 3\n2 + 2\n\u0013\n= f\n\u00127\n\u0013\n=\ns\nsin4\n\u00127\n\u0013\n+ 7 ≈2.817350905627184\nf\n\u0013\n= f\n\u00122 + 5\n\u0013\n= f\n\u00129\n\u0013\n=\ns\nsin4\n\u00129\n\u0013\n+ 7 ≈2.714130913751178\nf\n\u0012x3 + x4\n\u0013\n= f\n\u0012 5\n2 + 3\n\u0013\n= f\n\u001211\n\u0013\n=\ns\nsin4\n\u001211\n\u0013\n+ 7 ≈2.649758163512828\nFinally, just sum up the above values and multiply by\n∆x = 1\n2 :\n\u0014\n2.794821922941848 + 2.817350905627184 + 2.714130913751178 + 2.649758163512828\n\u0015\n= 5.488030952916519\nTherefore\n\u0002\nq\nsin4 (x) + 7 dx ≈5.488030952916519\n■\nExample 2.4.2\nFind the integral using the midpoint rule\n\u0002 2\nxdx with n = 10\nThe step width is given by ∆xi = 2 −1\n= 1\n10 such that f(x) = 1\nx ⇒f(mi) = 1\nmi\n\u0002 2\nxdx = ∆x\nn\nX\ni=1\nf(mi)\n= 1\n10 [f(1.05) + f(1.15) + f(1.25) + f(1.35) + · · · + f(1.75) + f(1.85) + f(1.95)]\n= 1\n\u0014 1\n1.05 +\n1.15 +\n1.25 +\n1.35 +\n1.45 +\n1.55 +\n1.65 +\n1.75 +\n1.85 +\n1.95\n\u0015\n= 0.69284\nNote 2.4.1 The Mid-point algorithm is the Riemann sum at mid point, not the upper (right\nend) Riemann and not the lower (left end) Riemann sum.\nPage 24 of 196", "word_count": 261, "start_char": 33223, "end_char": 34300}
{"chunk_id": "DOC0132__00022", "doc_id": "DOC0132", "chunk_index": 22, "text": "age 24 of 196\n\n2.4.1\nMid-Point Truncation Error\nIf\n|f ′′ (ξ) | < M , ∀ξ ∈[a, b]\nthen the truncation error in the Mid-point scheme is given by\nEtrunc = M(b −a)3\n24n2\n(2.11)\nExample 2.4.3 The exact solution for\n\u0002 1\ncos xdx = sin 1 ≈0.8414709848. For different step\nlength h = ∆x, show the Mid-Point rule results below:\nh\nIMidpoint(h)\nAbsolute Error\n0.500000\n0.85030065\n8.8 × 10−3\n0.250000\n0.84366632\n2.2 × 10−3\n0.125000\n0.84201907\n5.5 × 10−4\n0.062500\n0.84160796\n1.4 × 10−4\n0.031250\n0.84150523\n3.4 × 10−5\n0.015625\n0.84147954\n8.6 × 10−6\n0.007813\n0.84147312\n2.1 × 10−6\n0.003906\n0.84147152\n5.3 × 10−7\n0.001953\n0.84147112\n1.3 × 10−7\n0.000977\n0.84147102\n3.3 × 10−8\nExample 2.4.4 Use the midpoint rule to estimate\n\u0002 1\nx2 dx using four subintervals. Compare\nthe result with the actual value of this integral.\nEach subinterval has length ∆x = 1 −0\n= 1\n4. Therefore, the subintervals consist of\n\u0014\n0, 1\n\u0015\n,\n\u00141\n4, 1\n\u0015\n,\n\u00141\n2, 3\n\u0015\n, and\n\u00143\n4, 1\n\u0015\n.\n\u001a1\n8, 3\n8, 5\n8, 7\n\u001b\nM4 = 1\n4 · f\n\u00121\n\u0013\n+ 1\n4 · f\n\u00123\n\u0013\n+ 1\n4 · f\n\u00125\n\u0013\n+ 1\n4 · f\n\u00127\n\u0013\n= 1\n4 · 1\n4 · 9\n4 · 25\n4 · 49\n= 21\n64 = 0.328125.\nSince\n\u0002 1\nx2 dx = 1\n3,\nthe absolute error in this approximation is:\n\n3 −21\n=\n192 ≈0.0052,\nPage 25 of 196", "word_count": 259, "start_char": 34287, "end_char": 35458}
{"chunk_id": "DOC0132__00023", "doc_id": "DOC0132", "chunk_index": 23, "text": "ince\n\u0002 1\nx2 dx = 1\n3,\nthe absolute error in this approximation is:\n\n3 −21\n=\n192 ≈0.0052,\nPage 25 of 196\n\nand we see that the midpoint rule produces an estimate that is somewhat close to\nthe actual value of the definite integral.\n■\nExample 2.4.5\nUse the midpoint rule with n = 2 to estimate\n\u0002 2\nx dx.\n■\nExample 2.4.6\n\u0002\n√\n2x + 1 dx\nwith\nn = 4\nusing the midpoint rule.\nThe midpoint rule (also known as the midpoint approximation) uses\nthe midpoint of a subinterval for computing the height of the approximating rectangle:\nb\u0001\na\nf (x) dx ≈∆x\n\u0014\nf\n\u0013\n+ f\n\u0013\n+ f\n\u0013\n+ · · · + f\n\u0012xn−2 + xn−1\n\u0013\n+ f\n\u0012xn−1 + xn\n\u0013 \u0015\nwhere\n∆x = b −a\nn\nWe have that\n√\n2x + 1, a = 0, b = 1, n = 4\n∆x = 1 −0\nDivide the interval [0, 1] into n = 4 subintervals of the length ∆x = 1\n4 with the\nfollowing endpoints:\na = 0, 0.25, 0.5, 0.75, 1 = b\nNow, find the function at the midpoints of the subintervals.\nf\n\u0013\n= f\n\u00120 + 0.25\n\u0013\n= f (0.125) =\n√\n20.125 + 1 = 1.11803398874989\nf\n\u0013\n= f\n\u00120.25 + 0.5\n\u0013\n= f (0.375) =\n√\n20.375 + 1 = 1.32287565553230\nf\n\u0013\n= f\n\u00120.5 + 0.75\n\u0013\n= f (0.625) =\n√\n20.625 + 1 = 1.50000000000000\nf\n\u0012x3 + x4\n\u0013\n= f\n\u00120.75 + 1\n\u0013\n= f (0.875) =\n√\n20.875 + 1 = 1.65831239517770\nFinally, just sum up the above values and multiply by ∆x = 1\n4 = 0.25\n0.25(1.11803398874989 + 1.32287565553230 + 1.50000000000000 + 1.65831239517770)\n= 1.39980550986497\nPage 26 of 196\n\n\u0002\n√\n2x + 1 dx ≈1.399805509864973\n■\nPage 27 of 196\n\n2.5\nComparison of the Numerical Integration Techniques\n2.5.1\nTruncation Errors Comparisons\n1.) Error bound for midpoint rule\nEM ≤M(b −a)3\n24n2\nwhere M is the maximum value of |f ′′(x)| over [a, b].\n2.) Error bound for trapezoidal rule\nET ≤M(b −a)3\n12n2\nwhere M is the maximum value of |f ′′(x)| over [a, b].\n3.) Error bound for Simpson’s rule\nES ≤M(b −a)5\n180n4\nwhere M is the maximum value of\nf (4)(x)\nover [a, b].\nExample 2.5.1\nDetermine the Midpoint rule truncation error in approximating\n\u0002 π\nsin x dx\n1.) The integral\n\u0002 π\nsin x dx has b −a = π.\n2.) The second derivative of the integrand satisfies", "word_count": 430, "start_char": 35355, "end_char": 37336}
{"chunk_id": "DOC0132__00024", "doc_id": "DOC0132", "chunk_index": 24, "text": "xample 2.5.1\nDetermine the Midpoint rule truncation error in approximating\n\u0002 π\nsin x dx\n1.) The integral\n\u0002 π\nsin x dx has b −a = π.\n2.) The second derivative of the integrand satisfies\n\nd2\ndx2 sin x\n= | −sin x| ≤1\nSo we take M = 1.\n3.) So the error, EM, introduced when n steps are used is bounded by\n|EM(n)| ≤M\nn2\n= π3\nn2\n≈1.29 1\nn2\n■\nPage 28 of 196\n\nExample 2.5.2\nWhat value of n should be used to guarantee that an estimate of\n\u0002 1\nis accurate to within 0.01 if we use the midpoint rule?\nWe begin by determining the value of M, the maximum value of\n|f ′′(x)| over [0, 1] for f(x) = ex2. Since f ′(x) = 2xex2, we have\nf ′′(x) = 2ex2 + 4x2ex2.\nThus,\n|f ′′(x)| = 2ex2(1 + 2x2) ≤2 · e · 3 = 6e.\nFrom the error-bound Equation, we have the error in Mn\nEM ≤M(b −a)3\n24n2\n≤6e(1 −0)3\n24n2\n=\n6e\n24n2.\nNow we solve the following inequality for n (accurate to within 0.01):\n6e\n24n2 ≤0.01\nThus,\nn ≥\nr\n600e\n≈8.24.\nSince n must be an integer satisfying this inequality, a choice of n = 9 would guarantee that\n\n\u0002 1\nex2 dx −Mn\n< 0.01.\n■\nExample 2.5.3 Use Equation (truncation error) to find an upper bound for the error in using\nM4 (Midpoint rule with 4 steps) to estimate\n\u0002 1\nx2 dx.\nf ′′(x) = 2, so M = 2 such that\nEM =\n■\nExample 2.5.4\nEstimate a bound for the error in Simpson’s rule in approximating\n\u0002 1\nx3 dx\nwith n = 2.\nSince f (4)(x) = 0 and consequently M = 0, we see that\nES ≤\n0(1)5\n180 · 24 = 0.\nThis bound indicates that the value obtained through Simpson’s rule is exact.\n■\nPage 29 of 196", "word_count": 322, "start_char": 37152, "end_char": 38636}
{"chunk_id": "DOC0132__00025", "doc_id": "DOC0132", "chunk_index": 25, "text": "ince f (4)(x) = 0 and consequently M = 0, we see that\nES ≤\n0(1)5\n180 · 24 = 0.T\n\nhis bound indicates that the value obtained through Simpson’s rule is exact.\n■\nPage 29 of 196\n\nExercise 2.5.1\nLet f(x) = −1\n12x4 + 7\n6x3 −3x2.\n1.) Find a reasonable value M such that |f ′′(x)| ≤M for all 1 ≤x ≤6.\n2.) Find a reasonable value M such that |f (4)(x)| ≤M for all 1 ≤x ≤6.\nExercise 2.5.2 Let f(x) = x sin x+2 cos x. Find a reasonable value M such that |f ′′(x)| ≤M\nfor all −3 ≤x ≤2.\nExercise 2.5.3\nConsider the quantity\nA =\n\u0002 π\n−π\ncos x dx.\nFind the upper bound on the error using Simpson’s rule with n = 4 to approximate A.\nExercise 2.5.4\nGive a function f(x) such that:\n• f ′′(x) ≤3 for every x in [0, 1], and\n• the error using the trapezoidal rule approximating\n\u0002 1\nf(x) dx with n = 2 intervals is exactly\n16.\nExercise 2.5.5\nTrue or False: for fixed positive constants M, n, a, and b, with b > a,\nM\nn2\n≤M\nn2\nExercise 2.5.6\nTrue or False: for a function f(x) and fixed constants n, a, and b, with\nb > a, the n-interval midpoint approximation of\n\u0002 b\na\nf(x) dx is more accurate than the n-interval\ntrapezoidal approximation.\nPage 30 of 196\n\n2.5.2\nNumerical Solutions Comparison\nExample 2.5.5\n\u0002 1\n1 + x2 dx using the midpoint rule with n = 8 subintervals.\n1.) First we set up all the x-values that we will need. Note that a = 0, b = 1, ∆x =\n8 and\nx0 = 0\nx1 = 1\nx2 = 2\n· · ·\nx7 = 7\nx8 = 8\n8 = 1\nConsequently, the midpoints ̄x\n̄x1 = 1\n̄x2 = 3\n̄x3 = 5\n· · ·\n̄x8 = 15\n2.) We apply the midpoint rule to the integrand f(x) =\n1 + x2\n\u0002 1\n1 + x2 dx ≈\n\u0014\nf( ̄x1)\n+\nf( ̄x2)\n+· · ·+\nf( ̄xn−1)\n+\nf( ̄xn)\n\u0015\n∆x\n=\n\u0014\n1 +\n+\n+\n+\n+\n1 + 92\n+\n1 + 112\n+\n1 + 132\n+\n1 + 152\n\u00151\n=\n\u0002\n3.98444 + 3.86415 + 3.64413 + 3.35738 + 3.03858+\n2.71618 + 2.40941 + 2.12890\n\u00031\n= 3.1429\nwhere we have rounded to four decimal places\n3.) In this case we can compute the integral exactly (which is one of the reasons it\nwas chosen as an example):\n\u0002 1\n1 + x2 dx = 4 arctan x", "word_count": 444, "start_char": 38462, "end_char": 40380}
{"chunk_id": "DOC0132__00026", "doc_id": "DOC0132", "chunk_index": 26, "text": "0 = π\n4.) So the absolute error in the approximation generated by eight steps of the midpoint rule is\n|3.1429 −π| = 0.0013\n5.) The relative error is then\n|approximate −exact|\nexact\n= |3.1429 −π|\nπ\n= 0.0004\nThat is the error is 0.0004 times the actual value of the integral.\n6.) We can write this as a percentage error by multiplying it by 100\npercentage error = 100 × |approximate −exact|\nexact\n= 0.04%\nThat is, the error is about 0.04% of the exact value.\n■\nPage 31 of 196\n\nExample 2.5.6 Approximate\n\u0002 π\nsin x dx applying the midpoint rule with n = 8 subintervals\nto the above integral.\n1.) We again start by setting up all the x-values that we will need. So a = 0, b =\nπ, ∆x = π\n8 and\nx0 = 0\nx1 = π\nx2 = 2π\n· · ·\nx7 = 7π\nx8 = 8π\n8 = π\nConsequently,\n̄x1 = π\n̄x2 = 3π\n· · ·\n̄x7 = 13π\n̄x8 = 15π\n2.) Applying the mid point rule with the integrand f(x) = sin x\n\u0002 π\nsin x dx ≈\nh\nsin( ̄x1) + sin( ̄x2) + · · · + sin( ̄x8)\ni\n∆x\n=\nh\nsin( π\n16) + sin(3π\n16) + sin(5π\n16) + sin(7π\n16) + sin(9π\n16)+\nsin(11π\n16 ) + sin(13π\n16 ) + sin(15π\n16 )\ni\nπ\n=\nh\n0.1951 + 0.5556 + 0.8315 + 0.9808 + 0.9808+\n0.8315 + 0.5556 + 0.1951\ni\n× 0.3927\n= 5.1260 × 0.3927 = 2.013\n3.) The exact value is given by\n\u0002 π\nsin x dx =\n\u0002\n−cos x\n\u0003π\n0 = −cos π + cos 0 = 2.\n4.) So with eight subintervals (steps) of the midpoint rule we achieved\nabsolute error = |2.013 −2| = 0.013\nrelative error = |2.013 −2|\n= 0.0065\npercentage error = 100 × |2.013 −2|\n= 0.65%\nWith little work we have managed to estimate the integral to within 1% of its true\nvalue.\n■\nPage 32 of 196", "word_count": 348, "start_char": 40380, "end_char": 41905}
{"chunk_id": "DOC0132__00027", "doc_id": "DOC0132", "chunk_index": 27, "text": "Example 2.5.7\n\u0002 1\n1 + x2 dx using the Trapezoidal rule with n = 8 subintervals.\n\u0002 1\n1 + x2 dx ≈\n\u0014\nf(x0)\n1+x2\n+2 ·\nf(x1)\n1+x2\n+· · ·+ 2 ·\nf(xn−1)\n1+x2\n+\nf(xn)\n1+x2\n\u0015∆x\n=\n\u0014\n1 + 02 + 2 ·\n1 + 1\n+ 2 ·\n1 + 22\n+ 2 ·\n+ 2 ·\n1 + 42\n+ 2 ·\n+ 2 ·\n1 + 62\n+ 2 ·\n+\n1 + 82\n\u0015 1\n8(2)\n=\nh\n4 + 2(3.939) + 2(3.765) + 2(3.507)\n+ 2(3.2) + 2(2.876) + 2(2.56) + 2(2.266) + 2\ni 1\n= 3.139\nThe exact value of the integral is still π. So the error in the approximation generated\nby eight steps of the trapezoidal rule is\n|3.139 −π| = 0.0026,\nwhich is\n100|3.139−π|\nπ\n% = 0.08%\nof the exact answer. Notice that this is roughly twice the error that we achieved\nusing the midpoint rule in Example 2.5.5 on page 31.\n■\nExample 2.5.8\n\u0002 π\nsin x dx with the Trapezoidal rule with n = 8.\n\u0002 π\nsin x dx ≈\nh\nsin(x0) + 2 · sin(x1) + · · · + 2 · sin(x7) + sin(x8)\ni∆x\n=\nh\nsin 0 + 2 · sin π\n8 + 2 · sin 2π\n8 + 2 · sin 3π\n8 + 2 · sin 4π\n8 + 2 · sin 5π\n+ 2 · sin 6π\n8 + 2 · sin 7π\n8 + sin 8π\ni\nπ\n=\nh\n0 + 2(0.3827) + 2(0.7071) + 2(0.9239) + 2(1.0000) + 2(0.9239)+\n2(0.7071) + 2(0.3827) + 0\ni\n× 0.1963\n= 1.974\nThe exact answer is\n\u0002 π\nsin x dx = −cos x\n\nπ\n0 = 2. So with eight steps of the trapezoidal rule we achieved 100|1.974−2|\n= 1.3% accuracy. Again this is approximately\ntwice the error we achieved in Example 2.5.6 on page 32 using the midpoint rule. ■\nRemark 2.5.1 These two examples suggest that the midpoint rule is more accurate than the\ntrapezoidal rule. Indeed, this observation is born out by a rigorous analysis of the error.\nPage 33 of 196", "word_count": 366, "start_char": 41905, "end_char": 43409}
{"chunk_id": "DOC0132__00028", "doc_id": "DOC0132", "chunk_index": 28, "text": "gain this is approximately\ntwice the error we achieved in Example 2.5.6 on page 32 using the midpoint rule. ■\nRemark 2.5.1 These two examples suggest that the midpoint rule is more accurate than the\ntrapezoidal rule.I\n\nndeed, this observation is born out by a rigorous analysis of the error.P\n\nage 33 of 196\n\nExample 2.5.9\n\u0002 1\n1 + x2 dx using the Simpson’s rule with n = 8 subintervals.\n\u0002 1\n1 + x2 dx\n≈\n\u0014\n1 + 02 + 4\n1 + 1\n+ 2\n1 + 22\n+ 4\n+ 2\n1 + 42\n+ 4\n+ 2\n1 + 62\n+ 4\n+\n1 + 82\n\u0015\n8 × 3\n=\nh\n4+4 × 3.938461538+2 × 3.764705882+4 × 3.506849315+2 × 3.2\n+ 4 × 2.876404494 + 2 × 2.56 + 4 × 2.265486726 + 2\ni\n8 × 3\n= 3.14159250\nWith the absolute error as\n|3.14159250 −π| = 1.5 × 10−7\nIt is striking that the absolute error approximating with Simpson’s rule is so much\nsmaller than the error from the midpoint and trapezoidal rules.\nmidpoint error\n= 0.0013\ntrapezoid error\n= 0.0026\nSimpson error\n= 0.00000015\nSee Example 2.5.5 and Example 2.5.7.\n■\nPage 34 of 196", "word_count": 205, "start_char": 43102, "end_char": 44053}
{"chunk_id": "DOC0132__00029", "doc_id": "DOC0132", "chunk_index": 29, "text": "Example 2.5.10\n\u0002 π\nsin x dx with the Simpson’s rule with n = 8.\n\u0002 π\nsin x dx\n≈\nh\nsin(x0) + 4 sin(x1) + 2 sin(x2) + · · · + 4 sin(x7) + sin(x8)\ni\n∆x\n=\nh\nsin(0) + 4 sin(π\n8) + 2 sin(2π\n8 ) + 4 sin(3π\n8 ) + 2 sin(4π\n8 )\n+ 4 sin(5π\n8 ) + 2 sin(6π\n8 ) + 4 sin(7π\n8 ) + sin(8π\n8 )\ni\nπ\n8×3\n=\nh\n0 + 4 × 0.382683 + 2 × 0.707107 + 4 × 0.923880 + 2 × 1.0\n+ 4 × 0.923880 + 2 × 0.707107 + 4 × 0.382683 + 0\ni\nπ\n8×3\n= 15.280932 × 0.130900\n= 2.00027\nWith only eight subintervals/steps of Simpson’s rule we achieved\n\u00122.00027 −2\n\u0013\n= 0.014% accuracy.\nAgain we contrast the error we achieved with the other two rules:\nmidpoint error\n= 0.013\ntrapezoid error\n= 0.026\nSimpson error\n= 0.00027\n■\nRemark 2.5.2 These last two examples suggest that the Simpson’s rule is more accurate than\nthe midpoint rule and the trapezoidal rule. Indeed, this observation is born out by a rigorous\nanalysis of the error.\nNote 2.5.1 Two obvious considerations when deciding whether or not a given algorithm is of\nany practical value are\n1.) the amount of computational effort required to execute the algorithm\n2.) the accuracy that this computational effort yields.\nTo get a first impression of the error behaviour of these methods, we apply them to a problem\nwhose answer we know exactly:\n\u0002 π\nsin x dx = −cos x\nπ\n0 = 2.\nTo be a little more precise, we would like to understand how the errors of the three methods\nchange as we increase the effort we put in (as measured by the number of steps n).\nThe\nfollowing table lists the error in the approximate value for this number generated by our three\nrules applied with three different choices of n. It also lists the number of evaluations of f\nrequired to compute the approximation.\nPage 35 of 196", "word_count": 352, "start_char": 44053, "end_char": 45755}
{"chunk_id": "DOC0132__00030", "doc_id": "DOC0132", "chunk_index": 30, "text": "he\nfollowing table lists the error in the approximate value for this number generated by our three\nrules applied with three different choices of n.I\n\nt also lists the number of evaluations of f\nrequired to compute the approximation.P\n\nage 35 of 196\n\nMidpoint\nTrapezoidal\nSimpson’s\nn\nerror\nerror\nerror\n8.2 × 10−3\n1.6 × 10−2\n1.1 × 10−4\n8.2 × 10−5\n1.6 × 10−4\n1.1 × 10−8\n8.2 × 10−7\n1.6 × 10−6\n1.1 × 10−12\nObserve that\n1.) Using 101 evaluations of f worth of Simpson’s rule gives an error 75 times smaller than\n1000 evaluations of f worth of the midpoint rule.\n2.) The trapezoidal rule error with n steps is about twice the midpoint rule error with n steps.\n3.) With the midpoint rule, increasing the number of steps by a factor of 10 appears to reduce\nthe error by about a factor of 100 = 102 = n2.\n4.) With the trapezoidal rule, increasing the number of steps by a factor of 10 appears to reduce\nthe error by about a factor of 102 = n2.\n5.) With Simpson’s rule, increasing the number of steps by a factor of 10 appears to reduce\nthe error by about a factor of 104 = n4.\nPage 36 of 196\n\nExample 2.5.11\nWith the composite Trapezoidal Rule, approximate\nI =\n\u0002 1\nx2dx\nusing\n1.) h = 0.25\nHence, Compare you solutions with the exact solution.\n1.) With h = 0.25\nI = h\n2 [f(x0) + f(xn) + 2 {f(x1) + f(x2) + · · · + f(xn−1)}]\n\u0002 1\nx2dx = 0.25\n[f(0) + f(1) + 2 {f(0.25) + f(0.5) + f(0.75)}]\n= 0.5\n\u0002\n0 + 1 + 2(0.252 + 0.52 + 0.752)\n\u0003\n= 2.75\n= 0.34375\n2.) With h = 0.5\nI = h\n2 [f(x0) + f(xn) + 2 {f(x1) + f(x2) + · · · + f(xn−1)}]\n\u0002 1\nx2dx = 0.5\n2 [f(0) + f(1) + 2{f(0.5)}]\n= 0.5\n\u0002\n0 + 1 + 2(0.52)\n\u0003\n= 1.5\n4 = 0.375\n3.) exact solution\n\u0002 1\nx2dx =\n\u0014x3\n\u00151\n= 1\n3 −(0)\n= 1\n= 0.3333\nErrors.\nWhen h = 0.25, the error is\n|0.33333 −0.34375| = 0.01042\nWith h = 0.5, the error is\n|0.33333 −0.375| = 0.04167\n■\nPage 37 of 196", "word_count": 386, "start_char": 45507, "end_char": 47302}
{"chunk_id": "DOC0132__00031", "doc_id": "DOC0132", "chunk_index": 31, "text": "hen h = 0.25, the error is\n|0.33333 −0.34375| = 0.01042\nWith h = 0.5, the error is\n|0.33333 −0.375| = 0.04167\n■\nPage 37 of 196\n\nExample 2.5.12\nApply the Mid-point Rule to estimate\nI =\n\u0002 1\nx2dx\nusing\n1.) h = 0.25\nHence, Compare you solutions with the exact solution.\n1.) For h = 0.25 Each subinterval has length ∆x = 0.25 = 1\n4. Therefore, the\nsubintervals consist of\n\u0014\n0, 1\n\u0015\n,\n\u00141\n4, 1\n\u0015\n,\n\u00141\n2, 3\n\u0015\n, and\n\u00143\n4, 1\n\u0015\n.\n\u001a1\n8, 3\n8, 5\n8, 7\n\u001b\nM4 = 1\n4 · f\n\u00121\n\u0013\n+ 1\n4 · f\n\u00123\n\u0013\n+ 1\n4 · f\n\u00125\n\u0013\n+ 1\n4 · f\n\u00127\n\u0013\n= 1\n4 · 1\n4 · 9\n4 · 25\n4 · 49\n= 21\n64 = 0.328125.\n2.) For h = 0.5 = 1\n2. Therefore, the subintervals consist of\n\u0014\n0, 1\n\u0015\n, and\n\u00141\n2, 1\n\u0015\n.\n\u001a1\n4, 3\n\u001b\nM2 = 1\n2 · f\n\u00121\n\u0013\n+ 1\n2 · f\n\u00123\n\u0013\n= 1\n2 · 1\n16 + 1\n2 · 9\n= 10\n32 = 0.3125.\n3.) Absolute error: Since\n\u0002 1\nx2 dx = 1\n3,\nthe absolute error in this approximation is:\nPage 38 of 196\n\n(a) For h = 0.25\n\n3 −21\n=\n192 ≈0.0052,\n(b) For h = 0.5\n\n3 −10\n= 1\n48 ≈0.0208,\nand we see that the midpoint rule produces an estimate that is somewhat close\nto the actual value of the definite integral than the Trapezoidal rule.\n■\nPage 39 of 196", "word_count": 283, "start_char": 47176, "end_char": 48248}
{"chunk_id": "DOC0132__00032", "doc_id": "DOC0132", "chunk_index": 32, "text": "2.5.3\nSteps Required to Accuracy\nExample 2.5.13\nHow many steps n required for approximating\n\u0002 1\ne−x2 dx\nusing the midpoint rule to within an accuracy of 10−6.\n1.) The integral has a = 0 and b = 1.\n2.) The first two derivatives of the integrand are\nd\ndxe−x2 = −2xe−x2\nand\nd2\ndx2e−x2 = d\ndx\n\u0000−2xe−x2\u0001\n= −2e−x2 + 4x2e−x2 = 2(2x2 −1)e−x2\n3.) As x runs from 0 to 1, 2x2 −1 increases from −1 to 1, so that\n0 ≤x ≤1 =⇒|2x2 −1| ≤1, e−x2 ≤1 =⇒\n2(2x2 −1)e−x2 ≤2\nSo we take M = 2.\n4.) The error introduced by the n step midpoint rule is at most\nEM ≤M\nn2\n≤2\n(1 −0)3\nn2\n=\n12n2\n5.) We need this error to be smaller than 10−6 so\nEM ≤\n12n2 ≤10−6\nand so\n12n2 ≥106\nclean up\nn2 ≥106\n12 = 83333.3\nsquare root both sides\nn ≥288.7\nSo 289 steps of the midpoint rule will do the job.\n6.) In fact n = 289 results in an error of about 3.7 × 10−7.\nThat seems like far too much work, and the trapezoidal rule will have twice the error.\n■\nPage 40 of 196\n\nExample 2.5.14\nHow many steps n required for approximating\n\u0002 1\ne−x2 dx\nusing the Simpson’s rule to within an accuracy of 10−6.\n1.) The integral has a = 0 and b = 1.\n2.) The first four derivatives of the integrand are\nd\ndxe−x2 = −2xe−x2\nand\nd2\ndx2e−x2 = d\ndx\n\u0000−2xe−x2\u0001\n= −2e−x2 + 4x2e−x2 = 2(2x2 −1)e−x2\nsuch that the third and fourth derivatives are given by\nd3\ndx3e−x2 = d\ndx\n\b\n2(2x2 −1)e−x2\n= 8xe−x2 −4x(2x2 −1)e−x2\n= 4(−2x3 + 3x)e−x2\nd4\ndx4e−x2 = d\ndx\n\b\n4(−2x3 + 3x)e−x2\n= 4(−6x2 + 3)e−x2−8x(−2x3 + 3x)e−x2\n= 4(4x4 −12x2 + 3)e−x2\n3.) Now for any x, then e−x2 ≤1. Also, for 0 ≤x ≤1\n0 ≤x2, x4 ≤1\nso\n3 ≤4x4 + 3 ≤7\nand\n−12 ≤−12x2 ≤0\nadding these together gives\n−9 ≤4x4 −12x2 + 3 ≤7\nConsequently,\n4x4 −12x2 + 3\nis bounded by 9 and so\n\nd4\ndx4e−x2\n≤4 × 9 = 36\nSo, take M = 36.\n4.) The error introduced by the n step Simpson’s rule is at most\nES ≤L\n(b −a)5\nn4\n≤36\n(1 −0)5\nn4\n=\n5n4\n5.) In order for this error to be no more than 10−6 we require n to satisfy\nES ≤\n5n4 ≤10−6\nand so\n5n4 ≥106\nn4 ≥200000\ntake fourth root\nn ≥21.15\nSo 22 steps of Simpson’s rule will do the job.\nPage 41 of 196", "word_count": 439, "start_char": 48248, "end_char": 50254}
{"chunk_id": "DOC0132__00033", "doc_id": "DOC0132", "chunk_index": 33, "text": "age 41 of 196\n\n6.) Just n = 22 steps (as compared to midpoint n = 289 steps results in an error\nof about 3.7 × 10−7 ) results in an error of about 3.5 × 10−8.\nThat seems like far too less work, as compared to work required by Midpoint and the\nTrapezoidal rule.\n■\nPage 42 of 196\n\n2.6\nNumerical Integration Chapter Examples\nExercise 2.6.1 Using n = 4 and all three rules to approximate the value of the following\nintegral\n\u0002 2\n1.) Mid-Point rule\n14.48561253\n2.) Trapezium rule\n20.64455905\n3.) Simpson’s rule\n17.35362645\nMaple gives the exact solution as\n\u0002 2\nex2 dx = 16.45262776. Therefore, the Simpson’s technique\nis more superior followed by the Trapezoidal rule and then the Mid-point algorithm.\nExercise 2.6.2 Show that the error (absolute error) in the Trapezium rule to compute\n\u0002 2\nxdx\nis\n600 ≃0.0017.\nExample 2.6.1\nEvaluate\n\u0002 4\n\u0012\n1 +\n1 + x2\n\u0013 1\ndx by Simpson rule with n = 4.\n13.72624\n= 4.575412\nExample 2.6.2\nUse Trapezoidal rule and Simpson’s rule with 2 subintervals to estimate the\nfollowing integral\n\u0002 4\nx3 dx\nI = h\n≈2\n2 [f(0) + f(4) + 2 {f(2)}]\n≈2\n\u0002\n03 + 43 + 2\n\b\n23 \u0003\n≈80.0000\n2.) Simpson rule\nI = h\n≈2\n3 [f(0) + f(4) + 4 {f(2)}]\n≈2\n\u0002\n03 + 43 + 4\n\b\n23 \u0003\n≈64.0000\n3.) Analytical (Exact or Classical)\n\u0002 4\nx3 dx = x4\n\n= 64.0000\nPage 43 of 196\n\nExample 2.6.3\n\u0002 4\nx2 dx with n = 8 subintervals using\nI = h\n≈0.5\n2 [f(0) + f(4) + 2 {f(0.5) + f(1) + f(1.5) + f(2) + f(2.5) + f(3) + f(3.5)}]\n≈21.5000\n2.) Upper (right-end) Riemann sum\n\u0002\n0.52 + 12 + 1.52 + 22 + 2.52 + 32 + 3.52 + 42\u0003\n= 25.5000\n3.) Lower (left-end) Riemann sum\n\u0002\n02 + 0.52 + 12 + 1.52 + 22 + 2.52 + 32 + 3.52\u0003\n= 17.5000\n4.) Average of Riemann sum\nSn + Sn\n= 25.5000 + 17.5000\n= 21.5000\nSame as Trapezoidal rule!!!\n5.) Mid-point Riemann sum\n\u0002\n0.252 + 0.752 + 1.252 + 1.752 + 2.252 + 2.752 + 3.252 + 3.752\u0003\n= 21.2500\nSame as Midpoint rule!!!\n6.) Analytical methods\n\u0002 4\nx2 dx = x3", "word_count": 389, "start_char": 50241, "end_char": 52085}
{"chunk_id": "DOC0132__00034", "doc_id": "DOC0132", "chunk_index": 34, "text": "= 64\n3 ≈21.3333\nRemark 2.6.1\n• The Trapezoid Rule is nothing more than the average of the left-hand and right-hand\nRiemann Sums. It provides a more accurate approximation of total change than either\nsum does alone.\n• Simpson’s Rule is a weighted average that results in an even more accurate approximation.\n• The Mid-point rule is the Riemann sums at mid points (Not the average of the two\nRiemann sums, that would be Trapezoidal)\nExample 2.6.4 Determine the smallest number of subintervals required to guarantee accuracy\nto within 0.002 in the approximation of\n\u0002 1\nex2dx using Trapezoidal rule.\nUsing the Truncation error of Trapezoidal, (2.2) on page (p. 7). Since\nf(x) = ex2 ⇒f ′′(x) = 4x2ex2 + 2ex2 on [0, 1] ⇒M = 6e. Therefore,\n12n2\n= 6e(1 −0)\n12n2\n= 0.002 ⇒n = 36.86 = 37\n■\nPage 44 of 196\n\nExample 2.6.5 Given the tabulated function\nt\n−4\n−2\nW(t)\n−1\n\u0002 4\n−2\nW(t)dt\nusing the Trapezoidal rule with 3 subintervals.\nI = h\n≈2\n2 [W(−2) + W(4) + 2 {W(0) + W(2)}]\n≈2\n2 [4 + 2 + 2 {3 + (−1)}]\n≈10.0000\nExample 2.6.6\nWrite down the correct formula to use Simpson’s rule and 4 subintervals for\n\u0002 10\nI = h\n≈2\n3 [f(2) + f(10) + 2 {f(6)} + 4 {f(4) + f(8)}]\nExercise 2.6.3\nUse the Riemann sum formula at mid point to compute the definite integral\nin Example 2.4.2 above. Compare both answers to the classical value of the definite integral.\nExample 2.6.7 Estimate\n\u0002 1\ncos\n\u0000x3 + x\n\u0001\ndx using five ordinates (four intervals). The interval\nwidth, h = 0.25 using\nI = 0.25\n[1.0000 −0.41615 + 2 {0.96493 + 0.81096 + 0.38843}] = 0.6141\n2.) Simpson’s method\nI = 0.25\n[1.0000 −0.41615 + 2 {0.81096} + 4 {0.96493 + 0.38843}] = 0.6349\nExample 2.6.8\nApply the mid-point scheme to approximate\n\u0002 1\ncos xdx using h = 0.25.\n\u0002 1\ncos xdx = ∆x\nn\nX\ni=1\nf(mi)\n= (0.25) [f(0.125) + f(0.375) + f(0.625) + f(0.875)]\n= (0.25) [cos(0.125) + cos(0.375) + cos(0.625) + cos(0.875)]\n= (0.25) [0.992197667 + 0.930507621 + 0.810963119 + 0.640996858]\n= 0.8436663\n■\nPage 45 of 196", "word_count": 369, "start_char": 52085, "end_char": 54021}
{"chunk_id": "DOC0132__00035", "doc_id": "DOC0132", "chunk_index": 35, "text": "Example 2.6.9 Given\n\u0002 2\ndx\nx . How large should n be to guarantee that the Trapezoidal Rule\napproximation of the integral is accurate to within 0.0001?\nSince\n|ET| ≤2(2 −1)3\n12n2\n≤0.0001 = 10−4,\nthen\n6n2 ≥104 ⇔n > 102\n√\n6 ≈40.8 ⇒n ≥41.\nExample 2.6.10\nEstimate the number of subintervals required to guarantee accuracy of the\nintegral\n\u0002 2\nxdx within 0.005 using the Trapezoidal rule approximation. n ≥\nr\n≈5.77 ≥6\nExercise 2.6.4\nDetermine the smallest value of n such that the Trapezoidal Rule approximation of the integral in Example 2.6.9, is accurate to within 0.000001?\nExample 2.6.11\nDetermine the definite integral\n\u0002 1\n(2 + x), with n = 4 using the\nx\n0.25\n0.5\n0.75\n(x + 2)\n2.25\n2.5\n2.75\n3.0\nA = h\n= h\n2 [f(0) + f(1) + 2 {f(0.25) + f(0.5) + f(0.75)}] + Etrunc\n≈1\n2(0.25) [2 + 3.0 + 2 {2.25 + 2.5 + 2.75}]\n= 2.5000\n2.) Simpson’s method\nx0\nx1\nx2\nx3\nx4\nx\n0.25\n0.5\n0.75\n(x + 2)\n2.25\n2.5\n2.75\n3.0\n\u0002 1\n(x + 2) dx = h\n3 [f(x0) + f(xn) + 2 {f(x2) + f(x4) + . . . + f(x2n−2)} + 4 {f(x1) + f(x3) + . . . + f(x2\n= h\n3 [f(0) + f(1) + 2 {f(0.5)} + 4 {f(0.25) + f(0.75)}] + ET\n≈0.25\n[2 + 3 + 2 {2.5} + 4 {2.25 + 2.75}]\n≈2.5 ≈2.5000\n3.) Mid-point algorithm\n4.) Compare your results with the exact value of I. Which of the techniques is more superior?\nThe analytical technique,\nI =\n\u0002 1\n(x + 2) dx = x\n2 + 2x\n\n0 =\n\u0014\u00121\n2 + 2\n\u0013\n−(0 + 0)\n\u0015\n= 2.5\nFor this specific function, both numerical methods give a similar solution, both accurate\nPage 46 of 196", "word_count": 310, "start_char": 54021, "end_char": 55453}
