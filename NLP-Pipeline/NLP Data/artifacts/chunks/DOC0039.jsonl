{"chunk_id": "DOC0039__00000", "doc_id": "DOC0039", "chunk_index": 0, "text": "Topic: Other Data Mining Techniques-Association Mining\nDr. Daphne Nyachaki Bitalo\nDepartment of Computing & Technology\nFaculty of Engineering, Design & Technology\nDSC3108: Big Data Mining and Analytics\nLecture 03 (BSCS, BSDS_3:1)\n\nCOURSE OVERVIEW\nBig Data\nFundamentals and Mining\nData Analytics\nPredictive analytics\nDescriptive analytics\nArchitectures, storage\nof data\n\nLecture Objectives and Learning outcomes\nThe Objectives of this lecture are :\n❑Understand association data mining techniques that can be used\nfor predictive analyses\nBy the end of this lecture, students should be able to:\n❑Get practical experience working with association mining\nalgorithms and unsupervised learning.\n\nLecture Overview\nAssociation mining parameters\nAssociation mining algorithms\nHands-on practical\nApplications of association\nmining\n\n1. Data mining process: CRISP-DM methodology\n2. Data exploration and visualization\n3. Association rule mining\n4. Classification algorithms (Decision trees, Naïve Bayes,\nSupport Vector Machines)\n5. Clustering algorithms (K-means, hierarchical clustering)\n6. Outlier detection\n\nCRISP-DM (Cross-Industry Standard Process for Data Mining)\nis a widely used methodology that provides a framework for\nconducting data mining projects. It outlines a series of phases\nthat guide the process from business understanding to\ndeployment.\nDocumentation: Maintain clear documentation throughout the\nproject.\n\nPhases of CRISP-DM:\n1. Business Understanding:\n❑Define the business objectives and goals.\n❑Identify the relevant data sources.\n❑Create a project plan.\n2. Data Understanding:\n❑Collect and gather the necessary data.\n❑Explore the data to understand its characteristics, quality, and\ncompleteness.\n❑Identify potential data quality issues.\n\n3. Data Preparation:\n❑Clean and preprocess the data to address any quality issues.\n❑Transform the data into a suitable format for analysis.\n❑Create features or attributes that are relevant to the problem.\n4. Modeling:\n❑Select appropriate data mining techniques based on the business\nobjectives.\n❑Build and train models using the prepared data.\n❑Evaluate the performance of the models.\n\n5. Evaluation:\n❑Assess the quality and reliability of the models.\n❑Compare the performance of different models.\n❑Validate the models using unseen data.\n6. Deployment:\n❑Integrate the chosen model into the production environment.\n❑Monitor the model's performance and update it as needed.\n\nData exploration and visualisation\nIn data mining, exploration helps an analyst understand the\ndata, identify patterns, and communicate findings effectively.\nHandles various aspects such as;\nSummary Statistics: Calculate measures like mean, median, mode, standard deviation,\nand percentiles to get a basic understanding of the data distribution.\nData Profiling: Examine data types, missing values, outliers, and inconsistencies.\nUnivariate Analysis: Analyze individual variables to understand their distributions and\ncharacteristics.\n\nData exploration and visualisation\nHandles various aspects such as;\nBivariate Analysis: Examine relationships between pairs of variables.\nMultivariate Analysis: Explore relationships among multiple variables.\nData Storytelling: Use visualizations to create compelling narratives and\ncommunicate insights effectively.", "word_count": 432, "start_char": 0, "end_char": 3274}
{"chunk_id": "DOC0039__00001", "doc_id": "DOC0039", "chunk_index": 1, "text": "ata Profiling: Examine data types, missing values, outliers, and inconsistencies.U\n\nnivariate Analysis: Analyze individual variables to understand their distributions and\ncharacteristics.D\n\nata exploration and visualisation\nHandles various aspects such as;\nBivariate Analysis: Examine relationships between pairs of variables.M\n\nultivariate Analysis: Explore relationships among multiple variables.D\n\nata Storytelling: Use visualizations to create compelling narratives and\ncommunicate insights effectively.\n\nAssociation rule mining\n●This technique discovers interesting relationships between\nitems in a large dataset. These relationships, typically\nrepresented as rules, can be used to make predictions or\nrecommendations.\n●The technique uses unsupervised machine learning\nalgorithms to find the hidden rules (associations) in data\n●Association rule mining assigns key statistical parameters that\nare different from correlations (i.e. Support, Lift, Confidence)\n\n1. Support\nSupport is a measure of how frequent a item or an item set appears in a\ndataset. For example, what is the support for the item set { Milk + Cheese }\neverytime a customer goes to a shop?\n\n2. Confidence\nConfidence is a measure of how often this rule is found to be true. Or the\nprobability that an event will occur given that another event has occurred.\nSo what is the probability that a customer who purchases milk will also\npurchase cheese?\n\n3. Lift\nLift defines that strength of the relationship or association of purchasing\nmilk and cheese\n\n1. Apriori algorithm\n●The Apriori Algorithm searches through small datasets to identify\ndifferent rules(associations). In this algorithm, there are product clusters\nthat pass frequently, and then strong relationships between these\nproducts and other products are sought.\n●It's designed to efficiently discover frequent itemsets and association\nrules in small datasets.\nAssociation rule: A rule of the form X → Y, where X and Y are itemsets. X is called the antecedent,\nand Y is called the consequent.\nSupport: The fraction of transactions that contain both X and Y.\nConfidence: The probability that Y will occur given that X has occurred.\n\n2. FP-Growth algorithm\n●The frequent pattern growth algorithm also uses unsupervised\nlearning but is more efficient than apriori algorithm\n●The algorithm uses a divide-and-conquer approach to generate\nfrequent itemsets efficiently. The main idea of the FP-growth\nalgorithm is to represent the dataset in a compact form called the\nfrequent pattern tree\n●Limited to categorical data only.\n\n3. ECLAT algorithm\n●Equivalence Class Clustering and List Intersection offers a more\nefficient approach compared to Apriori, especially for dense\ndatasets.\nKey Concepts:\n●Equivalence class: A group of items that always appear together in\ntransactions.\n●Item prefix: The initial part of an itemset.\n●Item list: A list of transactions that contain a specific item.", "word_count": 427, "start_char": 2767, "end_char": 5675}
{"chunk_id": "DOC0039__00002", "doc_id": "DOC0039", "chunk_index": 2, "text": "CLAT algorithm\n●Equivalence Class Clustering and List Intersection offers a more\nefficient approach compared to Apriori, especially for dense\ndatasets.K\n\ney Concepts:\n●Equivalence class: A group of items that always appear together in\ntransactions.\n●Item prefix: The initial part of an itemset.\n●Item list: A list of transactions that contain a specific item.\n\nApplications of association mining\nMarket basket analysis: Identifying products that are frequently purchased\ntogether.\nRecommendation systems: Suggesting items to users based on their past\npurchases or preferences.\nWeb usage mining: Analyzing user behavior on a website to improve its\ndesign.\nMedical diagnosis: Identifying patterns in patient data to assist in\ndiagnosis.\n\nIn-class practical\nImport the necessary libraries for association rule mining:\nLibraries in python:\nmlextend,\napyori,\nApriori\nUse the datasets provided on Moodle\n\n@ugandachristianuniversity\n@UCUniversity\n@UgandaChristianUniversity\nP.O. Box 4 Mukono, Uganda\nTel: 256-312-350800\nEmail: info@ucu.ac.ug.\nUganda Christian University\nhttps://cse.ucu.ac.ug/\n@ucu_ComputEng\n@ucucomputeng\nTel: +256 (0) 312 350 863 | WhatsApp: +256 (0) 708 114 300\nDepartment of Computing & Technology\nFACULTY OF ENGINEERING, DESIGN AND TECHNOLOGY\nEmail: dct-info@ucu.ac.ug", "word_count": 170, "start_char": 5316, "end_char": 6599}
