{"chunk_id": "DOC0129__00000", "doc_id": "DOC0129", "chunk_index": 0, "text": "Chapter 6\nSolution to Non-Linear Equations\n6.1\nIntroduction\n6.1.1\nMotivation\nGiven a second degree polynomial, we can accurately compute it’s root, that is\nax2 + bx + c = 0 ⇒x = −b ±\n√\nb2 −4ac\n2a\nBut what if ax5 + bx4 + cx3 + dx2 + ex + f = 0 ⇒x =?, sin x + x = 0 ⇒x =?\n6.1.2\nProblem Description\n• Given a non-linear equation f(x) = 0, find a x⋆such that f(x⋆) = 0. Thus, x⋆is a root\nof f(x) = 0.\n• Galois theory in math tells us that only polynomials of degree ≤4 can be solved with\nclose forms using +, −, ×, ÷ and taking roots.\n• General non-linear equations can be solved with iterative methods.\n• Basically, we try to guess the location of a root, and approximate it iteratively.\n• Unfortunately, this process can go wrong, leading to another root or even diverge.\n6.1.3\nMethods to be discussed\n• There are two types of methods, bracketing and open. The bracketing methods require\nan interval that is known to contain a root, while the open method does not.\n• Commonly seen bracketing methods include the Bisection method and the regula falsi\nmethod, and the open methods are Newton’s method, the secant method, and the successive\nsubstitution.\n\n6.2\nNewton Raphson’s Method\n6.2.1\nDerivation of the Newton’s method\nIf we are given a non-linear equation f(x) = 0 and we are to apply the Newton Raphson’s\nmethod, we linear approximate the graph of y = f(x) by a straight line passing through the\npoint (x0, f0) and tangential to the graph of y = f(x). Take the slope of this line to be p.\nGeometrically this is given in figure below.\nFigure 6.1: Geometrical representation of a tangent to a curve at a point\nThe equation of the line with slope p and passing through the point (x0, f0) is\ny −f0\nx −x0\n= p\n(6.1)\nHowever, we know that p is the slope of the tangent to y = f(x) at (x0, f0). This is given by;\np = f ′(x0) = f ′\n(6.2)\nSubstituting equation (6.2) in equation (6.1) we get\ny −f0\nx −x0\n= f ′\ny −f0 = (x −x0)f ′\n(6.3)\nFrom figure 6.1, line of equation 13.3 cuts the x-axis at the point (x1, 0) i.e when x = x1 and\ny = 0.\nSubstituting in equation (6.3) we get,\n0 −f0 = (x1 −x0)f ′\nMaking x1 the subject, we get,\nx1 = x0 −f0\nf ′\nor\nx1 = x0 −f(x0)\nf ′x0\n(6.4)\nPage 175 of 315", "word_count": 439, "start_char": 0, "end_char": 2181}
{"chunk_id": "DOC0129__00001", "doc_id": "DOC0129", "chunk_index": 1, "text": "ubstituting in equation (6.3) we get,\n0 −f0 = (x1 −x0)f ′\nMaking x1 the subject, we get,\nx1 = x0 −f0\nf ′\nor\nx1 = x0 −f(x0)\nf ′x0\n(6.4)\nPage 175 of 315\n\nequation (6.4) is actually the Newton’s method for obtaining the next iterate x1 from the\nprevious iterate x0. The equation (6.4) is generalized and written;\n(6.5)\nsince the linear approximation of the curve is done at each of the iterates xn, xn+1, xn+2, . . . as\nreflected in figure above.\nExample 6.2.1\nUse Newton Raphson’s method to find the root of\nx2 −3 = 0 on [1, 2]\n.\nf(xn) = x2\nn −3\ntherefore\nf ′(xn) = 2xn\nBut Raphson’s formula is\nSubstituting in the Raphson’s formula we get\nxn+1 = xn −(x2\nn −3)\n2xn\n= 2x2\nn −x2\nn + 3\n2xn\n=\n\u0012x2\nn + 3\n2xn\n\u0013\nTaking the initial guess/approximation as x0 = 2, but you could also consider x0 = 1 you come\nup with the same answer.\n⇒x1 = x2\n0 + 3\n2x0\n= 22 + 3\n2(2) = 1.7500000\nx2 = x2\n1 + 3\n2x1\n= (1.75)2 + 3\n2(1.75)\n= 1.7321000\nx3 = x2\n2 + 3\n2x2\n= (1.7321)2 + 3\n2(1.7321)\n= 1.7320508\nx4 = x2\n3 + 3\n2x3\n= (1.7320508)2 + 3\n2(1.7320508)\n= 1.7320508\nThus the root is 1.7320508\nPage 176 of 315", "word_count": 237, "start_char": 2031, "end_char": 3110}
{"chunk_id": "DOC0129__00002", "doc_id": "DOC0129", "chunk_index": 2, "text": "Example 6.2.2 Use Newton-Raphson Method to find the only real root of the equation\ncorrect to 9 decimal places.\nSince f(1) = −1 and f(2) = 5, the function has a root in the interval [1, 2] since the function\nchanges sign between [1, 2]. Let us make an initial guess x0 = 1.5.\nf(x) = x3 −x −1 ⇒f(xn) = x3\nn −xn −1\nf ′(x) = 3x2 −1 ⇒f ′(xn) = 3x2\nn −1\nxn+1 = xn −(x3\n(3x2\nn −1)\nxn+1 = 2x3\nn + 1\n3x2\nn −1\n0 + 1\n3x2\n3(1.5)2 −1 = 1.347826087\n1 + 1\n3x2\n1 −1 = 2(1.347826087)3 + 1\n3(1.347826087)2 −1 = 1.325200399\nx3 = 2x3\n2 + 1\n3x2\n2 −1 = 2(1.325200399)3 + 1\n3(1.325200399)2 −1 = 1.324718174\nx4 = 2x3\n3 + 1\n3x2\n3 −1 = 2(1.324718174)3 + 1\n3(1.324718174)2 −1 = 1.324717957\nx5 = 2x3\n4 + 1\n3x2\n4 −1 = 2(1.324717957)3 + 1\n3(1.324717957)2 −1 = 1.324717957\nto 9 decimal places is 1.324717957\nRemark 6.2.1\nThe more the decimal places the better the approximation.\nExample 6.2.3 Repeat Example 6.2.2\nusing 4 decimal places.\nf ′(xn) = xn −(x3\n(3x2\nn −1)\n= 2x3\nn + 1\n3x2\nn −1\n0 + 1\n3x2\n3(1.5)2 −1 = 1.3478\n1 + 1\n3x2\n1 −1 = 2(1.3478)3 + 1\n3(1.3478)2 −1 = 1.3252\nx3 = 2x3\n2 + 1\n3x2\n2 −1 = 2(1.3252)3 + 1\n3(1.3252)2 −1 = 1.3247\nx4 = 2x3\n3 + 1\n3x2\n3 −1 = 2(1.3247)3 + 1\n3(1.3247)2 −1 = 1.3247\nPage 177 of 315", "word_count": 267, "start_char": 3110, "end_char": 4296}
{"chunk_id": "DOC0129__00003", "doc_id": "DOC0129", "chunk_index": 3, "text": "to 4 decimal places is 1.3247\nExample 6.2.4 Repeat Example 6.2.2\nusing 1 decimal places.\nf ′(xn) = xn −(x3\n(3x2\nn −1)\n= 2x3\nn + 1\n3x2\nn −1\n0 + 1\n3x2\n3(1.5)2 −1 = 1.3\n1 + 1\n3x2\n1 −1 = 2(1.3)3 + 1\n3(1.3)2 −1 = 1.3\nto 1 decimal places is 1.3\nRemark 6.2.2\nThe fewer the decimal places the faster the iteration scheme converges.\nExample 6.2.5\nFind the root of the function\ny = e−x −x\nin the vicinity of x = 0.5 correct to 4 decimal places.\nf(x) = e−x −x ⇒f(xn) = e−xn −xn\nf ′(x) = −e−x −1 ⇒f ′(xn) = −e−xn −1\nxn+1 = xn −(e−xn −xn)\n(−e−xn −1) = −xne−xn −xn −e−xn + xn\n(−e−xn −1)\n= (xn + 1) e−xn\n1 + e−xn\nx1 = (x0 + 1) e−x0\n1 + e−x0\n= ([0.5] + 1) e−0.5\n1 + e−0.5\n= 0.5663\nx2 = (x1 + 1) e−x1\n1 + e−x1\n= ([0.5663] + 1) e−0.5663\n1 + e−0.5663\n= 0.5671\nx3 = (x2 + 1) e−x2\n1 + e−x2\n= ([0.5671] + 1) e−0.5671\n1 + e−0.5671\n= 0.5671\ne−x −x = 0\nto 4 decimal places is 0.5671\nExample 6.2.6\nPitfall - no real root\nNewton’s method will fail (the sequence {xn} does not converge) on solving\nf(x) = x2 −4x + 5 = 0\nsince f does not have any real root.\nPage 178 of 315", "word_count": 243, "start_char": 4296, "end_char": 5340}
{"chunk_id": "DOC0129__00004", "doc_id": "DOC0129", "chunk_index": 4, "text": "age 178 of 315\n\nExample 6.2.7\nFind the root of\nf(x) = 3x + sin x −ex = 0\nin the interval [0, 1] numerically by the famous Newton Raphson’s method\nSolution\nSince f(0) = −1 < 0 and f(1) = 3 + sin(1) −e > 0, so there is a real root in [0, 1]. Using\n= xn −(3xn + sin xn −exn)\n(3 + cos xn −exn)\n= 3xn + xn cos xn −xnexn −3xn −sin xn + exn\n3 + cos xn −exn\n= xn [cos xn −exn] −sin xn + exn\n3 + cos xn −exn\nto have the iterations\nx1 = x0 [cos x0 −ex0] −sin x0 + ex0\n3 + cos x0 −ex0\n= 0 [cos 0 −e0] −sin 0 + e0\n3 + cos 0 −e0\nx2 = x1 [cos x1 −ex1] −sin x1 + ex1\n3 + cos x1 −ex1\n= 0.33333 [cos 0.33333 −e0.33333] −sin 0.33333 + e0.33333\n3 + cos 0.33333 −e0.33333\n= 0.36017\nx3 = x2 [cos x2 −ex2] −sin x2 + ex2\n3 + cos x2 −ex2\n= 0.36017 [cos 0.36017 −e0.36017] −sin 0.36017 + e0.36017\n3 + cos 0.36017 −e0.36017\n= 0.36042\nx4 = x3 [cos x3 −ex3] −sin x3 + ex3\n3 + cos x3 −ex3\n= 0.36042 [cos 0.36042 −e0.36042] −sin 0.36042 + e0.36042\n3 + cos 0.36042 −e0.36042\n= 0.36042\nto 5 decimal places is 0.36042\nPage 179 of 315\n\nExample 6.2.8\nPitfall - Alternating or oscillating solutions\nUse Newton’s Method to find the only real root of the equation\nf(x) = ex −2x = 0\nwith an initial guess of x0 = 1.\nf(x) = ex −2x ⇒f(xn) = exn −2xn\nf ′(x) = ex −2 ⇒f ′(xn) = exn −2\nf ′(xn) = xn −exn −2xn\nexn −2\n= exn(xn −1)\nexn −2\nx1 = ex0(x0 −1)\nex0 −2\ne1 −2\n= 0\nx2 = ex1(x1 −1)\nex1 −2\ne0 −2\n= 1\nx3 = ex2(x2 −1)\nex2 −2\ne1 −2\n= 0\nx4 = ex3(x3 −1)\nex3 −2\ne0 −2\n= 1\nx5 = ex4(x4 −1)\nex4 −2\ne1 −2\n= 0\nx6 = ex5(x5 −1)\nex5 −2\ne0 −2\n= 1\n...\n...\nIts an alternating solutions, the solutions oscillate near the local maxima or local minima.\nIn other words, Newton’s Method fails to produce a solution. Why is this? Because there is no\nsolution to be found!\nMathematicians are often very happy when, after a great deal of work, they are just able to\nsay that a solution to a problem exists. This is because once they know it exists, there might\nbe some nice method, such as Newton’s Method, to actually compute the solution.\nPage 180 of 315", "word_count": 450, "start_char": 5326, "end_char": 7315}
{"chunk_id": "DOC0129__00005", "doc_id": "DOC0129", "chunk_index": 5, "text": "ecause there is no\nsolution to be found!M\n\nathematicians are often very happy when, after a great deal of work, they are just able to\nsay that a solution to a problem exists.T\n\nhis is because once they know it exists, there might\nbe some nice method, such as Newton’s Method, to actually compute the solution.P\n\nage 180 of 315\n\nExample 6.2.9\nPitfall - Diverging sequence\nWhen Newton’s method is applied to\nf(x) = xe−x\nwith x0 = 2, it produces\nn\nxn\nf(xn)\n2.00000\n2.70671 × 10−1\n4.00000\n7.32626 × 10−2\n5.33333\n2.57491 × 10−3\n6.56410\n9.25597 × 10−4\n...\n...\n...\n24.96488\n3.59105 × 10−10\n26.00660\n1.31995 × 10−10\n27.04659\n4.85206 × 10−11\nNote that,\n• The sequence {xn} diverges to ∞slowly;\n• However, f(xn) goes to zero rapidly as xn gets larger in a finite precision environment, and\ncould be mistaken as a zero of f.\nDefinition 6.2.1\nConvergence of Newton’s Method\nIf the iterations are getting closer and closer to the correct answer the method is said to converge.\nThat is, the Newton’s method is said to converge if |xn+1 −xn| →0.\nRemark 6.2.3\nHowever, Newton’s method will not converge if\n1.) If f ′(xn) = 0 for some n\n2.) If lim\nn→∞xn does not exist\nPage 181 of 315\n\nExample 6.2.10\nPitfall - Interval size\nIf the numerical When Newton’s method applied to\nf(x) = x3 −x −3\nThe algorithm given by\n= xn −x3\nn −xn −3\n3x2\nn −1\nxn+1 = 2x3\nn + 3\n3x2\nn −1\nwith x0= 0, it produces\nx1 = −3.00000\nx2 = −1.96154\nx3 = −1.14718\nx4 = −0.00658\nx5 = −3.00039\nx6 = −1.96182\nx7 = −1.14743\nThe sequence will not converge. But if the algorithm starts with x0= 2, then it produces\nx1 = 1.7272727\nx2 = 1.6736912\nx3 = 1.6717026\nx4 = 1.6716999\nx5 = 1.6716999\nThe sequence converges to the root 1.6716999 correct to seven decimal places.\nThis examples illustrates again that the starting point x0 must be close enough to the zero of\nf.\nPage 182 of 315", "word_count": 347, "start_char": 6989, "end_char": 8815}
{"chunk_id": "DOC0129__00006", "doc_id": "DOC0129", "chunk_index": 6, "text": "ut if the algorithm starts with x0= 2, then it produces\nx1 = 1.7272727\nx2 = 1.6736912\nx3 = 1.6717026\nx4 = 1.6716999\nx5 = 1.6716999\nThe sequence converges to the root 1.6716999 correct to seven decimal places.T\n\nhis examples illustrates again that the starting point x0 must be close enough to the zero of\nf.P\n\nage 182 of 315\n\nExample 6.2.11\nPitfall - Choice of x0 and f ′(x) = 0\nUse the Newton Method to find a non-zero solution of\nx = 2 sin x\n(6.6)\nLet f(x) = x −2 sin x. Then f ′(x) = 1 −2 cos x, and the Newton-Raphson iteration is\nf ′(xn) = xn −xn −2 sin xn\n1 −2 cos xn\n= 2 (sin xn −xn cos xn)\n1 −2 cos xn\nLet x0= 1.1. The next six estimates, to 3 decimal places, are:\nx1 = 8.453\nx2 = 5.256\nx3 = 203.384\nx4 = 118.019\nx5 = −87.471\nx6 = −203.637\nThings don’t look good, and they get worse. It turns out that x35 < −64000000. We could be\nstubborn and soldier on. Miracles happen-but not often. (One happens here, around n = 212.)\nThe trouble was caused by the choice of x0, let us consider x0= 1.5. Here are the next six\nestimates, to 19 decimal places - to indicate how fast the convergence is\nx1 = 2.0765582006304348291\nx2 = 1.9105066156590806258\nx3 = 1.8956220029878460925\nx4 = 1.8954942764727706570\nx5 = 1.8954942670339809987\nx6 = 1.8954942670339809471\nThe next iterate x7 agrees with x6 in the first 19 decimal places, indeed in the first 32, and the\ntrue root is equal to x6 to 32 decimal places.\nRemark 6.2.4\nNote that choosing\nx0 = π\n3 ≈1.0472\nleads to immediate disaster, since then the denominator f ′(x) = 1 −2 cos x0 = 0 and therefore\nx1 does not exist.\nComment 6.2.1\nThe remedy to this is to rewrite the Equation (6.6) into other forms say\nx −\nsin x = 0 or sin x\nx\n= 1\nworks nicely - to have f ′(x) harder to be too small or almost zero for ∀x ∈(0, π) - as we shall\nsee in the section of successive substitution, Section 6.6\nPage 183 of 315", "word_count": 371, "start_char": 8491, "end_char": 10345}
{"chunk_id": "DOC0129__00007", "doc_id": "DOC0129", "chunk_index": 7, "text": "Example 6.2.12\nConsider the problem of finding the positive number x with cos x = x3 We\ncan rephrase that as finding the zero of\nf(x) = cos x −x3 ⇒f ′(x) = −sin x −3x2\nSince cos x ≤1 for all x and x3 > 1 for x > 1, we know that our zero lies in [0, 1]. We try a\nstarting value of x0 = 0.5.\nf ′(xn) = xn −\ncos xn −x3\nn\n−sin xn −3x2\nn\n= xn sin xn + cos xn + 2x3\nn\nsin xn + 3x2\nn\nx1 = x0 sin x0 + cos x0 + 2x3\nsin x0 + 3x2\n= (0.5) sin(0.5) + cos(0.5) + 2(0.5)3\nsin(0.5) + 3(0.5)2\n= 1.1121416\nx2 = x1 sin x1 + cos x1 + 2x3\nsin x1 + 3x2\n= (1.1121416) sin(1.1121416) + cos(1.112141637097) + 2(1.1121416)3\nsin(1.1121416) + 3(1.1121416)2\n= 0.9096727\nx3 = x2 sin x2 + cos x2 + 2x3\nsin x2 + 3x2\n= (0.9096727) sin(0.9096727) + cos(0.9096727) + 2(0.9096727)3\nsin(0.9096727) + 3(0.9096727)2\n= 0.8672638\nx4 = x3 sin x3 + cos x3 + 2x3\nsin x3 + 3x2\n= (0.8672638) sin(0.8672638) + cos(0.8672638) + 2(0.8672638)3\nsin(0.8672638) + 3(0.8672638)2\n= 0.8654771\nx5 = x4 sin x4 + cos x4 + 2x3\nsin x4 + 3x2\n= (0.8654771) sin(0.8654771) + cos(0.8654771) + 2(0.8654771)3\nsin(0.8654771) + 3(0.8654771)2\n= 0.8654740\nx6 = x5 sin x5 + cos x5 + 2x3\nsin x5 + 3x2\n= (0.8654740) sin(0.8654740) + cos(0.8654740) + 2(0.8654740)3\nsin(0.8654740) + 3(0.8654740)2\n= 0.8654740\nTherefore, the solution is\nx = 0.8654740\ncorrect to 7 decimal places\nPage 184 of 315", "word_count": 269, "start_char": 10345, "end_char": 11663}
{"chunk_id": "DOC0129__00008", "doc_id": "DOC0129", "chunk_index": 8, "text": "Example 6.2.13\nUse Newton’s Method to estimate the point of intersection of\ny = e−x2 and y = x.\nf(x) = x −e−x2 , ⇒xn+1 = xn −\nxn −e−x2\nn\n1 + 2xne−x2n\nn\nxn\nf(xn)\nf(xn)\nf′(xn)\nxn −f(xn)\nf′(xn)\n0.500000\n-0.27880\n1.77880\n-0.15673\n0.65673\n0.65673\n0.00706\n1.85331\n0.00381\n0.00000\n1.85261\n0.00000\nThe solution exists and it is 0.65292\nExercise 6.2.1\nLet f(x) = x2 −a. Show that the Newton Method leads to the recurrence\n\u0012\nxn + a\nxn\n\u0013\nExercise 6.2.2\nNewton’s equation y3 −2y −5 = 0 has a root near y = 2. Starting with\ny0 = 2, compute y1, y2, and y3, the next three Newton-Raphson estimates for the root.\nExercise 6.2.3\nFind the root of the equation\nx2 + x −1 = 0\nin the interval [0, 1], giving your answer correct to 4 decimal places.\nExercise 6.2.4\nShow that the cubic equation\n2x3 + 3x2 −3x −5 = 0\nhas a real root in the interval [1, 2]. Approximate this root correct to five decimal places using\nNewton Raphson’s method.\nExercise 6.2.5\nUse Newton’s method to approximate the root of the equation\ng(x) = x3 −2 sin x\non [0.5, 2].\nPage 185 of 315\n\n6.2.2\nRoots of Positive Numbers\nSuppose that our interest is to find the rth root of a real positive number A. If x is the value\nof this root, then x is related to A by the equation,\nA\nr = x or xr = A or xr −A = 0\nLet f(x) = xr −A, then x is the root of the nonlinear equation,\nf(x) = xr −A = 0, ⇒f(xn) = xr\nn −A, ⇒f ′(xn) = rxr−1\nn\nApplying the Newton Raphson’s method, we have;\nxn+1 = xn −(xr\nn −A)\nrxr−1\nn\n= rxr\nn −xr\nn + A\nrxr−1\nn\n= (r −1)xr\nn + A\nrxr−1\nn\nr\n\u001a\n(r −1)xn +\nA\nxr−1\nn\n\u001b\n(6.7)\nEquation (6.7) is a general formula from which we can obtain quadratically convergent iterative\nprocesses for finding approximations to arbitrary roots of numbers.\nNote 6.2.1\nThe root, or answer interested in is the x. And also what is f(x) is the function\nf(x) = 0\nExample 6.2.14\nWhen r = 2, the square root of a number A we have\nx =\n√\nA ⇒x2 = A\nThus for r = 2 in the general formula, we get,\n\u0012\nxn\n\u0013\nWhich is the Newton’s square root algorithm for extracting roots of positive numbers.\nPage 186 of 315", "word_count": 425, "start_char": 11663, "end_char": 13698}
{"chunk_id": "DOC0129__00009", "doc_id": "DOC0129", "chunk_index": 9, "text": "age 186 of 315\n\nExample 6.2.15\nUse Newton’s square root algorithm to find the square root of 5 correct to\nsix decimal places.\n√\n5 = x ⇒5\n2 = x ⇒x2 −5 = 0 ⇒f(x) = x2 −5 = 0\nOr substituting in the general formula r = 2 and A = 5 we get,\n\u0012\nxn\n\u0013\nor, using the Newton Raphson formula directly,\nf(x) = x2 −5\nf ′(x) = 2x\nto have\nxn+1 = xn −x2\nn −5\n2xn\nxn+1 = 2x2\nn −x2\nn + 5\n2xn\nxn+1 = x2\nn + 5\n2xn\n\u0012\nxn + 5\nxn\n\u0013\nStarting with x0 = 2.0 we get,\nx1 = 1\n\u0012\nx0 + 5\nx0\n\u0013\n= 1\n\u0012\n2.000000 +\n2.000000\n\u0013\n= 2.250000\nx2 = 1\n\u0012\nx1 + 5\nx1\n\u0013\n= 1\n\u0012\n2.250000 +\n2.250000\n\u0013\n= 2.236111\nx3 = 1\n\u0012\nx2 + 5\nx2\n\u0013\n= 1\n\u0012\n2.236111 +\n2.236111\n\u0013\n= 2.236068\nx4 = 1\n\u0012\nx3 + 5\nx3\n\u0013\n= 1\n\u0012\n2.236068 +\n2.236068\n\u0013\n= 2.236068\nThe value of x2 = 2.236111 is correct only to one decimal place since it agrees with the previous\niterate x1 = 2.250000 only in one decimal place.\nHowever, x3 = 2.236068 is correct to three decimal places since it is in agreement with the\nprevious iterate x2 in exactly three places of decimal.\nBut x4 = 2.236068 is exactly the same as x3. In fact they are exactly the same up to nine\nThis means that x4 = 2.236068 is the value of the root correct to nine decimal places. Thus\nx4, must also be correct up to six decimal places.\nHence, the value of the root that you state as being correct to six decimal places or nine decimal\nplaces is x4 = 2.236068. Compare with the value obtained from calculator.\nPage 187 of 315", "word_count": 321, "start_char": 13684, "end_char": 15077}
{"chunk_id": "DOC0129__00010", "doc_id": "DOC0129", "chunk_index": 10, "text": "hus\nx4, must also be correct up to six decimal places.H\n\nence, the value of the root that you state as being correct to six decimal places or nine decimal\nplaces is x4 = 2.236068.C\n\nompare with the value obtained from calculator.P\n\nage 187 of 315\n\nExample 6.2.16\nUse Newton’s method to approximate\n√\nFor f(x) = x2 −2, f ′(x) = 2x. such that\nxn = xn−1 −f(xn−1)\nf ′(xn−1)\n= xn−1 −x2\nn−1 −2\n2xn−1\n= 1\n2xn−1 +\nxn−1\n= 1\n\u0012\nxn−1 +\nxn−1\n\u0013\n.\nTherefore\nx1 = 1\n\u0012\nx0 + 2\nx0\n\u0013\n= 1\n\u0012\n2 + 2\n\u0013\n= 1.5\nx2 = 1\n\u0012\nx1 + 2\nx1\n\u0013\n= 1\n\u0012\n1.5 + 2\n1.5\n\u0013\n≈1.416666667.\nContinuing in this way, we find that\nx1 = 1.5\nx2 ≈1.416666667\nx3 ≈1.414215686\nx4 ≈1.414213562\nx5 ≈1.414213562.\nSince we obtained the same value for x4 and x5, it is unlikely that the value xn\nwill change on any subsequent application of Newton’s method. We conclude that\n√\n2 ≈1.414213562..\n■\nExercise 6.2.6 Use Newton’s method to approximate\n√\n3 by letting f(x) = x2−3 and x0 = 3.\nFind x1 and x2.\nx1 = 2\nx2 = 1.75\n■\nPage 188 of 315", "word_count": 211, "start_char": 14831, "end_char": 15801}
{"chunk_id": "DOC0129__00011", "doc_id": "DOC0129", "chunk_index": 11, "text": "e conclude that\n√\n2 ≈1.414213562..\n■\nExercise 6.2.6 Use Newton’s method to approximate\n√\n3 by letting f(x) = x2−3 and x0 = 3.F\n\nind x1 and x2.\nx1 = 2\nx2 = 1.75\n■\nPage 188 of 315\n\n6.2.3\nReciprocals of Numbers\nThe reciprocal of a number A\nA−1 = x ⇒x−1 = A\n⇒1\nx = A\n⇒f(x) = Ax −1 = 0 wrong choice, f ′(x) = c\n⇒f(x) = 1\nx −A = 0 ⇒f ′(x) = −1\nx2\nf ′(xn) ⇒xn+1 = xn −\nxn −A\n−1\nx2n\n⇒xn+1 = xn(2 −Axn)\nAlternatively, if we have that r = −1 then x−1 = A (positive number), this means x = 1\nA\n(reciprocal of A) with r = −1 in the general formula in equation (6.7) then we get,\nxn+1 = xn(2 −Axn)\nThis formula is quadratically convergent and can suitably be applied to calculate the reciprocal\nof numbers.\nExample 6.2.17\nUse Newton’s reciprocal algorithm to find the reciprocal of 3.\nxn+1 = xn(2 −Axn) ⇒xn+1 = xn(2 −3xn)\nor, using the formula, since finding\n3−1 = x ⇒3x = 1 ⇒3x −1 = 0 ⇒f(x) = 3x −1\nwould be a wrong choice as xn+1 will equal to a constant\n3−1 = x ⇒3 = x−1 ⇒1\nx −3 = 0 ⇒f(x) = 1\nx −3\nsuch that\nf(x) = 1\nx −3, f ′(x) = −1\nx2\nf ′(xn) = xn(2 −3xn)\nLet x0 = 0.5.\nx1 = x0[2 −3(x0)] = 0.50000\n\u0014\n2 −3(0.50000)\n\u0015\n= 0.25000\nx2 = x1[2 −3(x1)] = 0.25000\n\u0014\n2 −3(0.25000)\n\u0015\n= 0.31250\nx3 = x2[2 −3(x2)] = 0.31250\n\u0014\n2 −3(0.31250)\n\u0015\n= 0.33203\nx4 = x3[2 −3(x3)] = 0.33203\n\u0014\n2 −3(0.33203)\n\u0015\nx5 = x4[2 −3(x4)] = 0.33333\n\u0014\n2 −3(0.33333)\n\u0015\nThus x5 = 0.33333 is the value of the reciprocal of 3 i.e 1\n3 correct to five decimal places.\nPage 189 of 315", "word_count": 324, "start_char": 15624, "end_char": 17056}
{"chunk_id": "DOC0129__00012", "doc_id": "DOC0129", "chunk_index": 12, "text": "age 189 of 315\n\n6.2.4\nFailures of Newton’s Method\nTypically, Newton’s method is used to find roots fairly quickly. However, things can go wrong.\nSome reasons why Newton’s method might fail include the following:\n1. At one of the approximations xn, the derivative f ′ is zero at xn, but f(xn) ̸= 0. As a result,\nthe tangent line of f at xn does not intersect the x-axis. Therefore, we cannot continue the\niterative process.\n2. The approximations x0, x1, x2, . . . may approach a different root. If the function f has more\nthan one root, it is possible that our approximations do not approach the one for which we\nare looking, but approach a different root (see Figure below).\nFigure 6.2: If the initial guess x0 is too far from the root sought, it may lead to approximations\nthat approach a different root.\nThis event most often occurs when we do not choose the approximation x0 close enough to\nthe desired root.\n3. The approximations may fail to approach a root entirely. In Example 6.2.18 , we provide an\nexample of a function and an initial guess x0 such that the successive approximations never\napproach a root because the successive approximations continue to alternate back and forth\nbetween two values.\nExample 6.2.18\nConsider the function f(x) = x3 −2x + 2. Let x0 = 0. Show that the\nsequence x1, x2, . . . fails to approach a root of f.\nFor f(x) = x3 −2x + 2, the derivative is f ′(x) = 3x2 −2. Therefore,\nx1 = x0 −f(x0)\nf ′(x0) = 0 −f(0)\nf ′(0) = −2\n−2 = 1.\nIn the next step,\nx2 = x1 −f(x1)\nf ′(x1) = 1 −f(1)\nf ′(1) = 1 −1\n1 = 0.\nConsequently, the numbers x0, x1, x2, . . . continue to bounce back and forth between\n0 and 1 and never get closer to the root of f which is over the interval [−2, −1] .\nPage 190 of 315", "word_count": 337, "start_char": 17042, "end_char": 18766}
{"chunk_id": "DOC0129__00013", "doc_id": "DOC0129", "chunk_index": 13, "text": "onsequently, the numbers x0, x1, x2, . . . continue to bounce back and forth between\n0 and 1 and never get closer to the root of f which is over the interval [−2, −1] .P\n\nage 190 of 315\n\nFigure 6.3: The approximations continue to alternate between 0 and 1 and never approach the\nroot of f.\nFortunately, if we choose an initial approximation x0 closer to the actual root, we\ncan avoid this situation.\n■\nExercise 6.2.7\nFor f(x) = x3 −2x + 2, let x0 = −1.5 and find x1 and x2.\nx1 ≈−1.842105263\nx2 ≈−1.772826920\n■\nNote 6.2.2 From Example 6.2.18, we see that Newton’s method does not always work. However, when it does work, the sequence of approximations approaches the root very quickly.\nDiscussions of how quickly the sequence of approximations approach a root found using Newton’s method are included in texts on numerical analysis.\n6.2.5\nAdvantages of Newton Raphson’s Method\n• A faster method for converging on a single root of a function is the Newton- Raphson method.\n• Perhaps it is the most widely used method of all locating formulas.\n• Because the convergence rate is high, no worry for initial guess, interval size, and number of\ndecimal places required.\n• Requires only one guess\nPage 191 of 315", "word_count": 216, "start_char": 18581, "end_char": 19785}
{"chunk_id": "DOC0129__00014", "doc_id": "DOC0129", "chunk_index": 14, "text": "6.2.6\nLimitations of Newton Raphson’s Method\nGood though it is, the method has some limitations.\n• The Newton Raphson’s method may also fail if f(x) has a point of inflection in the neighborhood of the root.\n• Newton’s method is an extremely powerful technique, but it has a major weakness: the need\nto know the value of the derivative of f at each approximation.\n• Frequently, f ′(x) is far more difficult and needs more arithmetic operations to calculate than\nf(x).\n• If in the immediate neighborhood of a root of f(x), f ′(x) vanishes or is very small, the\nNewton Raphson’s method will not converge. The reason for this failure is; since f ′(x) is\nvery small, the quantity, −f(xn)\nf ′(xn) becomes very large. In case it is zero - the denominator,\nthen function is not defined. The consequence is that we are thrown away from the root we\nare approximating.\nExercise 6.2.8\nUse Newton’s square root algorithm to find the square root of 2 correct to 6\nExercise 6.2.9\nUse cube root Newton’s algorithm to find the cube root of 7 correct to four\nExercise 6.2.10\nUse Newton’s reciprocal algorithm to find\n1.) the reciprocal of the square root of 2.\n2.) The reciprocal of the cube root of 4.\nExercise 6.2.11 State the advantages and disadvantages of the Newton’s method for nonlinear equations.\nExercise 6.2.12\nDefine the Newton-Raphson method formula for finding the root of a nonlinear equation f(x) = 0\nExercise 6.2.13 With any simple example, write short notes on the ”NRM” for solving nonlinear equations.\nPage 192 of 315\n\nExample 6.2.19\n1.) The convergence of the Newton-Raphson method technique highly depends on the initial\nguess. Discuss.\nYes, when the initial guess is in the interval given, the iterations\nconverge faster than otherwise.\n■\n2.) Use Newton Raphson method to estimate one of the solutions of x2 −4 = 0 using x0 = 6\nto 2 decimal places.\nxn\nxn+1\nx0 = 6\nx1 = 3.33\nx1 = 3.33\nx2 = 2.27\nx2 = 2.27\nx3 = 2.01\nx3 = 2.01\nx4 = 2.00\nx4 = 2.00\nx5 = 2.00\n■\n3.) Newton’s Raphson’s method is one of the popular schemes for solving a non-linear equation\nf(x) = 0. Prove that the Newton Raphson’s method for finding the square root of a positive\nnumber A is given by,\n\u0012\nxn\n\u0013\nUse the scheme above to approximate the square root of 5(\n√\n5) to three decimal places with\nx0 = 2.\nxn\nxn+1\nx0 = 2\nx1 = 2.25\nx1 = 2.25\nx2 = 2.236\nx2 = 2.236\nx3 = 2.236\nx3 = 2.236\nx4 = 2.236\n■\nPage 193 of 315", "word_count": 448, "start_char": 19785, "end_char": 22168}
{"chunk_id": "DOC0129__00015", "doc_id": "DOC0129", "chunk_index": 15, "text": "6.3\nBisection Method (Interval Halving)\n6.3.1\nBackground\nThe bisection method is one of the bracketing methods for finding roots of equations.\n6.3.2\nImplementation\nGiven a function f(x) and an interval which might contain a root, perform a predetermined\nnumber of iterations using the bisection method.\n6.3.3\nLimitations\nInvestigate the result of applying the bisection method over an interval where there is a discontinuity. Apply the bisection method for a function using an interval where there are distinct\nroots. Apply the bisection method over a ”large” interval.\n6.3.4\nExplanation on the bisection method\nThe bisection method takes a similar geometrical approach with the Regula falsi algorithm.\nYou need two initial guesses x0 and x1 to the root x⋆of the nonlinear equation f(x) = 0, such\nthat\nf(x0)f(x1) < 0\nThe next approximation is obtained by getting the arithmetic mean of the previous two. That\nis\n(6.8)\nHowever, the pair xn, xn+1 to be used to get xn+2 must satisfy the condition\nf(xn)f(xn−1) < 0\n(6.9)\nMasenge (1989) called this method a trivial simplification of the regula falsi.\nIn mathematics, the bisection method is a root-finding algorithm which works by repeatedly\ndividing an interval in half and then selecting the subinterval in which the root exists.\nPage 194 of 315\n\nExample 6.3.1\nUse the Bisection method to estimate the root of x2 = 3 on (1, 2).\nThe non linear function x2 −3 = 0 ⇒f(x) = x2 −3\nLet\nx0 = 1 ⇒f0 = −2.000 < 0\nx1 = 2 ⇒f1 = 1.000 > 0\nFor the Bisection scheme,\n= 1 + 2\n= 1.500 ⇒f2 = −0.75 < 0\n= 1.500 + 2.000\n= 1.750 ⇒f3 = 0.062 > 0\n= 1.750 + 1.500\n= 1.625 ⇒f4 = −0.359 < 0\n= 1.625 + 1.750\n= 1.688 ⇒f5 = −0.151 < 0\n= 1.688 + 1.750\n= 1.719 ⇒f6 = −0.045 < 0\nx7 = x6 + x3\n= 1.719 + 1.750\n= 1.735 ⇒f7 = 0.010 > 0\n= 1.735 + 1.719\n= 1.727 ⇒f8 = −0.017 < 0\nx9 = x8 + x7\n= 1.727 + 1.735\n= 1.731 ⇒f9 = −0.004 < 0\nx10 = x9 + x7\n= 1.731 + 1.735\n= 1.733 ⇒f10 = 0.003 > 0\nx11 = x10 + x9\n= 1.733 + 1.731\n= 1.732 ⇒f11 = 0.000\nSince f11 = 0.000, then x11 = 1.732 it is the root or zero of the function x2 −3 = 0, that is the\napproximated square root of 3 correct to three decimal places.\nPage 195 of 315", "word_count": 424, "start_char": 22168, "end_char": 24296}
{"chunk_id": "DOC0129__00016", "doc_id": "DOC0129", "chunk_index": 16, "text": "age 195 of 315\n\nExample 6.3.2\nCompute the numerical root of\nusing the Bisection method on the interval [0, 0.5] correct to 4 decimal places.\nLet\nx0 = 0 ⇒f0 = −1.0000 < 0\nx1 = 0.5 ⇒f1 = 0.3307 > 0\nFor the Bisection scheme,\n= 0 + 0.5\n= 0.2500 ⇒f2 = −0.2866 < 0\n= 0.2500 + 0.5000\n= 0.3750 ⇒f3 = 0.0363 > 0\n= 0.3750 + 0.2500\n= 0.3125 ⇒f4 = −0.1219 < 0\n= 0.3125 + 0.3750\n= 0.3438 ⇒f5 = −0.0418 < 0\n= 0.3438 + 0.3750\n= 0.3594 ⇒f6 = −0.0026 < 0\nx7 = x6 + x3\n= 0.3594 + 0.3750\n= 0.3672 ⇒f7 = 0.0169 > 0\n= 0.3672 + 0.3594\n= 0.3633 ⇒f8 = 0.0072 > 0\nx9 = x8 + x6\n= 0.3633 + 0.3594\n= 0.3614 ⇒f9 = 0.0024 > 0\nx10 = x9 + x6\n= 0.3614 + 0.3594\n= 0.3604 ⇒f10 = −0.0001 < 0\nx11 = x10 + x9\n= 0.3604 + 0.3614\n= 0.3609 ⇒f11 = 0.0012 > 0\nx12 = x11 + x10\n= 0.3609 + 0.3604\n= 0.3607 ⇒f12 = 0.0007 > 0\nx13 = x12 + x10\n= 0.3607 + 0.3604\n= 0.3606 ⇒f13 = 0.0004 > 0\nx14 = x13 + x10\n= 0.3606 + 0.3604\n= 0.3605 ⇒f14 = 0.0002 > 0\nx15 = x14 + x10\n= 0.3605 + 0.3604\n= 0.3604 ⇒f15 = −0.0001 < 1\nx16 = x15 + x14\n= 0.3604 + 0.3605\n= 0.3604\nis approximately\n0.3604\nThe exact solution is in fact 0.36044\nRemark 6.3.1\nThe Bisection method takes long to converge.\nPage 196 of 315\n\n6.3.5\nAdvantages of the Bisection method\n• The method is simple.\n• The method is always convergent.\n6.3.6\nDisadvantages of the Bisection method\n• It requires the values of a = x0 and b = x1.\n• The convergence of interval halving is very slow (slow at converging to the root x⋆). For\nexample, a simple non linear equation\nx3 −x −2\nwill converge to about 1.521 after 15-fifteen iterations.\n• The method fails in case of approximating a double root or a root of even multiplicity.\n• A faster method for converging on a single root of a function is the Newton-Raphson\niteration Method.\nPage 197 of 315", "word_count": 383, "start_char": 24282, "end_char": 26020}
{"chunk_id": "DOC0129__00017", "doc_id": "DOC0129", "chunk_index": 17, "text": "or\nexample, a simple non linear equation\nx3 −x −2\nwill converge to about 1.521 after 15-fifteen iterations.\n• The method fails in case of approximating a double root or a root of even multiplicity.\n• A faster method for converging on a single root of a function is the Newton-Raphson\niteration Method.P\n\nage 197 of 315\n\nExample 6.3.3\nUsing the Bisection algorithm, find the root of\ncos x −xex = 0\ncorrect to 3 decimal places on the interval 0 ≤x ≤1\nLet x0 = 0 ⇒f0 = 1.000 > 0 and x1 = 1 ⇒f1 = −2.178 < 0, for the Bisection scheme,\n= 0 + 1\n= 0.500 ⇒f2 = 0.053 > 0\n= 0.500 + 1.000\n= 0.750 ⇒f3 = −0.856 < 0\n= 0.750 + 0.500\n= 0.625 ⇒f4 = −0.357 < 0\nx5 = x4 + x2\n= 0.625 + 0.500\n= 0.562 ⇒f5 = −0.140 < 0\nx6 = x5 + x2\n= 0.562 + 0.500\n= 0.531 ⇒f6 = −0.041 < 0\nx7 = x6 + x2\n= 0.531 + 0.500\n= 0.516 ⇒f7 = 0.005 > 0\n= 0.516 + 0.531\n= 0.524 ⇒f8 = −0.019 < 0\nx9 = x8 + x7\n= 0.524 + 0.516\n= 0.520 ⇒f9 = −0.007 < 0\nx10 = x9 + x7\n= 0.520 + 0.516\n= 0.518 ⇒f10 = −0.001 < 0\nx11 = x10 + x7\n= 0.518 + 0.516\n= 0.517 ⇒f11 = 0.002 > 0\nx12 = x11 + x10\n= 0.517 + 0.518\n= 0.518 ⇒f12 = −0.001 < 0\nx13 = x12 + x11\n= 0.518 + 0.517\n= 0.518\nThe scheme converges at x = 0.518. Analytically, the root is 0.5177\nPage 198 of 315", "word_count": 288, "start_char": 25702, "end_char": 26896}
{"chunk_id": "DOC0129__00018", "doc_id": "DOC0129", "chunk_index": 18, "text": "nalytically, the root is 0.5177\nPage 198 of 315\n\nExample 6.3.4\nEstimate the zero to the non linear equation\nf(x) = x3 −5x2 −2x + 10\nusing numerical Bisection method, if the graphical methods found the real root between x = 1\nand x = 3:\nLet\nx0 = 1 ⇒f0 = 4.0000 > 0\nx1 = 3 ⇒f1 = −14.0000 < 0\nBy interval halving,\n= 3 + 1\n= 2.0000 ⇒f2 = −6.0000 < 0\nx3 = x2 + x0\n= 2.0000 + 1.0000\n= 1.5000 ⇒f3 = −0.8750 < 0\nx4 = x3 + x0\n= 1.5000 + 1.0000\n= 1.2500 ⇒f4 = 1.6406 > 0\n= 1.2500 + 1.5000\n= 1.3750 ⇒f5 = 0.3965 > 0\n= 1.3750 + 1.5000\n= 1.4375 ⇒f6 = −0.2366 < 0\nx7 = x6 + x5\n= 1.4375 + 1.3750\n= 1.4063 ⇒f7 = 0.0802 > 0\n......\nIt is evident that the functional values f(xi) are approaching zero as the number of iterations\nis increased.\nAfter more six iteration the approximated root of 1.40625 compares favorably with the exact\nvalue of\n√\nPage 199 of 315\n\nExample 6.3.5\nThe following polynomial has a root within the interval 3.75 ≤x ≤5.00\nf(x) = x3 −x2 −10x −8 = 0\nIf a tolerance of 0.01(1%) is required, find this root using bisection method.\nThe Bisection algorithm is given by\nalternatively xm = xs + xe\nwhere xm is the mid point, xs starting point of the two, and xe end point of the two\ni\nxs\nxm\nxe\nf(xs)\nf(xm)\nf(xe)\nf(xs)f(xm)\nf(xm)f(xe)\nerror εd\n4.3750\n5.0000\n12.8496\n42.0000\n-\n+\n–\n4.3750\n12.8496\n-\n+\n0.31250\n3.9063\n-2.7166\n+\n-\n0.15625\n3.9063\n.9844\n-2.7166\n+\n-\n0.07813\n4.0234\n0.7092\n-\n+\n0.03906\n4.0234\n0.7092\n-\n+\n0.01953\n3.9941\n-0.1754\n+\n-\n0.00977\n3.9941\n-0.1754\n+\n-\n0.00488\n4.0015\n0.0440\n-\n+\n0.00244\n4.0015\n0.0440\n-\n+\n0.00122\n3.9996\n-0.0110\n+\n-\n0.00061\n3.9996\n-0.0110\n+\n-\n0.00031\n4.0001\n0.0027\n-\n+\n0.00015\n4.0001\n0.0027\n-\n+\n0.00008\n-0.0007\n+\n-\n0.00004\nPage 200 of 315", "word_count": 345, "start_char": 26849, "end_char": 28512}
{"chunk_id": "DOC0129__00019", "doc_id": "DOC0129", "chunk_index": 19, "text": "Example 6.3.6\nConsider finding the root of\nf(x) = e−x (3.2 sin x −0.5 cos x)\non the interval [3, 4], this time with εstep = 0.001, εabs = 0.001.\ni\nxs\nxe\nf(xs)\nf(xe)\nxm\nf(xm)\nεabs\n3.0000\n0.047127\n-0.038372\n0.5\n3.0000\n0.047127\n0.25\n3.3750\n-0.0086808\n0.125\n3.3750\n-0.0086808\n0.0625\n0.0313\n0.0156\n3.2890\n0.00091736\n0.0078\n3.2890\n0.00091736\n3.2929\n0.00044352\n0.0039\n3.2929\n0.00044352\n3.2948\n0.00021466\n0.002\n3.2948\n0.00021466\n3.2958\n0.000094077\n0.001\n3.2958\n0.000094077\n3.2963\n0.000034799\nRemark 6.3.2\nThus, after the 11th iteration, we note that the final interval, [3.2958, 3.2968]\nhas a width less than 0.001 and |f(3.2968)| = 0.000025 < 0.001 and therefore we chose xe =\n3.2968 to be our approximation of the root.\nAlthough it is xm = 3.2963 in the last interval, but it is not the better approximation, since\nscheme has not yet converged and yet |f(3.2963)| = 0.000035 a much more deviation from the\nexact value 0.00000 compared to f(3.2968)\nRemark 6.3.3 The Bisection scheme has not yet converged, but iteration terminated because\nof the required error achieved.\nPage 201 of 315", "word_count": 178, "start_char": 28512, "end_char": 29591}
{"chunk_id": "DOC0129__00020", "doc_id": "DOC0129", "chunk_index": 20, "text": "age 201 of 315\n\nExample 6.3.7\nThe root of\nex −2 = 0\nis known to exist in [0, 2]. Use 8 iterations to find an approximate value of the root (or find an\napproximate value of the root to within a tolerance of ε)\ni\nxs\nxm\nxe\nf(xs)\nf(xe)\nf(xm)\n0.0000\n1.0000000\n2.000000\n-1.0000\n5.3891\n0.0000\n0.5000000\n1.000000\n-1.0000\n0.5000\n0.7500000\n1.000000\n0.5000\n0.6250000\n-0.1318\n0.6250\n0.6875000\n-0.1318\n0.7187500\n0.0519\n0.7031250\n0.718750\n0.0201\n0.0519\n0.6953125\n0.703125\n0.0043\n0.0201\nExercise 6.3.1 Will the Bisection Method applied to f(x) = tan x and initial interval [a, b] =\n[1, 2] converge to a root? Why or why not? To which value, if any, will the Bisection Method\nconverge?\nExercise 6.3.2 If g(x) = cos x−2x, and [a1, b1] = [0, 1], use the Bisection Method to compute\nx3. Show your work.\nExercise 6.3.3\nConsider the equations\n(a) x5 + x = 1\n(b) sin x = 6x + 5\n(c) ln x + x2 = 3\nApply two steps of the Bisection Method to find an approximate root within 1/8 of the true\nroot.\nExercise 6.3.4\nApproximate to 2 decimal places the roots of the following equations using\nthe bisection method.\n(a) x2 = 3\n(b) x3 = 2\n(c) x4 = 2\nExercise 6.3.5 The function h(x) = x sin x occurs in the study of damped forced oscillation.\nFind the value of x that lies in the interval [0, 2] where the function takes on the value h(x) = 1.\nUse interval bisection.\nExercise 6.3.6\nIf a = 0.1 and b = 1.0, how many steps of the bisection method are needed\nto determine a root in this interval with an error of at most 1\n2 × 10−8?\nPage 202 of 315", "word_count": 295, "start_char": 29577, "end_char": 31089}
{"chunk_id": "DOC0129__00021", "doc_id": "DOC0129", "chunk_index": 21, "text": "se interval bisection.E\n\nxercise 6.3.6\nIf a = 0.1 and b = 1.0, how many steps of the bisection method are needed\nto determine a root in this interval with an error of at most 1\n2 × 10−8?P\n\nage 202 of 315\n\nExercise 6.3.7\nConsider obtaining the root of:\nf(x) = ex + 1 + sin x\n.\nShow that f(1.9) < 0, f(2.1) > 0 and use the bisection method to obtain the root.\nExercise 6.3.8\nFind the real root of the equation\nx3 −x2 −x + 1 = 0\nusing the bisection algorithm.\nExercise 6.3.9\nThe bisection method generates intervals [a0, b0], [a1, b1], and so on, which of\nthese inequalities are true for the root r that is being calculated?\n(a) |r −an| ≤2|r −bn|\n(b) |r −an| ≤2−n−1(b0 −a0)\n(c) |r −bn| ≤2−n−1(b0 −a0)\n(d) 0 ≤r −an2−n(b0 −a0)\n(e) |r −1\n2(an + bn)| ≤2−n−2(b0 −a0)\nExample 6.3.8\nFind all the real solutions to the cubic equation\nx3 + 4x2 −10 = 0\nin the interval [1, 2].\nExample 6.3.9 Use Newton’s method to find the roots of the cubic polynomial x3−3x+2 = 0\nin the interval\n(a) [0, 2]\n(b) [−3, −1]\nPage 203 of 315\n\n6.4\nSecant Method (Chords Method)\nThe Secant method needs two points near the root before the algorithm can be applied. Thus\nit is of the form\nxr+1 = f(xr, xr−1).\n6.4.1\nDerivation of the Secant method\nWe linear approximate the graph of y = f(x) in figure (10.1), by a chord passing through the\npoints A and B. The equation of this chord is,\nThe equation of the Chord is,\ny = f(x1) = [f(x0) −f(x1)](x −x1)\nx0 −x1\nThis Chord cuts the x-axis at x2 i.e.\n−f(x1) = f(x0) −f(x1)\n(x0 −x1)\n(x2 −x1)\ngiving, x2 = x1 −f(x1)(x1 −x0)\nor in general we have that,\nxn+1 = g(xn, xn−1)\nThat is\nxn+1 = xn −f(xn) [xn −xn−1]\nxn+1 = xn [f(xn) −f(xn−1)] −f(xn) [xn −xn−1]\nxn+1 = xnf(xn) −xnf(xn−1) −xnf(xn) + xn−1f(xn)\n(6.10)\nThe error in the (n + 1)th iterate is related to the error in the nth iterate en by the relation\nen+1 ≃Aek\nn where k ≃1.618 . . . and A is a constant. This relation suggests that the method\nhas order of convergence 1.618.\nPage 204 of 315", "word_count": 388, "start_char": 30886, "end_char": 32835}
{"chunk_id": "DOC0129__00022", "doc_id": "DOC0129", "chunk_index": 22, "text": "his relation suggests that the method\nhas order of convergence 1.618.P\n\nage 204 of 315\n\nExample 6.4.1\nUse the Secant method to find the root near 2 of the equation\nx3 −2x −5 = 0\nStart the iteration with x0 = 1.9, ⇒f(x0) = −1.941 and x1 = 2.0 ⇒f(x1) = −1.000.\n= (1.9)(−1.000) −(2.0)(−1.941)\n−1.000 −−1.941\n= 2.10627,\nf2 = 0.13166\n= (2.0)(0.13166) −(2.10627)(−1.000)\n0.13166 −−1.000\n= 2.09391,\nf3 = −0.00716\n= (2.10627)(−0.00716) −(2.09391)(0.13166)\n−0.00716 −0.13166\n= 2.09455, f4 = −0.00002\n= (2.09391)(−0.00002) −(2.09455)(−0.00716)\n−0.00002 −−0.00716\n= 2.09455\nThus since x4 and x5 are identical to 5 decimal places, so x5 = 2.09455 is the value of the root\ncorrect to five decimal places.\nExample 6.4.2\nEstimate the root of\nx4 −x −10 = 0\nwith the initial guess as 1.0 and 2.0 using the numerical Secant scheme. Take solutions to 5\nLet\nx0 = 1.0 ⇒f0 = −10.0\nx1 = 2.0 ⇒f1 = 4.0\nFor the Secant rule\n= (1.0)(4.0) −(2.0)(−10.0)\n4.0 −−10.0\n= 1.71429\n⇒f2 = −3.07780\n= (2.0)(−3.07780) −(1.71429)(4.0)\n−3.07780 −4.0\n= 1.83853\n⇒f3 = −0.41283\n= (1.71429)(−0.41283) −(1.83853)(−3.07780)\n−0.41283 −−3.07780\n= 1.85778\n⇒f4 = 0.05401\n= (1.83853)(0.05401) −(1.85778)(−0.41283)\n0.05401 −−0.41283\n= 1.85555\n⇒f5 = −0.00085\n= (1.85778)(−0.00085) −(1.85555)(0.05401)\n−0.00085 −0.05401\n= 1.85558\n⇒f6 = −0.00011\n= (1.85555)(−0.00011) −(1.85558)(−0.00085)\n−0.00011 −−0.00085\n= 1.85558\nPage 205 of 315\n\nSo the iterative process converges at 1.85558\nNote 6.4.1 If the function f(x) has a trigonometric term, the calculators better be in radians.\nExample 6.4.3\nApproximate the root of\nx −sin x −1\n2 = 0\nLet the initial guess be 1.0 and 2.0 using the Secant algorithm.\nLet x0 = 1.0 ⇒f0 = −0.34147 and x1 = 2.0 ⇒f1 = 0.59070\n= (1.0)(0.59070) −(2.0)(−0.34147)\n0.59070 −−0.34147\n= 1.36632\n⇒f2 = −0.11285\n= (2.0)(−0.11285) −(1.36632)(0.59070)\n−0.11285 −0.59070\n= 1.46796\n⇒f3 = −0.02676\n= (1.36632)(−0.02676) −(1.46796)(−0.11285)\n−0.02676 −−0.11285\n= 1.49955\n⇒f4 = 0.00209\n= (1.46796)(0.00209) −(1.49955)(−0.02676)\n0.00209 −−0.02676\n= 1.49726\n⇒f5 = −0.00004\n= (1.49955)(−0.00004) −(1.49726)(0.00209)\n−0.00004 −0.00209\n= 1.49730\n⇒f6 = 0.00000\n= (1.49726)(0.00000) −(1.49730)(−0.00004)\n−0.00000 −−0.00004\n= 1.49730\nSo the iterative process converges at 1.49730, and it is almost exact.\nExample 6.4.4\nLet the initial guess be −2.0 and −1.0, find the root of\n(x2 + 5x + 2)e−x + 1 = 0\nusing the Secant technique approximated to 5 decimal places.\nPage 206 of 315", "word_count": 388, "start_char": 32749, "end_char": 35173}
{"chunk_id": "DOC0129__00023", "doc_id": "DOC0129", "chunk_index": 23, "text": "xample 6.4.4\nLet the initial guess be −2.0 and −1.0, find the root of\n(x2 + 5x + 2)e−x + 1 = 0\nusing the Secant technique approximated to 5 decimal places.P\n\nage 206 of 315\n\nLet x0 = −2.0 ⇒f0 = −28.55622 and x1 = −1.0 ⇒f1 = −4.43656\n= (−2.0)(−4.43656) −(−1.0)(−28.55622)\n−4.43656 −−28.55622\n= −0.81606\n⇒f2 = −2.19865\n= (−1.0)(−2.19865) −(−0.81606)(−4.43656)\n−2.19865 −−4.43656\n= −0.63535\n⇒f3 = −0.45933\n= (−0.81606)(−0.45933) −(−0.63535)(−2.19865)\n−0.45933 −−2.19865\n= −0.58763\n⇒f4 = −0.06695\n= (−0.63535)(−0.06695) −(−0.58763)(−0.45933)\n−0.06695 −−0.45933\n= −0.57949\n⇒f5 = −0.00260\n= (−0.58763)(−0.00260) −(−0.57949)(−0.06695)\n−0.00260 −−0.06695\n= −0.57916\n⇒f6 = −0.00001\n= (−0.57949)(−0.00001) −(−0.57916)(−0.00260)\n−0.00001 −−0.00260\n= −0.57916\nThe approximated zero of\n(x2 + 5x + 2)e−x + 1 = 0\nis\n−0.57916\nto five decimal places.\nPage 207 of 315\n\nExample 6.4.5\nApply the Secant method to show that for the non linear equation\ncos x −xex = 0\nthe approximated roots are given by\nx0\nx1\nx2\nx3\nx4\nx5\nx6\nx7\nx8\n1.0\n2.0\n0.83267\n0.72878\n0.56240\n0.52478\n0.51801\n0.51776\n0.51776\nSo the iterative process converges at 0.51776\nExample 6.4.6 With initial conditions as x0 = 1.0 and x1 = 2.0, iterate with Secant method\nto show that for\nx −e−x = 0\nthe inexact solutions approximated to 5 decimal places are\nx0\nx1\nx2\nx3\nx4\nx5\nx6\n1.0\n2.0\n0.48714\n0.58378\n0.56739\n0.56714\n0.56714\nSo one of the roots of f(x) = x −e−x is approximately 0.56714\nExample 6.4.7\nFind the zero of the non linear equation\ne−x = 3 log10 x\nby the Secant method to 5 decimal places with the initial guess as 1.0 and 2.0\nx0\nx1\nx2\nx3\nx4\nx5\nx6\nx7\n1.0\n2.0\n1.32394\n1.22325\n1.24759\n1.24683\n1.24682\n1.24682\nSo one of the roots of e−x = 3 log10 x is approximately 1.24682.\nHint: The function f(x) used is\nf(x) = e−x −3 log10 x = 0\nPage 208 of 315", "word_count": 320, "start_char": 35001, "end_char": 36796}
{"chunk_id": "DOC0129__00024", "doc_id": "DOC0129", "chunk_index": 24, "text": "int: The function f(x) used is\nf(x) = e−x −3 log10 x = 0\nPage 208 of 315\n\nExample 6.4.8\nUse the Secant method to find a solution to x = cos x , and compare the\napproximations with those given by Newton’s method with x0 = π/4.\nFor the Secant method we need two initial approximations.\nSuppose we use x0 = 0.5 and\nx1 = π/4.\nn\nxn−1\nxn\nxn+1\n|xn+1 −xn|\n0.500000000\n0.785398163\n0.0490140246\n0.785398163\n0.739058139\n0.0026740004\n0.0000270101\n0.739058139\n0.739085133\n0.0000000161\nThe Newton’s method for x = cos x with x0 = π/4 is given by\nn\nxn\nf (xn)\nf ′ (xn)\nxn+1\n|xn+1 −xn|\n0.78539816\n-0.078291\n-1.707107\n0.73953613\n0.04586203\n0.73953613\n-0.000755\n-1.673945\n0.73908518\n0.00045096\n0.73908518\n-0.000000\n-1.673612\n0.00000004\n-0.000000\n-1.673612\n0.00000000\nObservations:\n• For Newton’s method, an excellent approximation is obtained with n = 2\n• Because of the agreement of x2 and x3 we could reasonably expect this result to be\naccurate to the places listed.\n• Comparing results, we see that the Secant Method approximation x4 is accurate to the\ntenth decimal place, whereas Newton’s method obtained this accuracy by x2.\n• Here, the convergence of the Secant method is much faster than functional iteration but\nslightly slower than Newton’s method.\nPage 209 of 315\n\n6.4.2\nAdvantages and Disadvantages of the Secant method\nThe method;\n1.) can work for double roots.\n2.) has order of convergence of 1.618.\n3.) is not always convergent.\nThe above are advantages or disadvantages depending on the comparison technique in question.\nRemark 6.4.1\nThe Secant method and Newton’s method are often used to refine an answer\nobtained by another technique (such as the Bisection Method).\nExercise 6.4.1\nFind the real root of\nf(x) = x3 + x2 −3x −3 = 0\nusing Secant technique correct to 2 decimal places.\nExercise 6.4.2\nShow that there is a root of the equation\nf(x) = 3x −sin x −ex = 0\nin the interval (0, 1). Estimate this root to 2 decimal places using the Secant method.\nExercise 6.4.3\nFind the roots of the following equations, using the methods of Secant.\n(a) ex = cos x\n(b) x3 −2x + 1 = 0\n(c) sin 2x −ex −1 = 0\n(d) ln(x −1) = x2\nExercise 6.4.4\nUse the Secant method to find the real root of the equation\nx3 + 2x2 −x + 5 = 0.\nExercise 6.4.5\nConsider obtaining the root of;\nf(x) = ex + sin x\nShow that f(1.9) < 0,\nf(2.1) > 0 and use the Secant method to obtain the root.\nPage 210 of 315", "word_count": 429, "start_char": 36724, "end_char": 39092}
{"chunk_id": "DOC0129__00025", "doc_id": "DOC0129", "chunk_index": 25, "text": "xercise 6.4.5\nConsider obtaining the root of;\nf(x) = ex + sin x\nShow that f(1.9) < 0,\nf(2.1) > 0 and use the Secant method to obtain the root.P\n\nage 210 of 315\n\n6.5\nThe Regula-Falsi method (Method of false position)\nThe regula falsi algorithm uses two points near the root before the algorithm is applied (a\nsimilar geometric approach like the Secant method-the regula falsi method is an associate of\nthe Secant method) with the exception that,\nf(xr)f(xr−1) < 0\nat each stage of the algorithm. This is termed as root bracketing, like in the Bisection method.\nThus to start the method, you need two points x0 = a0 and x1 = b0 near the root such that\nf(a0)f(b1) < 0\nThat is f(a0) and f(b0) are of opposite signs, which implies by the intermediate value theorem\nthat the function f has a root in the interval [a0, b0], assuming continuity of the function f.\nThe method proceeds by producing a sequence of shrinking intervals [ak, bk] that all contain a\nroot of f.\n6.5.1\nGeometric representation and derivation of the Regula falsi\nalgorithm\nFigure 6.4: The first two iterations of the false position method\nFrom Figure (6.4) above, we note that the produce f(x0)(f(x1) < 0, which is in conformity\nwith the regula falsi. The equation of the Chord CD is,\ny = f(x1) = [f(x0) −f(x1)](x −x1)\nx0 −x1\nThis Chord cuts the x-axis at x2 i.e.\n−f(x1) = f(x0) −f(x1)\n(x0 −x1)\n(x2 −x1)\ngiving, x2 = x1 −f(x1)(x1 −x0)\nPage 211 of 315\n\nor in general we have that,\nxn+1 = g(xn, xn−1)\nThat is\nxn+1 = xn −f(xn) [xn −xn−1]\nxn+1 = xn [f(xn) −f(xn−1)] −f(xn) [xn −xn−1]\nxn+1 = xnf(xn) −xnf(xn−1) −xnf(xn) + xn−1f(xn)\n(6.11)\nEquation (6.11) is the popular Regula false/falsi position method with condition that at each\nstage of the algorithm,\nf(xn)f(xn−1) < 0\n(6.12)\nPage 212 of 315", "word_count": 319, "start_char": 38933, "end_char": 40688}
{"chunk_id": "DOC0129__00026", "doc_id": "DOC0129", "chunk_index": 26, "text": "Example 6.5.1 Find the root between (2, 3) of x3 −2x−5 = 0, by using regula falsi method.\nApproximate values to 3 decimal places.\nLet us take x0 = 2 and x1 = 3.\nf(x) = x3 −2x −5\nf(x0) = f(2) = 23 −2(2) −5 = −1 < 0 (negative)\nf(x1) = f(3) = 33 −2(3) −5 = 16 > 0 (positive)\nThe first approximation to root is x2 and is given by\n= 2f(3) −(3)f(2)\nf(3) −f(2)\n= 2(16) −(3)(−1)\n16 −(−1)\n= 35\n17 = 2.059\n⇒f(2.059) = −0.389 < 0\nThe root lies between x2 = 2.059 and x1 = 3\nTaking x2 = 2.059 and x1 = 3. we have the second approximation to the root given by\n= (3)f(2.059) −2.059f(3)\nf(2.059) −f(3)\n= (3)(−0.389) −2.059(16)\n(−0.389) −16\n= 2.081\n⇒f(2.081) = −0.150 < 0\nThe root lies between x3 = 2.081 and x1 = 3\nTaking x3 = 2.081 and x1 = 3. we have the third approximation to the root given by\n= (3)f(2.081) −2.081f(3)\nf(2.081) −f(3)\n= (3)(−0.150) −2.081(16)\n(−0.15) −16\n= 2.090\n⇒f(2.090) = −0.051 < 0\nThe root lies between x4 = 2.090 and x1 = 3\nTaking x4 = 2.090 and x1 = 3. we have the fourth approximation to the root given by\n= (3)f(2.090) −2.090f(3)\nf(2.090) −f(3)\n= (3)(−0.051) −(2.090)(16)\n(−0.051) −16\n= 2.091\nIf we need a root to 3 decimal places, we could still continue with the iterations (the root lies\nbetween x5 = 2.091 and x1 = 3), but if to 2 decimal places, the required root is 2.09\nPage 213 of 315", "word_count": 269, "start_char": 40688, "end_char": 41994}
{"chunk_id": "DOC0129__00027", "doc_id": "DOC0129", "chunk_index": 27, "text": "Example 6.5.2\nApproximate a root of\nusing the regula falsi scheme of solving non linear equations f(x) = 0 to 3 decimal places on\nthe interval [0, 0.5].\nIf we sketch the function f(x) it’s clear that there is a root between 0 and 0.5 and also another\nroot between 1.5 and 2.0. Now let us consider the function f(x) in the interval [0, 0.5] where\nf(0) × f(0.5) is less than zero and use the regula-falsi scheme to obtain the zero of f(x) = 0.\nLet x0 = 0.0 ⇒f0 = −1.000 < 0 and x1 = 0.5 ⇒f1 = 0.331 > 0\n= (0.0)(0.331) −(0.5)(−1.000)\n0.331 −−1.000\n= 0.376, ⇒f2 = 0.039 > 0\nx3 = x0f(x2) −x2f(x0)\nf(x2) −f(x0)\n= (0.0)(0.039) −(0.376)(−1.000)\n0.039 −−1.000\n= 0.362, ⇒f3 = 0.004 > 0\nx4 = x0f(x3) −x3f(x0)\nf(x3) −f(x0)\n= (0.0)(0.004) −(0.362)(−1.000)\n0.004 −−1.000\n= 0.361, ⇒f4 = 0.001 > 0\nx5 = x0f(x4) −x4f(x0)\nf(x4) −f(x0)\n= (0.0)(0.001) −(0.361)(−1.000)\n0.001 −−1.000\n= 0.360, ⇒f5 = −0.001 < 0\nx5 = x4f(x5) −x5f(x4)\n= (0.361)(−0.001) −(0.360)(0.001)\n−0.001 −0.001\n= 0.360\nis approximately 0.360.\nPage 214 of 315\n\nExample 6.5.3\nEstimate the zero of the equation\nx cos\n\u0012\nx\nx −2\n\u0013\n= 0\nwith the initial guess of x0 = 1 and x1 = 1.5 to 3 decimal places using the popular regula falsi\ntechnique.\nLet\nx0 = 1.0 ⇒f0 = 0.540 > 0\nx1 = 1.5 ⇒f1 = −1.485 < 0\n= (1.0)(−1.485) −(1.5)(0.540)\n−1.485 −0.540\n= 1.133, ⇒f2 = 0.296 > 0\n= (1.5)(0.296) −(1.133)(−1.485)\n0.296 −−1.485\n= 1.194, ⇒f3 = 0.107 > 0\n= (1.5)(0.107) −(1.194)(−1.485)\n0.107 −−1.485\n= 1.214, ⇒f4 = 0.032 > 0\n= (1.5)(0.032) −(1.214)(−1.485)\n0.032 −−1.485\n= 1.220, ⇒f5 = 0.008 > 0\n= (1.5)(0.008) −(1.220)(−1.485)\n0.008 −−1.485\n= 1.222, ⇒f6 = 0.000 > 0\n= (1.5)(0.000) −(1.222)(−1.485)\n0.000 −−1.485\n= 1.222\nx cos\n\u0012\nx\nx −2\n\u0013\n= 0\nis approximately\n1.222\nto 3 decimal places.\nPage 215 of 315", "word_count": 331, "start_char": 41994, "end_char": 43721}
{"chunk_id": "DOC0129__00028", "doc_id": "DOC0129", "chunk_index": 28, "text": "age 215 of 315\n\nExample 6.5.4\nUse the Regula-Falsi method to compute a real root of the equation\nx3 −9x + 1 = 0,\n(a) if the root lies between 2 and 4\n(b) if the root lies between 2 and 3.\nComment on the results.\nLet x0 = 2.0 ⇒f0 = −9 < 0 and x1 = 4.0 ⇒f1 = 29 > 0, For the regula falsi\n= 2.4736, ⇒f2 = −6.12644 < 0\n= 2.73989, ⇒f3 = −3.090707 < 0\n= 2.86125, ⇒f4 = −1.326868 < 0\n...\nLet x0 = 2.0 ⇒f0 = −9 < 0 and x1 = 3.0 ⇒f1 = 1 > 0, For the regula falsi\n= 2.90000, ⇒f2 = −0.7110 < 0\n= 2.94156, ⇒f3 = −0.0207 < 0\n= 2.94275, ⇒f4 = −0.0011896 < 0\n...\nWe observe that the value of the root as a third approximation is evidently different in both\nthe cases, while the value of x4, when the interval considered is (2, 3), is closer to the root.\nImportant observation: The initial interval (x0, x1) in which the root of the equation lies should\nbe sufficiently small.\nPage 216 of 315\n\nExample 6.5.5\nUse Regula-Falsi method to find a real root of the equation\nln x −cos x = 0\naccurate to four decimal places after three successive approximations.\nLet\nx0 = 1.0 ⇒f0 = −0.540302 < 0\nx1 = 2.0 ⇒f1 = 1.109 > 0\n= (1.0)(1.109) −(2.0)(−0.540302)\n1.109 −−0.540302\n= 1.3275\n⇒f2 = 0.0424 > 0\nNext iteration to be for x0 and x2 since f0f2 < 0, change signs\nx3 = x0f(x2) −x2f(x0)\nf(x2) −f(x0)\n= (1.0)(0.0424) −(1.3275)(−0.540302)\n0.0424 −−0.540302\n= 1.3037\n⇒f3 = 0.001248 > 0\nNext iteration to be for x0 and x3 since f0f3 < 0, change signs\nx4 = x0f(x3) −x3f(x0)\nf(x3) −f(x0)\n= (1.0)(0.001248) −(1.3037)(−0.540302)\n0.001248 −−0.540302\n= 1.3030\nThe required real root is 1.3030\nNote 6.5.1\nThe iterations have not converged, but we were interested in up to the third\niteration.\nNote 6.5.2\nFor Matlab program for the non linear equation, we write ln x as log x, where as\nlog x as log10 x\nPage 217 of 315", "word_count": 360, "start_char": 43707, "end_char": 45485}
{"chunk_id": "DOC0129__00029", "doc_id": "DOC0129", "chunk_index": 29, "text": "ote 6.5.2\nFor Matlab program for the non linear equation, we write ln x as log x, where as\nlog x as log10 x\nPage 217 of 315\n\nExample 6.5.6\nUse the method of false position to solve\nex + 2−x + 2 cos x −6 = 0 1 ≤x ≤2\ncorrect your approximations to 4 decimal places.\nLet\nx0 = 1.0 ⇒f0 = −1.7011 < 0\nx1 = 2.0 ⇒f1 = 0.8068 > 0\n= (1.0)(0.8068) −(2.0)(−1.7011)\n0.8068 −−1.7011\n= 1.6783, ⇒f2 = −0.5457 < 0\n= (2.0)(−0.5457) −(1.6783)(0.8068)\n−0.5457 −0.8068\n= 1.8081, ⇒f3 = −0.0858 < 0\n= (2.0)(−0.0858) −(1.8081)(0.8068)\n−0.0858 −0.8068\n= 1.8265, ⇒f4 = −0.0118 < 0\n= (2.0)(−0.0118) −(1.8265)(0.8068)\n−0.0118 −0.8068\n= 1.8290, ⇒f5 = −0.0016 < 0\n= (2.0)(−0.0016) −(1.8290)(0.8068)\n−0.0016 −0.8068\n= 1.8293, ⇒f6 = −0.0003 < 0\n= (2.0)(−0.0003) −(1.8294)(0.8068)\n−0.0003 −0.8068\n= 1.8294, ⇒f7 = 0.0001 > 0\nx8 = x6f(x7) −x7f(x6)\nf(x7) −f(x6)\n= (1.8293)(0.0001) −(1.8294)(−0.0003)\n0.0001 −−0.0003\n= 1.8294\nSo the root of\nex + 2−x + 2 cos x −6 = 0\nis approximately 1.8294 to 4 decimal places. Analytically, the exact value would be 1.82938.\nRemark 6.5.1\nLook back at how x8 was computed, how and why it was x6 and x7 paired\ntogether, and not x7 with x1.\nPage 218 of 315\n\nExample 6.5.7\nSolve the equation\n2x cos 2x −(x −2)2 = 0 2 ≤x ≤3\ncorrect your approximations to 4 decimal places. Perform only four iterations.\nLet\nx0 = 2.0 ⇒f0 = −2.6146 < 0\nx1 = 3.0 ⇒f1 = 4.7610 > 0\n= (2.0)(4.7610) −(3.0)(−2.6146)\n4.7610 −−2.6146\n= 2.3545\n⇒f2 = −0.1416 < 0\n= (3.0)(−0.1416) −(2.3545)(4.7610)\n−0.1416 −4.7610\n= 2.3731\n⇒f3 = 0.0212 > 0\n= (2.3545)(0.0212) −(2.3731)(−0.1416)\n0.0212 −−0.1416\n= 2.3707\n⇒f4 = 0.0001 > 0\nx5 = x2f(x4) −x4f(x2)\nf(x4) −f(x2)\n= (2.3545)(0.0001) −(2.3707)(−0.1416)\n0.0001 −−0.1416\n= 2.3707\nRemark 6.5.2\nThe scheme converges after the fourth iteration and converges to 2.3707.\nIn fact, one of the classical root of the non linear equation\n2x cos 2x −(x −2)2 = 0\nis\n2.37069\nRemark 6.5.3\nIn every next iteration, the previous point must be part of it.\nPage 219 of 315", "word_count": 360, "start_char": 45362, "end_char": 47319}
{"chunk_id": "DOC0129__00030", "doc_id": "DOC0129", "chunk_index": 30, "text": "n fact, one of the classical root of the non linear equation\n2x cos 2x −(x −2)2 = 0\nis\n2.37069\nRemark 6.5.3\nIn every next iteration, the previous point must be part of it.P\n\nage 219 of 315\n\nExample 6.5.8\nUsing Regula-Falsi algorithm, approximate the real root of\nf(x) = x3 −2x −2 = 0\nNow since, f(1) = −3 < 0 and f(2) = 2 > 0 and f(x) is continuous for all real x, there exists\nx⋆∈(1, 2) such that f(x⋆) = 0 (the intermediate value theorem).\nLet x0 = 1.0 ⇒f0 = −3.00000 < 0 and x1 = 2.0 ⇒f1 = 2.00000 > 0,\n= (1.0)(2.00000) −(2.0)(−3.00000)\n2.00000 −−3.00000\n= 1.60000, ⇒f2 = −1.10400 < 0\n= (2.0)(−1.10400) −(1.60000)(2.00000)\n−1.10400 −2.00000\n= 1.74227\n⇒f3 = −0.19587 < 0\n= (2.0)(−0.19587) −(1.74227)(2.00000)\n−0.19587 −2.00000\n= 1.76526\n⇒f4 = −0.02972 < 0\n= (2.0)(−0.02972) −(1.76526)(2.00000)\n−0.02972 −2.00000\n= 1.76870\n⇒f5 = −0.00438 < 0\n= (2.0)(−0.00438) −(1.76870)(2.00000)\n−0.00438 −2.00000\n= 1.76921\n⇒f6 = −0.00061 < 0\n= (2.0)(−0.00061) −(1.76921)(2.00000)\n−0.00061 −2.00000\n= 1.76928\n⇒f7 = −0.00009 < 0\nx8 = x1f(x7) −x7f(x1)\nf(x7) −f(x1)\n= (2.0)(−0.00009) −(1.76928)(2.00000)\n−0.00009 −2.00000\n= 1.76929\n⇒f8 = −0.00002 < 0\nx9 = x1f(x8) −x8f(x1)\nf(x8) −f(x1)\n= (2.0)(−0.00002) −(1.76929)(2.00000)\n−0.00002 −2.00000\n= 1.76929\nThe numerical solution is therefore 1.76929 to five decimal points.\nPage 220 of 315", "word_count": 225, "start_char": 47131, "end_char": 48448}
{"chunk_id": "DOC0129__00031", "doc_id": "DOC0129", "chunk_index": 31, "text": "age 220 of 315\n\nExample 6.5.9 Use the method of False Position to find a solution to x = cos x, and compare\nthe approximations with those given by the Newton’s method and the Secant Method. Let the\ninitial approximations be x0 = 0.5 and x1 = π\nFalse Position\nSecant\nNewton-Raphson\nn\nxn\nxn\nxn\n0.5\n0.5\n0.5\n0.7363841388\n0.7363841388\n0.7395361337\n0.7390581392\n0.7390581392\n0.7390851781\n0.7390848638\n0.7390851493\n0.7390851305\nNote 6.5.3\nNote that the False Position and Secant approximations agree through x3 and\nthat the method of False Position requires an additional iteration to obtain the same accuracy\nas the Secant method.\nRemark 6.5.4\n• The added insurance of the method of False Position commonly requires more calculation\nthan the Secant method, . . .\n• just as the simplification that the Secant method provides over Newton’s method usually\ncomes at the expense of additional iterations.\nExample 6.5.10\nThe function\nf(x) = x2ex −1\nhas a root in the interval [0, 1] since f(0)f(1) < 0. The results from the false position and\nsecant methods, both started with x0 = 0 and x1 = 1, are shown in the table\nIterates\nFalse position\nSecant\nx2\n0.3679\n0.3679\nx3\n0.5695\n0.5695\nx4\n0.6551\n0.7974\nx5\n0.6868\n0.6855\nx6\n0.6978\n0.7012\nx7\n0.7016\n0.7035\nIt appears from these results that the secant method gives the correct result x = 0.7035 a little\nmore quickly.\n6.5.2\nOrder of Convergence of the Regula algorithm\nThe error in the (n + 1)th iterate (denoted en+1) is related to the error in the nth iterate en by\nthe equation,\nen+1 ≃Aek\nn\nwhere k = 1.\nThis suggests that although the regula falsi uses the same formula as the\nSecant method, the order of convergence of the regula falsi is one compared to ≃1.618 for the\nSecant. Thus, the method is slower at converging to the root compared to the Secant method.\nHowever, with the condition f(xr)f(xr−1) < 0 at each stage, ensures that the regula falsi is\nalways convergent which is not the case with Secant method.\nPage 221 of 315", "word_count": 345, "start_char": 48434, "end_char": 50403}
{"chunk_id": "DOC0129__00032", "doc_id": "DOC0129", "chunk_index": 32, "text": "hus, the method is slower at converging to the root compared to the Secant method.H\n\nowever, with the condition f(xr)f(xr−1) < 0 at each stage, ensures that the regula falsi is\nalways convergent which is not the case with Secant method.P\n\nage 221 of 315\n\n6.5.3\nAdvantages and disadvantages of the regula falsi algorithm\n1.) The regula falsi algorithm is always convergent.\n2.) The order of convergence of the method is one.\nThe two basic points on the advantages and disadvantages.\nWhether it is an advantage or a disadvantage it all depends on the comparison in question. For\ninstance in comparison with the Secant method, it is disadvantageous that the regula falsi has\norder of convergence one. While it is advantageous that it is always convergent.\nExercise 6.5.1\nFind the approximate value of the real root of\nx log10 x = 1.2\nby regula falsi method\nExercise 6.5.2\nFind the root of the\nxex = 3\nby regula falsi method and correct to the three decimal places\nExercise 6.5.3\nFind a root which lies between 1 and 2 of\nf(x) = x3 + 2x2 + 10x −20\n(Leonardo’s Equation) using the regula falsi method\nExercise 6.5.4\nUse the regula false algorithm to find the root of\nf(x) = x2 −4x + 2 = 0\nthat lies in the interval (0, 1) and state your answer correct to three decimal places.\nExercise 6.5.5\nVerify that x = 3 is a solution of x = g(x) where\ng(x) =\n18x\n(x2 + 9).\nUse the regula false to approximate this root.\nExercise 6.5.6\nConsider the equation\nf(x) = ex + 1 + sin x\n= 0\nwhose root you would want to find. Show that\nf(1.9) < 0, f(2.1) > 0\nand use the regula false algorithm to compute this root.\nPage 222 of 315", "word_count": 303, "start_char": 50150, "end_char": 51758}
{"chunk_id": "DOC0129__00033", "doc_id": "DOC0129", "chunk_index": 33, "text": "se the regula false to approximate this root.E\n\nxercise 6.5.6\nConsider the equation\nf(x) = ex + 1 + sin x\n= 0\nwhose root you would want to find.S\n\nhow that\nf(1.9) < 0, f(2.1) > 0\nand use the regula false algorithm to compute this root.P\n\nage 222 of 315\n\nExercise 6.5.7 Approximate to three decimal places the roots of the following equations using\nthe regula false algorithm.\n(a) x3 = 2\n(b) x2 = 3\n(c) x4 = 2\n(d) x5 = 3\nExercise 6.5.8\n(a) Derive the regula falsi algorithm by clearly giving its geometrical illustration.\n(b) What advantages and disadvantages does the Secant method enjoy over other methods so\nfar considered for solving nonlinear equations.\nExercise 6.5.9\nUse both the Falsi Position and Bisection to solve the same equation\nf(d) = 2552 −30d2 + d3 = 0\nand see if there is a difference in the number of steps falsi Position takes to converge versus\nBisection.\nExercise 6.5.10\nFind the solution of x3 + x −4 = 0 in the interval [1, 4] with accuracy 10−3. Apply\n(a) Newton Raphson method\n(b) Bisection algorithm\n(c) Regular Falsi scheme\nExercise 6.5.11 Approximate the solution of x3−x−1 = 0 in the interval [1, 2] with accuracy\n10−4 with the Bisection method.\nExercise 6.5.12\nUse Newton’s method to solve the equation x3 −x −1 = 0\nExercise 6.5.13\nThe fourth-degree polynomial\nf(x) = 230x4 + 18x3 + 9x2 −221x −9\nhas two real zeros, one in [−1, 0] and the other in [0, 1]. Attempt to approximate these zeros\nto within 10−6 using the Regular Falsi method.\nSummary 6.1\nIncreased number of decimal points and/or increased size of interval given\nboth increase the number of iterations as they increase.\nHowever, increased number of decimal points and/or increased size of interval given both improve on the accuracy of the scheme.\nPage 223 of 315", "word_count": 315, "start_char": 51506, "end_char": 53261}
{"chunk_id": "DOC0129__00034", "doc_id": "DOC0129", "chunk_index": 34, "text": "ttempt to approximate these zeros\nto within 10−6 using the Regular Falsi method.S\n\nummary 6.1\nIncreased number of decimal points and/or increased size of interval given\nboth increase the number of iterations as they increase.H\n\nowever, increased number of decimal points and/or increased size of interval given both improve on the accuracy of the scheme.P\n\nage 223 of 315\n\n6.6. SUCCESSIVE SUBSTITUTION (FIXED POINT METHOD)\n6.6\nSuccessive Substitution (Fixed Point Method)\n6.6.1\nBackground knowledge\nSuccessive substitution is one of the iterative techniques for solving nonlinear equations. Iterative techniques start with an initial value/guess x0 to the root α and then using a suitable recurrence relation we generate a sequence of approximations {xk}∞\nk=o. If the sequence {x0, x1, . . .}\nconverges, then it does so on the required root. Iterative techniques are written in the form\nxn+1 = g(xn),\nn = 0, 1, 2, . . . ,\nif the next iterate xn+1 depends on the previous one xn.\nor xn+1 = gr(xn, xn−1), n = 1, 2, . . . ,\nif the next iterate depends on the previous two i.e. xn and xn−1.\n6.6.2\nSuccessive Substitutions\nIn the method, we seek the roots of,\nf(x) = 0.\n(6.13)\nWe try to split f(x) in the form,\nf(x) = x −g(x)\n(6.14)\nHowever, this splitting may not be unique. But not all the different splittings may be useful to\nus. We can determine the type of splitting which is useful to a numerical analyst. Now, instead\nof solving equation (6.13) we now solve x = g(x). The scheme for solving this problem is given\nby the algorithm;\nxn+1 = g(xn), n = 0, 1, 2, . . .\nThus we start with a suitable value x0, and generate the sequence of approximations\nx1 = g(x0)\nx2 = g(x1)\nx3 = g(x2)\nx4 = g(x3)\n...\nxn+1 = g(xn)\n...\n...\nThat is, the sequence is {x1, x2, . . . , xn, . . .}\nPage 224 of 315", "word_count": 331, "start_char": 52890, "end_char": 54678}
