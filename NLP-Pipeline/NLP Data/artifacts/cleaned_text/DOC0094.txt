MTH2206: LINEAR ALGEBRA
EASTER SEMESTER 2025
D.W. Ddumba & P. Musisi
Department of Computing and Technology
Uganda Christian University

Contents
Matrices
1.1
Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2
Other Special Types of Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.1
Diagonal Matrix
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.2
Tri-Diagonal Matrix
1.2.3
Triangular Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.4
Idempotent Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.5
Invertible or Non-Singular Matrix . . . . . . . . . . . . . . . . . . . . . .
1.3
Operations on Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.1
Addition and Scalar Multiplication of matrices . . . . . . . . . . . . . . .
1.3.2
Multiplication of Matrix by Matrix . . . . . . . . . . . . . . . . . . . . .
1.3.3
Trace of a Square Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4
Properties of Matrices Operations . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.1
Properties of Matrix Addition and Scalar Multiplication
. . . . . . . . .
1.4.2
Properties of Matrix Multiplication . . . . . . . . . . . . . . . . . . . . .
1.4.3
Properties of Matrix Transpose
. . . . . . . . . . . . . . . . . . . . . . .
1.4.4
Properties of the Matrix Trace . . . . . . . . . . . . . . . . . . . . . . . .
1.5
Determinants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.5.1
Permutations and Inversion of a Permutation
. . . . . . . . . . . . . . .
1.5.2
Matrix Adjoint, Minors and Cofactors
. . . . . . . . . . . . . . . . . . .
1.5.3
Properties of Determinants . . . . . . . . . . . . . . . . . . . . . . . . . .
1.6
Matrix Inverses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.6.1
Inverse Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.6.2
Direct Method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.6.3
Adjoint Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.6.4
Method of Elementary Row Operation(Gauss-Jordan Elimination Method) 26
1.6.5
Properties of Matrix Inverse . . . . . . . . . . . . . . . . . . . . . . . . .
1.7
Matrices Chapter Examples
1.8
Matrices Chapter Exercises
Simultaneous Linear Systems
2.1
Solving Linear Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2
A Linear System of Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3
Row Reduction to Echelon Form . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1
Methodology of Row Reduction for Solutions . . . . . . . . . . . . . . . .
2.4
Existence of a Solution to a Linear System . . . . . . . . . . . . . . . . . . . . .
2.4.1
Unique Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2
No Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.3
Infinitely Many Solutions . . . . . . . . . . . . . . . . . . . . . . . . . .

CONTENTS
2.5
Computer Algebra Systems
2.6
Input-Output Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.7
Analyzing Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.8
Algebra in Real World Problems . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.9
Linear Systems Chapter Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 100
2.10 Linear Systems Chapter Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . 110
Vector Spaces and Vector Subspaces
3.1
Vectors in Rn, Cn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3.2
Vector Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
3.3
Scalar Multiplication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
3.3.1
Properties of Vector Addition . . . . . . . . . . . . . . . . . . . . . . . . 125
3.3.2
Properties of Scalar Multiplication (Product)
. . . . . . . . . . . . . . . 125
3.4
Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.4.2
Vector Space
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.5
Vector Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
3.6
End of chapter Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
3.7
Vector Spaces Chapter Examples
. . . . . . . . . . . . . . . . . . . . . . . . . . 148
Linear Dependance and Independence
4.1
Linear Combination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
4.2
Spanning Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
4.3
Linear Dependence and Independence . . . . . . . . . . . . . . . . . . . . . . . . 152
4.4
Linear Dependence and Independence Chapter Examples . . . . . . . . . . . . . 154
4.5
Linear Dependence and Independence Chapter Exercises
. . . . . . . . . . . . . 175
Eigenvalues and Eigenvectors
5.1
Eigenvalues & Corresponding Eigenvectors. . . . . . . . . . . . . . . . . . . . . . 194
5.1.1
Algebraic and Geometric Multiplicity of an Eigenvalue
. . . . . . . . . . 201
5.2
Similar Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
5.2.1
Properties of Similar Matrices . . . . . . . . . . . . . . . . . . . . . . . . 205
5.3
Diagonisable Matrices
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
5.4
Eigen Values and Eigen Vectors Chapter Examples
. . . . . . . . . . . . . . . . 217
5.4.1
Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
5.5
Eigen Values and Eigen Vectors Chapter Exercises . . . . . . . . . . . . . . . . . 240
Linear Algebra By Python
Page of 246

Chapter 1
Matrices
1.1
Definitions
Definition 1.1.1 An m Ã— n matrix is a rectangular array of m Ã— n numbers arranged in m
horizontal rows and n vertical columns enclosed in brackets. These numbers in the matrix are
called elements (entries) of the matrix. Matrices are always denoted by capital letters(block
letters) while matrix entries are denoted by small letters. A matrix A can be generally written
as
A =
ï£«
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£­
a11
a12
Â· Â· Â·
a1n
a21
a22
Â· Â· Â·
a2n
...
Â· Â· Â·
...
Â· Â· Â·
...
Â· Â· Â·
am1
am2
. . .
amn
ï£¶
ï£·
ï£·
ï£·
ï£·
ï£·
ï£·
ï£·
ï£·
ï£¸
or A =
ï£®
a11
a12
Â· Â· Â·
a1n
a21
a22
Â· Â· Â·
a2n
...
Â· Â· Â·
...
Â· Â· Â·
...
Â· Â· Â·
am1
am2
. . .
amn
ï£¹
Or more briefly (for notation) we have that A = (aij) or B = (bij) where aij (respectively bij)
is an entry in the ith row and jth column of A (respectively B).
Definition 1.1.2 Square Matrix:
An m Ã— n matrix A denoted by AmÃ—n or Amn is said to be square if m = n (that is the number
of rows is equal to the number of columns).
Definition 1.1.3 Equality of Matrices:
If two matrices A = (aij) and B = (bij) are both m Ã— n then they are said to be equal if and
only if all corresponding entries of A and B are the same that is
aij = bij, âˆ€1 â‰¤i â‰¤m, 1 â‰¤j â‰¤n.
Example 1.1.1
Let
A =
 a11
a12
a21
a22

and
B =
 4
âˆ’1

.
Then
A = B if and only if
a11 = 4,
a12 = 0,
a21 = 3,
a22 = âˆ’1.
Example 1.1.2
The following matrices are all different. Explain!
 1

 4

 4

 1

 0


1.1. DEFINITIONS
Definition 1.1.4 Matrix Transpose:
Let A = (aij) be an m Ã— n matrix, then the transpose of A denoted by At or AT or Aâ€² is an
n Ã— m matrix obtained from matrix A by interchanging its rows with columns.
In the (aij) notation we have that AT = (aij)T where (aij)T = (aji) âˆ€i, j. We can also write
AT = (aji).
Note 1.1.1 The transpose of matrix A is determined by interchanging the rows with columns
of A that is if A is an n Ã— m matrix then the transpose of A, denoted by AT, is an m Ã— n
matrix that is obtained by interchanging the rows and columns of A. So, the first row of AT is
the first column of A, the second row of AT is the second column of A, etc. Likewise, the first
column of AT is the first row of A, the second column of AT is the second row of A, etc.
Example 1.1.3
The transpose of a general 3 Ã— 3 matrix
A =
ï£«
ï£­
a11
a12
a13
a21
a22
a23
a31
a32
a33
ï£¶
ï£¸is AT =
ï£«
ï£­
a11
a21
a31
a12
a22
a32
a13
a23
a33
ï£¶
ï£¸
Example 1.1.4
The transpose of the matrix A given by,
A =
ï£«
ï£­
âˆ’1
ï£¶
ï£¸is AT =
ï£«
ï£­
âˆ’1
ï£¶
ï£¸
Definition 1.1.5 Symmetric Matrices:
A square matrix A is said to be symmetric if its transpose matrix AT is equal to A that is
AT = A.
Example 1.1.5
Matrix A in Example 1.1.4 is not symmetric since A Ì¸= AT.
Example 1.1.6
ï£®
ï£°
ï£¹
ï£», then AT =
ï£®
ï£°
ï£¹
ï£». Hence AT = A, implying
that A is symmetric.
Example 1.1.7
 âˆ’7
âˆ’6

is symmetric.
Definition 1.1.6 Anti-Symmetric Matrices:
A matrix A is said to be anti-symmetric (sometimes called skew-symmetric) if AT = âˆ’A.
Example 1.1.8
Let
B =
ï£«
ï£­
âˆ’2
âˆ’1
âˆ’3
ï£¶
ï£¸then BT =
ï£«
ï£­
âˆ’1
âˆ’3
âˆ’2
ï£¶
ï£¸
Thus BT = âˆ’B and B is anti-symmetric (skew symmetric).
Remark 1.1.1
Symmetric and Skew Symmetric Matrices
1.) Given any matrix A, the matrices AAT and ATA are symmetric.
Page 2 of 246

1.1. DEFINITIONS
2.) Let A be a square matrix. The matrix A + AT is symmetric.
3.) Let A be a square matrix. The matrix A âˆ’AT is skew symmetric.
Definition 1.1.7 Identity or Unit matrix:
An identity matrix is an (n Ã— n) square matrix whose leading diagonal is composed of 1â€™s and
all other off diagonal elements are zeros. An identity matrix is of the form,
In =
ï£«
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£¬
ï£­
. . .
. . .
Â·
Â·
Â·
. . .
ï£¶
ï£·
ï£·
ï£·
ï£·
ï£·
ï£·
ï£¸
=
ï£±
ï£²
ï£³
aij = 1,
âˆ€i = j
aij = 0,
âˆ€i Ì¸= j
usually denoted as In or I with a nice property that I Â· A = A Â· I = A where A is an n Ã— n
matrix.
Example 1.1.9
The following is a 2 Ã— 2 identity matrix
I2 =
1

Example 1.1.10
The following is a 3 Ã— 3 identity matrix
I3 =
ï£®
ï£°
ï£¹
ï£»
Example 1.1.11
The following is a 1 Ã— 1 identity matrix
I1 = 1
Example 1.1.12
The following is a 4 Ã— 4 identity matrix
I4 =
ï£®
ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£»
Example 1.1.13
Check the following matrix is Identity matrix?
V =
ï£®
ï£°
ï£¹
ï£»
Solution :
No, Itâ€™s not an identity matrix, because it is of the order 3 Ã— 4, which
is not a square matrix.
â– 
Page 3 of 246

1.2
Other Special Types of Matrices
1.2.1
Diagonal Matrix
Definition 1.2.1
A square matrix A = (aij) is said to be a diagonal if
aij = 0 âˆ€i Ì¸= j.
This means that off diagonal elements are all equal to zero.
Definition 1.2.2
A diagonal matrix is an n Ã— n matrix in which the only nonzero entries lie
on the diagonal.
Example 1.2.1
The matrices
ï£®
ï£°
âˆ’1
ï£¹
ï£»and
ï£®
ï£°
ï£¹
ï£»are diagonal matrices.
1.2.2
Tri-Diagonal Matrix
Definition 1.2.3 A square matrix A = (aij) is said to be a tri-diagonal if aij = 0 for |iâˆ’j| â‰¥2,
that is if every element in the ith row and jth column is zero when the absolute difference between
i and j is greater or equal to two.
Example 1.2.2
A general 3 Ã— 3 tri-diagonal matrix is of the form
A =
ï£®
ï£°
a11
a12
a21
a22
a23
a32
a33
ï£¹
ï£»
Example 1.2.3
ï£®
ï£°
âˆ’1
ï£¹
ï£»is a tri-diagonal matrix.
1.2.3
Triangular Matrix
Definition 1.2.4 A triangular matrix is a square matrix whose non-zero elements lie on the
diagonal, and all the zero entries are either above or below the diagonal.
Example 1.2.4 The matrices A =
ï£®
ï£°
âˆ’1
ï£¹
ï£»and B =
ï£®
ï£°
âˆ’1
ï£¹
ï£»are triangular matrices.
1.2.3.1
Upper Triangular Matrix
Definition 1.2.5
An upper triangular matrix is a type of triangular matrix A = (aij) where
aij = 0 âˆ€i > j.
Definition 1.2.6 An upper triangular matrix is a matrix in which any non-zero entries lie on
or above the diagonal.
Page 4 of 246

Example 1.2.5
A general n Ã— n upper triangular matrix is of the form,
ï£®
a11
a12
. . .
a1n
a22
. . .
a2n
Â·
Â·
Â·
. . .
ann
ï£¹
Example 1.2.6
Matrix B in Example 1.2.4 on page (p. 4) is an upper triangular matrix.
Example 1.2.7
Examples of upper triangular matrices are
C =
ï£®
ï£¯ï£¯ï£¯ï£°
âˆ’2
ï£¹
ï£ºï£ºï£ºï£»,
D =
ï£®
ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£»,
E =
ï£®
ï£°
ï£¹
ï£»
Example 1.2.8
The matrix below is an upper triangular matrix
A =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£ºï£ºï£»
1.2.3.2
Lower Triangular Matrix
Definition 1.2.7
Let A = (aij) be a square matrix then the matrix A is said to be lower
triangular if
aij = 0, âˆ€i < j.
Definition 1.2.8
A lower triangular matrix is a matrix in which any nonzero entries lie on
or below the diagonal.
Example 1.2.9
They generally take the form,
ï£®
a11
. . .
a21
a22
. . .
Â·
Â·
Â·
an1
an2
an3
. . .
ann
ï£¹
Example 1.2.10
See matrix A in Example 1.2.4 on page (p. 4) is a lower triangular matrix.
Example 1.2.11
Examples of lower triangular matrices are
F =
ï£®
ï£°
ï£¹
ï£»,
G =
ï£®
ï£°
ï£¹
ï£»,
H =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£ºï£ºï£»
Page 5 of 246

Example 1.2.12
The matrix
A =
ï£®
ï£°
ï£¹
ï£»
is neither upper nor lower Triangular matrix because it is not a square matrix.
1.2.4
Idempotent Matrix
Definition 1.2.9
A matrix A = (aij) is said to be idempotent if
A2 = AA = A
Example 1.2.13
A =
 3
âˆ’6
âˆ’2

is an idempotent matrix.
Example 1.2.14
Examples of idempotent matrices are idempotent matrices are:
B =
ï£®
ï£°
ï£¹
ï£»,
C =
ï£®
ï£°
âˆ’2
âˆ’4
âˆ’1
âˆ’2
âˆ’3
ï£¹
ï£»,
D =
 1

Exercise 1.2.1
Show that the matrix
ï£®
ï£°
âˆ’2
âˆ’4
âˆ’1
âˆ’2
âˆ’3
ï£¹
ï£»is not an idempotent matrix.
Exercise 1.2.2 Is the matrix A = 1
 1 âˆ’cos Î¸
sin Î¸
sin Î¸
1 + cos Î¸

idempotent? Justify your answer.
1.2.5
Invertible or Non-Singular Matrix
Definition 1.2.10
A square matrix A = (aij) is non-singular or invertible if and only if âˆƒan
n Ã— n matrix denoted by Aâˆ’1 such that
AAâˆ’1 = Aâˆ’1A = I.
Note 1.2.1
I is the identity matrix, and Aâˆ’1 will later be called the inverse of A.
Remark 1.2.1
If Aâˆ’1 does not exist then we say that A is singular or non invertible.
Page 6 of 246

Example 1.2.15
Consider the matrices A, B, C and I4, as well as their transposes, where
A =
ï£®
ï£°
ï£¹
ï£»
B =
ï£®
ï£°
âˆ’1
ï£¹
ï£»
C =
ï£®
ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£».
Identify the diagonal of each matrix, and state whether each matrix is diagonal, upper triangular,
lower triangular, or none of the above.
We first compute the transpose of each matrix.
AT =
ï£®
ï£°
ï£¹
ï£»
BT =
ï£®
ï£°
âˆ’1
ï£¹
ï£»
CT =
ï£®
ï£°
ï£¹
ï£»
Note that IT
4 = I4.
The diagonals of A and AT are the same, consisting of the entries 1, 4 and 6. The diagonals of
B and BT are also the same, consisting of the entries 3, 7 and âˆ’1. Finally, the diagonals of C
and CT are the same, consisting of the entries 1, 4 and 6.
The matrix A is upper triangular; the only nonzero entries lie on or above the diagonal.
Likewise, AT is lower triangular.
The matrix B is diagonal. By their definitions, we can also see that B is both upper and lower
triangular. Likewise, I4 is diagonal, as well as upper and lower triangular.
Finally, C is upper triangular, with CT being lower triangular.
Remark 1.2.2
Make note of the definitions of diagonal and triangular matrices. We specify
that a diagonal matrix must be square, but triangular matrices donâ€™t have to be. (â€œMostâ€
of the time, however, the ones we study are.) Also, as we mentioned before in the example,
by definition a diagonal matrix is also both upper and lower triangular. Finally, notice that
by definition, the transpose of an upper triangular matrix is a lower triangular matrix, and
vice-versa.
Example 1.2.16
ï£®
ï£°
âˆ’7
âˆ’8
âˆ’1
âˆ’7
ï£¹
ï£», A is upper triangular and AT is
lower triangular.
Example 1.2.17
ï£®
ï£°
ï£¹
ï£»is upper and lower triangular, it is diagonal,
it is both symmetric and skew symmetric. Itâ€™s got it all.
Page 7 of 246

1.3
Operations on Matrices
1.3.1
Addition and Scalar Multiplication of matrices
Definition 1.3.1
Let A and B be matrices of the same size. The sum of A and B, written
A + B is the matrix whose ij-th entry is aij + bij.
Let A = (aij),
B = (bij). Then
C = A + B
=
(cij) = (aij + bij).
(1.1)
Note 1.3.1
Note that cij = bij + aij and so A + B = B + A.
Remark 1.3.1
Also if 0 is the zero matrix, then
0 + A = A + 0 = A
for any matrix A.
Definition 1.3.2 Scalar multiplication of a matrix;
Let A = (aij) be an m Ã— n matrix. Multiplying through matrix A by a scalar Î±, you get
Î±A
=
Î±(aij) = (Î±aij).
(1.2)
This is equivalent to multiplying each entry of matrix A with the scalar Î±.
Alternatively: Let k be a scalar. Then kA is a matrix whose ij-entry is kaij Therefore
kA = (kaij).
Example 1.3.1
For example, (âˆ’1)A = (âˆ’aij) and
A + (âˆ’1)A = A âˆ’A = 0
Example 1.3.2
Let
A =

âˆ’1

 âˆ’1
âˆ’2
âˆ’1

.
Find
1.) A + 2B =

âˆ’1

+
 âˆ’2
âˆ’4
âˆ’2

=
 âˆ’1
âˆ’1

2.) 3Aâ€² âˆ’Bâ€² =
ï£«
ï£­
âˆ’3
ï£¶
ï£¸âˆ’
ï£«
ï£­
âˆ’1
âˆ’2
âˆ’1
ï£¶
ï£¸=
ï£«
ï£­
âˆ’5
âˆ’2
ï£¶
ï£¸
3.)
(3A âˆ’B)â€²
=

âˆ’3

âˆ’
 âˆ’1
âˆ’2
âˆ’1
â€²
=

âˆ’5
âˆ’2
â€²
=
ï£«
ï£­
âˆ’5
âˆ’2
ï£¶
ï£¸
Note that 3Aâ€² âˆ’Bâ€² = (3A âˆ’B)â€².
Remark 1.3.2
Subtraction of two matrices A and B is defined using addition and scalar
multiplication that is: A âˆ’B = A + (âˆ’1)B.
Page 8 of 246

Theorem 1.3.1
Let A and B be matrices of the same size whose entries are in a field F and
s, t be scalars. Then
(sA + tB)â€² = sAâ€² + tBâ€².
Let
D
=
sA + tB = (saij + tbij)
Then Dâ€²
=
(sA + tB)â€² = (dji)
where
dji
=
saji + tbji
recall that Aâ€²
=
(aji) and Bâ€² = (bji)
Then
sAâ€² + tBâ€²
=
(saji + tbji) = dji
Thus the ji-entry of Dâ€² is equal to the ji-entry of SAâ€²+tBâ€² for all i and j. Therefore
Dâ€² = (SA + tB)â€² = SAâ€² + tBâ€².
â– 
Exercise 1.3.1
Solve the following matrix equation for a, b, c and d.

a âˆ’b
b + c
3d + c
2a âˆ’4d

=
 8

a = 5, b = âˆ’3,
c = 4,
d = 1
Example 1.3.3
 1
âˆ’3


âˆ’5

. Find A + B + (A + B)â€²
Note that A + Aâ€² =

âˆ’1
âˆ’1

and B + Bâ€² =
 14
âˆ’1
âˆ’1

So that
A + B + (A + B)â€² = A + Aâ€² + B + Bâ€² =
 16
âˆ’2
âˆ’2

Alternatively use
A + B
=

âˆ’3

â‡’
(A + B) + (A + Bâ€²)
=

âˆ’3

+
 8
âˆ’3

=
 16
âˆ’2
âˆ’2

Note that, the sums A + Aâ€²,
B + Bâ€² are symmetric matrices.
Theorem 1.3.2
Let A be a square matrix. Then A + Aâ€² is symmetric.
Let A
=
(aij).
Then Aâ€² = (aji)
Now A + Aâ€²
=
(aij + aji)
Clearly
aij + aji = bji = aji + aji âˆ€i, j
it follows that A + Aâ€² is symmetric.
â– 
Page 9 of 246

Theorem 1.3.3 Let A, B and C be matrices and s and t scalars in a field F. Then
1) A + B = B + A (Addition of matrices obeys the commutativity law)
2) (A + B) + C = A + (B + C) (Addition of matrices satisfies the Associative law).
Let A = (aij) and B = (bij), C = (cij). Then by definition
A + B
=
(aij + bij)
(A + B) + C
=
((aij + bij) + cij)
By associativity of scalars, (aij + bij) + cij = aij + (bij + cij)
So
(A + B) + C
=
(aij + (bij + cij))
=
(aij) + (bij + cij)
=
A + (B + C)
â– 
3) A + 0 = A (Additive identity)
4) A + (âˆ’A) = 0 (Additive inverse)
5) (st)A = s(tA) (commutative law)
6) (s + t)A = sA + tA (distributive law)
7) t(A + B) = tA + tB (distributive law)
8) 1 Â· A = A (1 is a multiplicative identity)
Exercise 1.3.2
Prove Theorem 1.3.3
1.3.2
Multiplication of Matrix by Matrix
Definition 1.3.3 The product C = AB (in this order) of an m Ã— n matrix A = [ajk] times an
r Ã— p matrix B = [bjk] is defined if and only if r = n and is then the m Ã— p matrix C = [cjk]
with entries
cjk
=
n
X
l=1
ajlblk = aj1b1k + aj2b2k + aj3b3k + Â· Â· Â· + ajnbnk
j
= 1, Â· Â· Â· , m
k
= 1, Â· Â· Â· , p.
(1.3)
Example 1.3.4 (Please verify)
Let A
=
 4
âˆ’1

and
B =
 1

Then AB
=
 4
âˆ’1
  1

=
 1

and BBâ€²
=
 1
 ï£®
ï£°
ï£¹
ï£»=
 21

Page 10 of 246

Example 1.3.5 Matrix Multiplication
AB =
ï£®
ï£°
âˆ’1
âˆ’6
âˆ’3
ï£¹
ï£»
ï£®
ï£°
âˆ’2
âˆ’4
ï£¹
ï£»=
ï£®
ï£°
âˆ’2
âˆ’16
âˆ’9
âˆ’37
âˆ’28
ï£¹
ï£»
Here c11 = 3(2)+5(5)+(âˆ’1)(9) = 22 and so on. The entry in the box is c23 = 4(3)+0(7)+2(1) =
14. The product BA is not defined.
Example 1.3.6
Multiplication of a Matrix and a Vector
1.)
 4
  3

=
 4(3) + 2(5)
1(3) + 8(5)

=
 22

2.) Whereas
 3
  4

is undefined.
Example 1.3.7
Products of Row and Column Vectors
1.)


ï£®
ï£°
ï£¹
ï£»= [19]
2.)
ï£®
ï£°
ï£¹
ï£»

=
ï£®
ï£°
ï£¹
ï£».
Example 1.3.8

  âˆ’1
âˆ’1

=
 0

but
 âˆ’1
âˆ’1
 

=

âˆ’99
âˆ’99

.
It is interesting that this also shows that AB = 0 does not necessarily imply BA = 0 or A = 0
or B = 0.
Example 1.3.9
Computing Products Columnwise
To obtain
AB =

âˆ’5
 
âˆ’1

=

âˆ’17
âˆ’23

Calculate the columns

âˆ’5
 
âˆ’1

=

âˆ’17

,

âˆ’5
  0

=
 4

,

âˆ’5
  7

=

âˆ’23

of AB and then write them as a single matrix, as shown in the first formula on the right.
Page 11 of 246

Example 1.3.10
ï£®
ï£°
3 + 2i
âˆ’i
1 + i
1 âˆ’i
ï£¹
ï£», B =
 âˆ’i
i

and C =
 âˆ’1 âˆ’i
âˆ’i
2i
âˆ’5

.
Then
BC
=
 5 + i
4i âˆ’11
3i âˆ’2
âˆ’5i

CA
=
 âˆ’23 âˆ’25i
âˆ’1 âˆ’i
69 âˆ’5i
âˆ’5 + 9i

and (1 + i)AB + (3 âˆ’4i)Câ€²
=
ï£®
ï£°
25 âˆ’7i
57 + 36i
âˆ’1 âˆ’i
âˆ’8 âˆ’6i
6 + 3i
âˆ’15 + 26i
ï£¹
ï£»
Theorem 1.3.4 Let A, B and C be conformable matrices over a field F and k a scalar.
Then
1) (AB)C = A(BC) (Associative property)
Let D = AB and E = BC
Then by definition,
D
=
(dij)
where dij =
X
k
aikbkj
and E
=
(eij)
where eij =
X
kâ€²
bikâ€²ckâ€²j
Thus
F
=
(fij) = DC = (AB)C
where fij
=
X
k
dikckj =
X
k
"X
iâ€²
aiiâ€²biâ€²k
#
ckj
=
X
i
aiiâ€²
X
k
biâ€²kCkj
=
X
i
aiiâ€²eiâ€²j
Therefore F
=
(fij) = AE = A(BC)
â– 
2) A(B + C) = AB + AC (Distributive property)
3) (B + C)A = BA + CA
4) k(AB) = (kA)B = A(kB)
Remark 1.3.3
For AB = 0, a zero matrix, does not mean that A = 0 or B = 0 or both.
Example 1.3.11 Let A =
 1
âˆ’1

 2

. Then
AB
=
 1
âˆ’1
  2

=
 4
âˆ’1

and
BA
=
 2
  1
âˆ’1

=
 2

Page 12 of 246

Note 1.3.2
In general, Matrix multiplication is not commutative; that is, AB Ì¸= BA.
In
general, just because AX = BX, we cannot conclude that A = B. The commutativity AB = BA
is possible only if when the matrices are equal or when the matrices A and B commute.
Example 1.3.12
For conformable matrices A and B, consider
(A âˆ’B)(A + B) = A2 âˆ’B2 + AB âˆ’BA
Then
(A âˆ’B)(A + B)
=
A2 âˆ’B2
(1.4)
if and only if A and B commute thus AB = BA. Note that the equality is always true for
scalars.
Exercise 1.3.3
Let X =
 1

and Y =
ï£®
ï£°
âˆ’1
ï£¹
ï£»â‡’
XY â€² =
 25

.
Find directly Y â€²X and compare it with XY â€² above.
Definition 1.3.4
Let A be a square matrix. The powers of A are defined as
A0 = I,
A1 = A,
A2 = AA,
A2A, . . .
Let f(x) be a polynomial. Then
f(x)
=
a0 + a1x + a2x2 + . . . + anxn
and f(A)
=
a0I + a1A + a2A2 + . . . + anAn
If f(A) = 0,
A is called the root or zero of the polynomial f(x).
Example 1.3.13
 2
âˆ’1

and f(x) = x2 âˆ’x âˆ’8. Then A2 =
 10

and
A3 =
 26
âˆ’1

. So
f(A)
=
A2 âˆ’A âˆ’8I =
 10

âˆ’
 2
âˆ’1

âˆ’
 8

=
 0

.
Therefore A is the zero of f(x).
Example 1.3.14
 2
âˆ’1

. Find the matrix X such that 2A + 3X = âˆ’4A..
We can use basic algebra techniques to manipulate this equation
X = âˆ’2A =
 âˆ’4
âˆ’6
âˆ’12

.
1.3.3
Trace of a Square Matrix
Definition 1.3.5 Let A be an n Ã— n square matrix, the trace of A denoted by tr(A) is the
sum of all diagonal elements of A. That is, trace(A) =
nP
i=1
aii
Example 1.3.15 Let A =
 1
âˆ’1

Then AAâ€² =
 5

â‡’
tr(AAâ€²) = 31,
Aâ€²A =
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’4
âˆ’4
ï£¹
ï£»
â‡’
tr(Aâ€²A) = 31
Page 13 of 246

1.4. PROPERTIES OF MATRICES OPERATIONS
Theorem 1.3.5 Let A and B be conformable matrices. Then tr(AB) = tr(BA).
Let C
=
AB = (Cij) where Cij =
X
k
aikbkj
Then tr(C)
=
tr(AB) =
X
i
Cii =
X
i
X
k
aikbki
Similarly let D
=
BA
Then tr(D)
=
X
i
X
k
bikaki
(why?) =
X
i
X
k
akibik
(Why?) = tr(C)
Thus tr(AB)
=
tr(BA)
1.4
Properties of Matrices Operations
1.4.1
Properties of Matrix Addition and Scalar Multiplication
1. A + B = B + A. i.e Matrix addition is commutative
2. A + (B + C) = (A + B) + C. i.e Associativity of matrix addition
3. A + 0 = 0 + A = A. where 0 is a zero matrix, a matrix with zero entries.
4. A + (âˆ’A) = 0 where âˆ’A = (âˆ’1)A
1.4.2
Properties of Matrix Multiplication
5. A(BC) = (AB)C. Associativity of matrix multiplication.
6. A(B + C) = AB + AC. Distributivity from the left.
7. (A + B)C = AC + BC. Distributivity from the right.
8. Î±(Î²A) = Î±Î²(A). where Î±, Î² are scalars.
9. Î±(A + B) = Î±A + Î±B.
10. A(Î±B) = Î±(AB) = (Î±A)B.
1.4.3
Properties of Matrix Transpose
11. (AT)T = A.
12. (A + B)T = AT + BT.
13. (AB)T = BTAT.
14. (Î±A)T = Î±AT.
1.4.4
Properties of the Matrix Trace
Let A and B be n Ã— n matrices. Then:
15. tr(A Â± B) = tr(A) Â± tr(B)
16. tr(kA) = kÂ· tr(A)
17. tr(AB) = tr(BA)
18. tr(AT) = tr(A)
Page 14 of 246

1.5
Determinants
The determinant of an n Ã— n matrix is the signed volume spanned by its column vectors. To
compute the determinant of any square matrix, one can use any of the two methods, namely
1.) Permutations - Inversion technique/method and the
2.) Cofactor method.
1.5.1
Permutations and Inversion of a Permutation
Definition 1.5.1 Permutation
Let S = {1, 2, . . . , n} be a set containing the first n natural numbers. An ordered arrangement
< i1i2 . . . in > of elements of set S is called a permutation of S.
Example 1.5.1
The permutations for S = {1, 2, 3} are
< 123 >,
< 132 >, < 213 >, < 231 >, < 312 >, and < 321 >
Exercise 1.5.1
Write down the permutations for S = {1, 2, 3, 4}
Note 1.5.1
A set of n elements has n! permutations.
Note 1.5.2
We denote the set of all permutations of set S by Sn where n is the number of
elements in the set S, and thus
S1
=
{< 1 >}
S2
=
{< 12 > < 21 >}
S3
=
{< 123 > < 132 > < 213 > < 231 > < 312 > < 321 >}
Definition 1.5.2 Inversion of Permutation
A permutation < i1i2 . . . in > of set S is said to have an inversion if a larger integer it precedes
(comes before) a smaller integer is. For example < 12 > has no inversion, < 21 > has one
inversion because a larger number 2 comes before 1, < 321 > has three inversions, < 2, 3, 1 >
has two inversions, and < 1, 2, 3 > has no inversions.
Definition 1.5.3
Even and Odd Permutation
A permutation is even or odd depending on the total number of inversions, either even or
odd.(Here we do consider zero to be even).
Example 1.5.2
The < 1, 2 > is an even permutation since it has no inversion, where as
< 1, 3, 2 > is an odd permutation since it has one inversion.
Definition 1.5.4 Determinant
If A = (aij) is an n Ã— n matrix, the determinant of A denoted as |A| or det(A) is defined by
|A| =
X
Ïƒ
Â±a1i1a2i2 . . . anin
where the Ïƒ denotes all permutations < i1 i2 . . . in > in the set S = {1, 2, . . . , n} (i.e the ij to
be substituted in the formula should be [in their order] got from each permutation).
Page 15 of 246

Note 1.5.3
Also that the + sign in the summation is taken when permutation is even, or âˆ’
when the permutation is odd.
Example 1.5.3 For n = 2 with A =
 a11
a12
a21
a22

and S2 = {< 1, 2 > < 2, 1 >} the determinant
of A is
|A|
=
Î£ Â± a1i1a2i2 = +a11a22 âˆ’a12a21
(1.5)
Example 1.5.4
For n = 3, where A =
ï£«
ï£­
a11
a12
a13
a21
a22
a23
a31
a32
a33
ï£¶
ï£¸and
S3 = {< 123 > < 132 > < 213 > < 231 > < 312 >< 321 >},
then
|A|
=
Î£ Â± a1i1a2i2a3i3
=
(1.6)
Example 1.5.5 The determinant of A =
 1

is
|A| = +a11a22 âˆ’a12a21 = (1)(7) âˆ’(2)(3) = 1.
Example 1.5.6
Given A =
ï£«
ï£­
ï£¶
ï£¸compute |A|.
Solution
= |A|
=
Î£ Â± a1i1a2i2a3i3
=
â‡’|A|
=
(1)(0)(4) âˆ’(1)(1)(3) âˆ’(2)(3)(4) + (2)(1)(3) + (0)(3)(3) âˆ’(0)(0)(3) = âˆ’21
1.5.2
Matrix Adjoint, Minors and Cofactors
Definition 1.5.5 If A = (aij) is an nÃ—n then Mij will denote (nâˆ’1)Ã—(nâˆ’1) matrix obtained
from A by deleting its ith row and jth column.
Its determinant which we denote by |Mij| is called the minor of the element aij of A.
Definition 1.5.6 The Cofactor of aij denoted by Cij is given by
Cij = (âˆ’1)i+j|Mij|
Example 1.5.7 Given A =
ï£«
ï£­
ï£¶
ï£¸. Find all the cofactors of the matrix A.
C11
=
(âˆ’1)1+1

= (1)(4) = 4
C12
=
(âˆ’1)1+2

= (âˆ’1)(4) = âˆ’4
Page 16 of 246

C13
=
(âˆ’1)1+3

C21
=
(âˆ’1)2+1

= (âˆ’1)(4) = âˆ’4
C22
=
(âˆ’1)2+2

C23
=
(âˆ’1)2+3

= (âˆ’1)(âˆ’4) = 4
C31
=
(âˆ’1)3+1

C32
=
(âˆ’1)3+2

= (âˆ’1)(8) = 8
C33
=
(âˆ’1)3+3

Then the cofactor matrix of A is
ï£«
ï£­
C11
C12
C13
C21
C22
C23
C31
C32
C33
ï£¶
ï£¸=
ï£«
ï£­
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
ï£¶
ï£¸
Definition 1.5.7 Determinant
Suppose that A = (aij) is an n Ã— n matrix, and let Cij denote the cofactor of the element aij
with i, j = 1, 2, . . . , n then
(1)
|A| =
n
X
k=1
akjCkj
That is summing along the jth column.
(2)
|A| =
n
X
k=1
aikCik
That is summing along the ith row.
Example 1.5.8
Compute the determinant of the matrix A =
ï£«
ï£­
ï£¶
ï£¸.
But we know (Example 1.5.7) that the cofactor matrix of A is
ï£«
ï£­
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
ï£¶
ï£¸Summing
along the
1st column â‡’|A|
=
(1)(4) + (3)(âˆ’4) + (2)(âˆ’4) = âˆ’16
2nd column â‡’|A|
=
(2)(âˆ’4) + (2)(âˆ’4) + (0)(8) = âˆ’16
3rd column â‡’|A|
=
(3)(âˆ’4) + (1)(âˆ’4) + (2)(âˆ’4) = âˆ’16
1st row â‡’|A|
=
(1)(4) + (2)(âˆ’4) + (3)(âˆ’4) = âˆ’16
2nd row â‡’|A|
=
(3)(âˆ’4) + (2)(âˆ’4) + (1)(4) = âˆ’16
3rd row â‡’|A|
=
(2)(âˆ’4) + (0)(8) + (2)(âˆ’4) = âˆ’16
Page 17 of 246

Same value of determinant no matter which row or column you consider. But preferably a row
or column with more zeros is better.
Definition 1.5.8
Adjoint
The transpose of the cofactor matrix of A is the adjoint of the matrix A. It is usually denoted
by adj(A). For A =
ï£®
a11
a12
. . .
a1n
a21
a22
. . .
a2n
Â·
Â·
Â·
an1
an2
. . .
ann
ï£¹
, the Cofactor Matrix is
ï£®
C11
C12
. . .
C1n
C21
a22
. . .
C2n
Â·
Â·
Â·
Cn1
Cn2
. . .
Cnn
ï£¹
Thus
Adj(A) =
ï£®
C11
C21
. . .
Cn1
C12
C22
. . .
Cn2
Â·
Â·
Â·
C1n
C2n
Â·
Cnn
ï£¹
Example 1.5.9
Compute the adjoint of the matrix A =
ï£®
ï£°
ï£¹
ï£». The cofactor matrix
of A is
ï£®
ï£°
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
ï£¹
ï£»â‡’adj(A) =
ï£®
ï£°
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
âˆ’4
ï£¹
ï£»
1.5.3
Properties of Determinants
1) |AT| = |A|.
2) Interchanging two rows or columns in a matrix gives the negative (determinant) of the
previous matrix.
3) If two rows or columns of a matrix are equal, then its determinant is equal to zero.
4) If any row or column in a matrix A is zero, then |A| = 0.
5) If any row or column is a constant multiple of another row or column, then |A| = 0.
6) A scalar k multiplying through a row or column of a matrix gives the determinant as k|A|.
Let Cij be the cofactor of aij. Then expanding by the first row, we have

ka11
ka12
ka13
a21
a22
a23
a31
a32
a33

=
ka11C11 + ka12C12 + ka13C13
=
k [a11C11 + a12C12 + a13C13]
=
k

a11
a12
a13
a21
a22
a23
a31
a32
a33

Property (6) also states that a factor common to all elements of a row (or column)
can be taken out as a factor of the determinant.
â– 
Page 18 of 246

In general, a scalar Î± multiplying through all rows or all columns |Î±A| = Î±n|A|
7) The value of the determinant remains unchanged if any row or column is replaced by a linear
combination of any two rows or columns.
8) The determinant of a triangular or diagonal matrix is given by the product of its diagonal
elements.
9) |AB| = |A||B|
10) |Aâˆ’1| = 1
|A|;
|A| Ì¸= 0 & Aâˆ’1 is called the inverse of A.
11) Let B be obtained from A by
1.) multiplying a row (column) of A by a scalar k; then |B| = k|A|.
If Ri â†kRj on A
Then every term in |A| is multiplied by k is
|B|
=
X
Ïƒ
(sgn(Ïƒ))a1i1a2i2 . . . (kajij) . . . anin
=
k
X
Ïƒ
(sgn(Ïƒ))a1i1a2i2 . . . ajij . . . ani1
=
k|A|.
â– 
2.) adding a multiple of a row (column) of A to another; then |B| = |A|
Rj â†Rj + cRk
|B|
=
X
Ïƒ
(sgn(Ïƒ))a1Ïƒ(1)a2Ïƒ(2) . . . (cakÏƒ(k) + ajÏƒ(j)) . . . anÏƒ(n)
=
c
X
Ïƒ
sgn(Ïƒ)a1Ïƒ(1)a2Ïƒ(2) . . . am(Ïƒk)
jth
. . . anÏƒ(n)
because jth row + kth row are the same.
+
X
Ïƒ
sgna1Ïƒ(1)a2Ïƒ(2) . . . anÏƒ(n)
3.) interchanging two rows (column) of A then |B| = âˆ’|A|
Omitted but results can be demonstrated in case of 3 Ã— 3 and 4 Ã— 4
matrix
â– 
Exercise 1.5.2
Compute the determinants of
1.) A =
ï£®
ï£°
ï£¹
ï£»
2.) B =
ï£®
ï£°
ï£¹
ï£»
3.) C =
ï£®
ï£°
ï£¹
ï£»
|A| = âˆ’21, |B| = 21, and |C| = âˆ’21. Check and explain why these answers (Property 2).
Page 19 of 246

Exercise 1.5.3 Using the properties of determinants explain why determinants of
1.)
ï£«
ï£­
âˆ’1
âˆ’2
ï£¶
ï£¸= 0
2.)
ï£«
ï£¬
ï£¬
ï£¬
ï£¬
ï£­
âˆ’1
âˆ’1
ï£¶
ï£·
ï£·
ï£·
ï£·
ï£¸
= âˆ’24
3.)
ï£«
ï£­
ï£¶
ï£¸= 27
4.)
ï£«
ï£¬
ï£¬
ï£­
ï£¶
ï£·
ï£·
ï£¸= 24
Example 1.5.10
Use the method of permutation to compute |A|
A =
ï£®
ï£°
âˆ’2
âˆ’7
ï£¹
ï£»
|A|
=
=
(âˆ’2)(5)(2) âˆ’(âˆ’2)(âˆ’7)(6) + (1)(âˆ’7)(1) âˆ’(1)(3)(2) + (4)(3)(6) âˆ’(4)(5)(1)
=
âˆ’137 + 72 = âˆ’65.
Example 1.5.11 Compute the determinant using â€œlinear combination of rows or columnsâ€
property.

âˆ’3
âˆ’2
âˆ’2

R2
â†
2R1 + R2
R3
â†
âˆ’5R1 + R3
=

âˆ’3
âˆ’2

R3
â†
2 R2 + R3
=
=

âˆ’3
âˆ’2

= âˆ’17 triangular matrix, or factor scalar third row 1

âˆ’3
âˆ’2

= âˆ’17
Remark 1.5.1 For Gauss-Jordan row reduction (operation), any scalar multiplication is with
the pivot.
Example 1.5.12 Compute the determinant using using â€œlinear combination of rows or columnsâ€
property.


R1
â†
R1
R2
â†
âˆ’1
2R1 + R2
R3
â†
R3
R4
â†
R4
=

âˆ’1
âˆ’1

R1
â†
R1
R2
â†
R2
R3
â†
4R2 + R3
R4
â†
2R2 + R4
=
=

âˆ’1
âˆ’1
âˆ’1

R1
â†
R1
R2
â†
R2
R3
â†
R3
R4
â†
R3 + R4
=
=

âˆ’1
âˆ’1
âˆ’1

= 6
(why?)
Page 20 of 246

Example 1.5.13
We can combine Gauss-Jordan row-reduction and cofactor expansion to
calculate determinants of large matrices.


=


âˆ’


Now 2


=


(2 column interchange)
=

+ 3



=
2(3 âˆ’6) = âˆ’6.
Also


=

âˆ’5
âˆ’2
âˆ’1

by row reduction
=

âˆ’5
âˆ’2
âˆ’1

=
âˆ’12
Therefore the required determinant = âˆ’6 + 12 = 6.
Example 1.5.14
Given that A =
ï£®
ï£°
âˆ’2
âˆ’3
ï£¹
ï£». Find the adj (A).
Since cofactors of A are
C11
=
(âˆ’1)1+1

âˆ’3
= âˆ’11
C12
=
(âˆ’1)1+2

âˆ’3
= 29
C13
=
(âˆ’1)1+3

= 1
C21
=
(âˆ’1)2+1

âˆ’2
âˆ’3
= âˆ’4
C22
=
(âˆ’1)2+2

âˆ’2
âˆ’3
= 7
C23
=
(âˆ’1)2+3

= âˆ’2
C31
=
(âˆ’1)3+1

âˆ’2
= 2
C32
=
(âˆ’1)3+2

âˆ’2
= âˆ’10
C33
=
(âˆ’1)3+3

= 1
Page 21 of 246

The Matrix of cofactors is
ï£®
ï£°
âˆ’11
âˆ’4
âˆ’2
âˆ’10
ï£¹
ï£»
and thus the adjoint of A is
ï£®
ï£°
âˆ’11
âˆ’4
âˆ’10
âˆ’2
ï£¹
ï£»
The Matrix adjoint is useful in finding the inverse of a non-singular matrix.
Example 1.5.15 Given the matrix
A =
ï£®
ï£°
ï£¹
ï£»
Using the Permutation-inversion technique, and the cofactor minor technique.
The cofactors of A are
C11 = (âˆ’1)2

= 6
C12 = (âˆ’1)3

= 0
C13 = (âˆ’1)4

= âˆ’6
C21 = (âˆ’1)3

= âˆ’6
C22 = (âˆ’1)4

= 4
C23 = (âˆ’1)5

= 6
C31 = (âˆ’1)4

= âˆ’3
C32 = (âˆ’1)5

= âˆ’2
C33 = (âˆ’1)6

= 9
The Matrix of cofactors is
ï£®
ï£°
âˆ’6
âˆ’6
âˆ’3
âˆ’2
ï£¹
ï£»
The determinant is given by
|A| = 4(6) + 3(0) + 2(âˆ’6) = 12
Example 1.5.16 Using properties of determinants, state the determinants of the following
matrices
1.) A =
 2

: |A| Does not exist (DNE) 0r is undefined because the matrix is not
square.
2.) A =
ï£®
ï£°
ï£¹
ï£»: |A| = 24
3.) A =
ï£®
ï£°
ï£¹
ï£»: |A| = 0 because two of the rows of the matrix A are equal.
Page 22 of 246

1.6
Matrix Inverses
Definition 1.6.1 Inverse of a matrix
The matrix B is said to be the inverse of matrix A if
AB = BA = I
(1.7)
I the identity matrix. We denote the inverse of A by Aâˆ’1.
Note 1.6.1
If matrix A has an inverse we say that A is invertible.
Theorem 1.6.1
If A is invertible, then its inverse is unique.
Assume A is invertible.
Suppose, by way of contradiction, that the
inverse of A is not unique, i.e., let B and C be two distinct inverses of A.
Then, by definition of inverse, we have
BA =
I
= AB
(1.8)
and
CA =
I
= AC
(1.9)
It follows that
B = BI
by definition of identity matrix,
B = B(AC)
by (1.9) above,
B = (BA)C
by associativity of matrix multiplication,
B = IC
by (1.8) above, and
B = C
by definition of identity matrix. Thus,
B = C
which contradicts the previous assumption that B Ì¸= C. So it must be that case that
the inverse of A is unique.
â– 
Page 23 of 246

1.6.1
Inverse Methodology
The inverse of a matrix could be determined by any of the following techniques
(1) Direct method
(2) Adjoint method
(3) Method of elementary row operations.
1.6.2
Direct Method
Example 1.6.1 Given a matrix A =

âˆ’1

, and if Aâˆ’1 = B =
 a
b
c
d

, find the inverse
B.
From definition of an inverse, equation (1.7)
AB
=
I

âˆ’1
  a
b
c
d

=
 1

To have
a = 1
3, b = âˆ’2
3, c = 1
3, d = 1
3 â‡’
 1/3
âˆ’2/3
1/3
1/3

Note 1.6.2 This method beomes increasingly difficult to use as the number of unknowns increase
with the increasing order of the matrix which makes it not preferable to other methods.
1.6.3
Adjoint Method
Theorem 1.6.2
adj(A).A = det(A)I
where I the identity matrix and |A| Ì¸= 0.
Corollary 1.6.1 If |A| Ì¸= 0 then
Aâˆ’1
=
|A| Â· adjA
(1.10)
From Theorem 1.6.2, adj(A).A = det(A)I. Dividing through by |A|,
|A|
A = I
Since |A| Ì¸= 0 â‡’
Aâˆ’1 exists. Multiplying through by Aâˆ’1 we get
|A|
AAâˆ’1 = IAâˆ’1
â‡’
|A|
= IAâˆ’1 = Aâˆ’1 â‡’
Aâˆ’1 = adjA
|A|
for |A| Ì¸= 0
â– 
Remark 1.6.1 From Corollary (1.6.1), equation (1.10), Aâˆ’1 exists if and only if
1) A is a square matrix
2) |A| Ì¸= 0
Page 24 of 246

Example 1.6.2
ï£®
ï£°
âˆ’1
ï£¹
ï£».
The co-factors are given by
C11 = (âˆ’1)1+1

= âˆ’1
C12 = (âˆ’1)1+2

âˆ’1
= âˆ’1
C13 = (âˆ’1)1+3

âˆ’1
= 1
C21 = (âˆ’1)2+1

= 1
C22 = (âˆ’1)2+2

âˆ’1
= 1
C23 = (âˆ’1)2+3

âˆ’1
= âˆ’5
C31 = (âˆ’1)3+1

= 1
C32 = (âˆ’1)3+2

= âˆ’3
C33 = (âˆ’1)3+3

= 3
The cofactor matrix is
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’5
âˆ’3
ï£¹
ï£»
â‡’
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’3
âˆ’5
ï£¹
ï£»
With
|A| = (3)(âˆ’1) + (0)(1) + (âˆ’1)(1) = âˆ’4
Then
Aâˆ’1 = adjA
|A| = 1
âˆ’4
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’3
âˆ’5
ï£¹
ï£»=
ï£®
ï£°
1/4
âˆ’1/4
âˆ’1/4
1/4
âˆ’1/4
3/4
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»
Theorem 1.6.3
An n Ã— n matrix is non singular if and only if |A| Ì¸= 0.
Suppose that A is non singular, then Aâˆ’1 exists such that
AAâˆ’1 = Aâˆ’1A = I
But
|AAâˆ’1| = |Aâˆ’1||A| = |I| = 1
Then |A| Ì¸= 0.
â– 
Example 1.6.3
Find the inverse of
A =
ï£®
ï£°
âˆ’2
âˆ’6
âˆ’2
ï£¹
ï£»
ï£±
ï£²
ï£³|A| = 96 , Aâˆ’1 = 1
ï£®
ï£°
âˆ’72
âˆ’24
ï£¹
ï£»
ï£¼
ï£½
ï£¾
Page 25 of 246

1.6.4
Method of Elementary Row Operation(Gauss-Jordan Elimination
Method)
Definition 1.6.2 An elementary row operation on A = (aij) is anyone of the following :
1.) Interchanging any two rows of a matrix.
2.) Multiplying any row of A by a non zero constant.
3.) Replacing any row by a linear combination of the row itself and any other row of A.
Remark 1.6.2
Linear combination of rows involve summing and subtraction of rows. But
not their product or quotient.
1.6.4.1
Process of computing the inverse using the elementary row operations.
Key Idea 1.1
For A an n Ã— n matrix
1). Form the n Ã— 2n matrix. i.e, (A : In).
2). Apply elementary row operations to (A : In).
3). Reduce (A : In) to a matrix of the form (In : B), then B will be the inverse matrix A.
Example 1.6.4
Compute Aâˆ’1 using the elementary row operation method, given that
A =
ï£®
ï£°
âˆ’1
ï£¹
ï£»
The n Ã— 2n matrix (A : I) is given by
ï£®
ï£°
âˆ’1
|
|
|
ï£¹
ï£»
Now the aim is to shift the identity matrix to side of A.
1.) Gauss-Jordan Elimination (Coefficients âˆ’aij
aii
multiplied on only the pivot):
ï£®
ï£°
âˆ’1
|
|
|
ï£¹
ï£»
â€¢ We begin with first column (whole) and we need a21 = 0, a31 = 0
[Operations for first column we apply the pivot in R1 ].
R1 â†’R1,
3R1 + R3 â†’R3
ï£®
ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
|
|
|
ï£¹
ï£ºï£ºï£ºï£ºï£ºï£»
Page 26 of 246

[But when looking for operations for second column, we only apply the pivot inR2 ]
Let âˆ’2R2 + R1 â†’R1,
âˆ’5
3R2 + R3 â†’R3
ï£®
ï£¯ï£¯ï£¯ï£°
âˆ’1
âˆ’4
|
âˆ’2
|
|
âˆ’5
ï£¹
ï£ºï£ºï£ºï£»
[But when looking for operations for third column, only use the pivot in R3 ]
Let âˆ’3
4R3 + R1 â†’R1,
4R3 + R2 â†’R2,
ï£®
âˆ’4
|
âˆ’3
âˆ’3
|
âˆ’1
|
âˆ’5
ï£¹
â€¢ To have
(I, B)
by 1
3R1 â†’R1, R2 â†’R2, 3
4R3 â†’R3 to have
ï£®
ï£°
|
3/12
âˆ’3/12
âˆ’3/12
|
1/4
âˆ’1/4
3/4
|
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»
â‡’
ï£®
ï£°
3/12
âˆ’3/12
âˆ’3/12
1/4
âˆ’1/4
3/4
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»=
ï£®
ï£°
1/4
âˆ’1/4
âˆ’1/4
1/4
âˆ’1/4
3/4
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»
2.) Gauss Elimination (Coefficients can be multiplied on any entry):
ï£®
ï£°
âˆ’1
|
|
|
ï£¹
ï£»
â€¢We begin with first column (whole) and we need a21 = 0, a31 = 0
[Operations for first column we apply the pivot in R1 ].
R1 â†’R1,
R1 + 3R3 â†’R3
ï£®
ï£°
|
|
|
ï£¹
ï£»
[But when looking for operations for second column, we only apply the pivot inR2 ]
Let R1 âˆ’2R2 â†’R1,
5R2 âˆ’R3 â†’R3
ï£®
ï£°
âˆ’1
|
âˆ’2
|
|
âˆ’1
âˆ’3
ï£¹
ï£»
Page 27 of 246

[But when looking for operations for third column, only use the pivot in R3 ]
Let 4R1 + R3 â†’R1,
4R2 âˆ’R3 â†’R2,
ï£®
ï£°
|
âˆ’3
âˆ’3
|
âˆ’1
|
âˆ’1
âˆ’3
ï£¹
ï£»
â€¢ To have
(I, B)
by
12R1 â†’R1, 1
4R2 â†’R2, 1
4R3 â†’R3 to have
ï£®
ï£°
|
3/12
âˆ’3/12
âˆ’3/12
|
1/4
âˆ’1/4
3/4
|
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»
â‡’
ï£®
ï£°
3/12
âˆ’3/12
âˆ’3/12
1/4
âˆ’1/4
3/4
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»=
ï£®
ï£°
1/4
âˆ’1/4
âˆ’1/4
1/4
âˆ’1/4
3/4
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»
Note 1.6.3
Always prove your inverse solution by checking whether, AAâˆ’1 = I
Definition 1.6.3
A matrix that has undergone Gaussian elimination is said to be in echelon
form.
Note 1.6.4
Gauss-Jordan is a special case of Gaussian elimination.
Example 1.6.5
Compute Aâˆ’1 given A =
ï£®
ï£°
ï£¹
ï£»
ï£®
ï£°
|
|
|
ï£¹
ï£»
1.) Gauss-Jordan Elimination (Coefficients multiplied on only the pivot):
ï£®
ï£°
|
|
|
ï£¹
ï£»
â€¢The first column looks okay since the non-zero term is only in a11.
Let R1 â†’R1,
ï£®
ï£°
|
|
|
ï£¹
ï£»
[But when looking for operations for second column,only use R2 ]
Let âˆ’R2 + R1 â†’R1,
âˆ’R2 + R3 â†’R3
ï£®
ï£°
|
âˆ’1
|
|
âˆ’1
ï£¹
ï£»
Page 28 of 246

[But when looking for operations for third column,only use R3 ]
Let âˆ’R3 + R1 â†’R1,
ï£®
ï£°
|
âˆ’1
|
|
âˆ’1
ï£¹
ï£»
â€¢ To have (I, B)
we use 1
2R1 â†’R1, 1
2R2 â†’R2, 1
2R3 â†’R3 to have
ï£®
ï£°
|
1/2
âˆ’1/2
|
1/2
|
âˆ’1/2
1/2
ï£¹
ï£»
â‡’
ï£®
ï£°
1/2
âˆ’1/2
1/2
âˆ’1/2
1/2
ï£¹
ï£»
2.) Gauss Elimination (Coefficients can be multiplied on any entry):
ï£®
ï£°
|
|
|
ï£¹
ï£»
â€¢The first column looks okay since the non-zero term is only in a11.
Let R1 â†’R1,
ï£®
ï£°
|
|
|
ï£¹
ï£»
[But when looking for operations for second column,only use R2 ]
Let R1 âˆ’R2 â†’R1,
R3 âˆ’R2 â†’R3
ï£®
ï£°
|
âˆ’1
|
|
âˆ’1
ï£¹
ï£»
[But when looking for operations for third column,only use R3 ]
Let R1 âˆ’R3 â†’R1,
ï£®
ï£°
|
âˆ’1
|
|
âˆ’1
ï£¹
ï£»
â€¢ To have (I, B)
we use 1
2R1 â†’R1, 1
2R2 â†’R2, 1
2R3 â†’R3 to have
ï£®
ï£°
|
1/2
âˆ’1/2
|
1/2
|
âˆ’1/2
1/2
ï£¹
ï£»
â‡’
ï£®
ï£°
1/2
âˆ’1/2
1/2
âˆ’1/2
1/2
ï£¹
ï£»
Page 29 of 246

Example 1.6.6
Determine the inverse Aâˆ’1 of
A =
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’1
ï£¹
ï£»
using the Gauss-Jordan row reduction technique.
[A|I]
=
ï£®
ï£¯ï£°
âˆ’1
âˆ’1
âˆ’1
ï£¹
ï£ºï£»
R1
â‡
R1
3R1 + R2
â‡
R2
âˆ’R1 + R3
â‡
R3
=
ï£®
ï£°
âˆ’1
âˆ’1
ï£¹
ï£»
âˆ’0.5R2 + R1
â‡
R1
R2
â‡
R2
âˆ’R2 + R3
â‡
R3
=
ï£®
âˆ’1
âˆ’3
âˆ’1
âˆ’1
âˆ’5
âˆ’4
âˆ’1
ï£¹
âˆ’3
10R3 + R1
â‡
R1
5R3 + R2
â‡
R2
R3
â‡
R3
=
ï£®
ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
âˆ’1
âˆ’1
âˆ’3
âˆ’13
âˆ’2
âˆ’5
âˆ’4
âˆ’1
ï£¹
ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»
âˆ’R1
â‡
R1
2R2
â‡
R2
âˆ’1
5R3
â‡
R3
=
ï£®
âˆ’7
âˆ’13
âˆ’1
âˆ’1
ï£¹
=
ï£®
ï£°
âˆ’0.7
0.2
0.3
âˆ’1.3
âˆ’0.2
0.7
0.8
0.2
âˆ’0.2
ï£¹
ï£»
The last three columns constitute Aâˆ’1. Check:
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’1
ï£¹
ï£»
ï£®
ï£°
âˆ’0.7
0.2
0.3
âˆ’1.3
âˆ’0.2
0.7
0.8
0.2
âˆ’0.2
ï£¹
ï£»=
ï£®
ï£°
ï£¹
ï£»
Hence AAâˆ’1Aâˆ’1A = I
Page 30 of 246

Remark 1.6.3
For sure AAâˆ’1 = I.
Example 1.6.7
Compute Aâˆ’1 given A =
ï£®
ï£°
âˆ’1
ï£¹
ï£»using the Gaussian elimination row
reduction (not Gauss-Jordan elimination).
=
ï£®
ï£°
âˆ’1
|
|
|
ï£¹
ï£»
R1
â‡
R1
R2 âˆ’2R1
â‡
R2
R3 âˆ’4R1
â‡
R3
=
ï£®
ï£¯ï£°
âˆ’1
âˆ’1
|
|
âˆ’2
|
âˆ’4
ï£¹
ï£ºï£»
R1
â‡
R1
R2
â‡
R2
R3 + R2
â‡
R3
=
ï£®
ï£¯ï£°
âˆ’1
âˆ’1
âˆ’1
|
|
âˆ’2
|
âˆ’6
ï£¹
ï£ºï£»
2R3 + R1
â‡
R1
R3 âˆ’R2
â‡
R2
R3
â‡
R3
=
ï£®
ï£°
âˆ’1
|
âˆ’11
|
âˆ’4
|
âˆ’6
ï£¹
ï£»
R1
â‡
R1
R2
â‡
R2
âˆ’R3
â‡
R3
(I : B)
=
ï£®
ï£°
|
âˆ’11
|
âˆ’4
|
âˆ’1
âˆ’1
ï£¹
ï£»
â‡’
ï£®
ï£°
âˆ’11
âˆ’4
âˆ’1
âˆ’1
ï£¹
ï£»
Exercise 1.6.1
ï£®
ï£°
âˆ’1
ï£¹
ï£», determine
1.) |A|, using
(a) Permutation-inversions technique
(b) Cofactors.
|A| = âˆ’1
2.) Aâˆ’1, using
(a) Aâˆ’1 = 1
|A|adj(A)
(b) Row reduction (Gauss-Jordan elimination
or Gauss elimination).
Aâˆ’1 =
ï£®
ï£°
âˆ’3
âˆ’6
âˆ’7
âˆ’2
ï£¹
ï£»
Page 31 of 246

1.6.5
Properties of Matrix Inverse
1.) If Aâˆ’1 is invertible, then
(Aâˆ’1)âˆ’1 = A
2.) If AB is invertible, then
(AB)âˆ’1 = Bâˆ’1Aâˆ’1
Let x = (AB)âˆ’1 then
(AB)x
=
(AB)(AB)âˆ’1 = I
(1.11)
But also
(AB)x
=
A(Bx)
(1.12)
Thus (1.11) will become
(AB)x
=
I
A(Bx)
=
I
Aâˆ’1A(Bx)
=
Aâˆ’1I
I(Bx)
=
Aâˆ’1
Bx
=
Aâˆ’1
Bâˆ’1Bx
=
Bâˆ’1Aâˆ’1
x
=
Bâˆ’1Aâˆ’1
â‡’(AB)âˆ’1 = Bâˆ’1Aâˆ’1
â– 
3.) If AT is invertible, then
(AT)âˆ’1 = (Aâˆ’1)T
Assume A is invertible, then Aâˆ’1 exists and we have,
(Aâˆ’1)TAT
=
(AAâˆ’1)T = IT = I and
AT(Aâˆ’1)T
=
(Aâˆ’1A)T = IT = I
so AT is invertible and (AT)âˆ’1 = (Aâˆ’1)T.
â– 
4.) For Î±A invertible for any nonzero scalar Î±, then (Î±A)âˆ’1 = 1
Î±Aâˆ’1.
5.) The inverse of a diagonal matrix is obtained by inverting the diagonal elements.
6.) If a product AB is not invertible, then A or B is not invertible.
7.) If A or B are not invertible, then AB is not invertible.
Exercise 1.6.2 Use both the methods of inverses and properties of inverses to determine Aâˆ’1
for A =
ï£®
ï£°
âˆ’4
ï£¹
ï£».
Aâˆ’1 =
ï£®
ï£°
1/2
1/3
âˆ’1/4
ï£¹
ï£»
Exercise 1.6.3
ï£®
ï£°
âˆ’1
ï£¹
ï£».
ï£®
ï£°Aâˆ’1 =
ï£®
ï£°
1/4
âˆ’1/4
âˆ’1/4
1/4
âˆ’1/4
1/4
âˆ’1/4
5/4
âˆ’3/4
ï£¹
ï£»
ï£¹
ï£».
Page 32 of 246

Example 1.6.8 Find the inverse Aâˆ’1 for the matrix
A =
ï£®
ï£°
ï£¹
ï£»
1.) Using the Cofactor-Adjoint technique.
From Example 1.5.15, the cofactor matrix of A was given as
ï£®
ï£°
âˆ’6
âˆ’6
âˆ’3
âˆ’2
ï£¹
ï£»
â‡’
ï£®
ï£°
âˆ’6
âˆ’3
âˆ’2
âˆ’6
ï£¹
ï£»
â‡’
Aâˆ’1 = 1
|A|adj(A) = 1
ï£®
ï£°
âˆ’6
âˆ’3
âˆ’2
âˆ’6
ï£¹
ï£»=
ï£®
ï£°
1/2
âˆ’1/2
âˆ’1/4
1/3
âˆ’1/6
âˆ’1/2
1/2
3/4
ï£¹
ï£»
2.) Using Gaussian elimination row-reduction
[A : I]
=
ï£®
ï£°
|
|
|
ï£¹
ï£»
R1 â‡R1
R1 âˆ’4R2 â‡R2
R1 âˆ’2R3 â‡R3
ï£®
ï£¯ï£°
|
âˆ’9
âˆ’2
|
âˆ’4
âˆ’2
|
âˆ’2
ï£¹
ï£ºï£»
3R1 + R2 â‡R1
R2 â‡R2
3R3 + R2 â‡R3
ï£®
ï£¯ï£°
|
âˆ’4
âˆ’9
âˆ’2
|
âˆ’4
âˆ’8
|
âˆ’4
âˆ’6
ï£¹
ï£ºï£»
2R1 + R3 â‡R1
4R2 âˆ’R3 â‡R2
R3 â‡R3
ï£®
ï£°
|
âˆ’12
âˆ’6
âˆ’36
|
âˆ’12
âˆ’8
|
âˆ’4
âˆ’6
ï£¹
ï£»
24R1 â‡R1
âˆ’1
36R2 â‡R2
âˆ’1
8R3 â‡R3
[I : B]
=
ï£®
ï£°
|
1/2
âˆ’1/2
âˆ’1/4
|
1/3
âˆ’1/6
|
âˆ’1/2
1/2
3/4
ï£¹
ï£»
â‡’
Aâˆ’1 =
ï£®
ï£°
1/2
âˆ’1/2
âˆ’1/4
1/3
âˆ’1/6
âˆ’1/2
1/2
3/4
ï£¹
ï£»
Note 1.6.5
The value for an inverse is always the same for both methods.
Page 33 of 246

1.7
Matrices Chapter Examples
Example 1.7.1
Compute the determinant of each of the following matrices. Indicate clearly
the method being used.
1.) Method of cofactors and adjoints
A =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
âˆ’3
âˆ’3
âˆ’1
âˆ’6
âˆ’2
âˆ’1
ï£¹
ï£ºï£ºï£ºï£ºï£»
The determinant can be got by
det A
=
âˆ’7 det
ï£®
ï£¯ï£¯ï£°
âˆ’3
âˆ’3
âˆ’1
âˆ’2
âˆ’1
ï£¹
ï£ºï£ºï£»
(along the second row)
=
âˆ’7(4) det
ï£®
ï£°
âˆ’3
âˆ’2
âˆ’1
ï£¹
ï£»
(along the fourth row)
=
âˆ’7(4)(2) det
 2
âˆ’1

(along the first row)
=
âˆ’7(4)(2)(âˆ’2) = 112
2.)
A =
ï£®
ï£°
b
b2
b
b2
b3
b2
b3
b4
ï£¹
ï£»
(where b is any real number).
We can do row operations: Add âˆ’b times the first row to the second row and âˆ’b2 times the
first row plus the second row. This gives
ï£®
ï£°
b
b2
ï£¹
ï£»
Therefore det A = 0. Thus, the original matrix is not invertible, since its determinant is
zero.
Example 1.7.2
Let
A =
ï£®
ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£»
B =
ï£®
ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£»
C =
ï£®
ï£¯ï£¯ï£°
x
ï£¹
ï£ºï£ºï£»
1.) Find det A and give a reason for your answer.
det A = 0 because two rows are equal.
Page 34 of 246

2.) Find the cofactor C11 and then find det B.
The cofactor C11 = âˆ’1. Then det B = det A âˆ’C11 = 1.
3.) Find detC for any value of x. You could use linearity in row 1.
det C = xC11 + det B = âˆ’x + 1. Check this answer (zero), for x = 1 when C = A.
Example 1.7.3
ï£®
ï£°
a
b
c
d
e
f
g
h
i
ï£¹
ï£»and assume that det(A) = 10. Find
1.) det(3A)
2.) det (2Aâˆ’1)
3.) det (2A2)
4.) det
Notice that A is a 3 Ã— 3 matrix. Therefore,
det(3A)
=
33 det(A) = 270
det
 2Aâˆ’1
=
23 det
 Aâˆ’1
=
det(A) = 8
det
 2A2
=
23 det
 A2
= 23 det (A)2 = 800
det
=
33 det
 (AT)âˆ’1
=
det (AT) =
det (A) = 27
5.) det
ï£®
ï£°
a
g
d
b
h
e
g
i
f
ï£¹
ï£»
Notice that we have
A =
ï£®
ï£°
a
b
c
d
e
f
g
h
i
ï£¹
ï£»
R2â†’R3
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’
Interchange
B =
ï£®
ï£°
a
b
c
g
h
i
d
e
f
ï£¹
ï£»
and BT =
ï£®
ï£°
a
g
d
b
h
e
g
i
f
ï£¹
ï£»
As a result, we have det(BT) = det(B) = (âˆ’1) det(A) = âˆ’10.
Example 1.7.4
Specify whether the matrix has an inverse without trying to compute the
inverse A =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£ºï£ºï£»
.
Solution :
|A| = âˆ’12 Ì¸= 0 â‡’
âˆƒAâˆ’1
â– 
Example 1.7.5
Suppose A =
ï£®
ï£°
ï£¹
ï£». Which one of the following statements is true ?
Page 35 of 246

A. Aâˆ’1 does not exist.
B. The third row of Aâˆ’1 is [âˆ’1
âˆ’1 1].
C. The second row of Aâˆ’1 is [1 2
âˆ’1].
D. The first row of Aâˆ’1 is [2 0
âˆ’1].
E. The second column of Aâˆ’1 is [0 2
âˆ’1]T.
F. All of B, C, D, E are true.
B
Example 1.7.6
ï£®
ï£°
âˆ’1
x
ï£¹
ï£». For which value(s) of x is A invertible?
A. x Ì¸= âˆ’1
B. x Ì¸= 1
C. x Ì¸= 0
D. x = âˆ’1
E. x = 1
F. x Ì¸= Â±1
A
Example 1.7.7
If three n Ã— n matrices A, B and C satisfy AB âˆ’BA = C, then ABA is
always equal to :
A. A2B âˆ’C
B. A2B âˆ’CA
C. BA2 + CA
D. A2B
E. A2B + AC
F. A2B + BC
C
Example 1.7.8
Let
A =

âˆ’4
âˆ’5

 7
k

.
For which values of k does AB = BA hold?
k = 9
Example 1.7.9
ï£®
ï£°
ï£¹
ï£»Compute
1.) |A|, using
(a) Permutation-inversions scheme
(b) Cofactors.
|A| = âˆ’12
2.) Aâˆ’1, using
(a) Aâˆ’1 = 1
|A|adj(A)
(b) Row reduction.
Aâˆ’1 =
ï£®
ï£°
âˆ’1/3
1/4
1/3
1/3
1/6
âˆ’7/12
1/3
âˆ’1/3
1/16
ï£¹
ï£»
Page 36 of 246

1.8
Matrices Chapter Exercises
Exercise 1.8.1
Define the subtraction of two matrices A and B.
Exercise 1.8.2
If A, B and C are conformable matrices then show that
A + (B + C) = (A + B) + C.
Exercise 1.8.3
If A is an m Ã— p, B is a p Ã— q, and C is a q Ã— n, then show that
(AB)C = A(BC).
Exercise 1.8.4
If A is an m Ã— p, B is an m Ã— p, and C is a p Ã— n, then show that
(A + B)C = AC + BC.
Exercise 1.8.5
If r, s âˆˆR then show that
1.) r(sA) = (rs)A
2.) (r + s)A = rA + sA
3.) A(rB) = r(AB)
where A is an m Ã— p matrix and B is a p Ã— n matrix
Exercise 1.8.6
Given that A and B matrices and r âˆˆR show that,
1.) (Aâ€²)â€² = A
2.) (rA)â€² = rAâ€²
3.) (A + B)â€² = Aâ€² + Bâ€²
Exercise 1.8.7 Show that there exists a unique m Ã— n matrix 0 such that A + 0 = A for any
m Ã— n matrix A.
Exercise 1.8.8
Show that for each m Ã— n matrix A, there exists a unique m Ã— n matrix âˆ’A
such that A + (âˆ’A) = 0.
Exercise 1.8.9
Let A and B be arbitrary n Ã— n matrices. Is it true that
(A âˆ’B)(A + B) = A2 âˆ’B2
Exercise 1.8.10
Prove that (AB)â€² = Bâ€²Aâ€² for A, B conformable matrices.
Exercise 1.8.11
If A is an idempotent matrix. Prove that
1.) An = A
âˆ€n âˆˆZ+.
2.) I âˆ’A is idempotent where I is an identity matrix of same order as A. (Is A âˆ’I also
idempotent?).
Exercise 1.8.12
If A and B are idempotent matrices. Is AB also idempotent? if not under
what condition(s) will AB be idempotent.
Exercise 1.8.13 If A and B are invertible n Ã— n matrices, Is it true that the inverse of A + B
is Aâˆ’1 + Bâˆ’1?
Exercise 1.8.14
Let A be an n Ã— n square invertible matrix. Prove that
det(Aâˆ’1) =
Exercise 1.8.15 Find the matrix A such that

âˆ’5

Exercise 1.8.16
Let A be a 5 Ã— 5 matrix with determinant 6. What is the determinant of
Aâˆ’1 (determinant of the inverse of A)?
Page 37 of 246

A. 6.
B. 0.
C. 1/6.
D. 30.
E. 25/6.
F. 1.
to
C
Exercise 1.8.17
Let A be a 5 Ã— 5 matrix with determinant 6, and let B be a 5 Ã— 5 matrix
with determinant 4. What is the determinant of AB?
A. 24.
B. 10.
C. 0.
D. 1/6.
E. 1/4.
F. 1.
to
A
Exercise 1.8.18
Suppose A is an n Ã— n matrix, prove that det[adj(A)] = (det A)nâˆ’1
Exercise 1.8.19 What is the size of the matrix B if the product AB has been computed and
A is m Ã— n matrix?
Exercise 1.8.20
For A and b matrices show that r(A + B) = rA + rB for r a real number.
What is known about the sizes of A and B?
Exercise 1.8.21 If A and B are symmetric matrices of the same order, show that ATBT +AB
is also symmetric.
Exercise 1.8.22
State any two axioms of inverse of a matrix.
Exercise 1.8.23
For a symmetric matrix A and a skew-symmetric matrix B, show that the
matrix AB âˆ’BA is also symmetric.
(AB âˆ’BA)T = (AB)T âˆ’(BA)T = BTAT âˆ’ATBT = âˆ’BA âˆ’A(âˆ’B) = AB âˆ’BA.
Exercise 1.8.24 True or False? Every nonzero square matrix has an inverse.
False
Exercise 1.8.25
ï£®
ï£°
âˆ’4
k2 + 3
2k
ï£¹
ï£». Find the values of k such that tr(A) = 7.
(k + 3)(k âˆ’1) = 0 â‡’k = âˆ’3 or k = 1
Page 38 of 246

Exercise 1.8.26
Let A be a 5 Ã— 5 matrix with determinant 6, and let B be a 5 Ã— 5 matrix
with determinant 4. What is the determinant of A + B?
A. 24.
B. 10.
C. 0.
D. 1/6.
E. 1/4.
F. 1.
to
G
Exercise 1.8.27
âˆ’A?
A. 3.
B. -3.
C. 1/3.
D. 0.
E. 1.
F. -1.
to
A
Exercise 1.8.28
2A?
A. 6.
B. 3.
C. 24.
D. 48.
E. 12.
F. 196,608.
to
D
Exercise 1.8.29
AT (the transpose of A)?
A. 3T.
B. 3.
C. 12.
D. 1/3.
E. 27.
F. 81.
to
B
Exercise 1.8.30
Let A be a 4 Ã— 4 matrix with determinant 3. Let B be the matrix formed
by swapping the second and third rows of A. What is det(B)?
A. 3.
B. 0.
C. 1/3.
D. -3.
E. 6.
F. 2.
to
D
Page 39 of 246

Exercise 1.8.31
If A is a 3 Ã— 5 matrix, then the determinant of A is
A. A number (possibly non-zero).
B. 35.
C. Zero.
D. 53.
E. A 5 Ã— 3 matrix.
F. Undefined.
G. A 3 Ã— 5 matrix.
F
Exercise 1.8.32
Find the row reduced echelon form of the matrix below:
A =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
âˆ’2
âˆ’4
âˆ’2
âˆ’2
âˆ’2
âˆ’4
ï£¹
ï£ºï£ºï£ºï£ºï£»
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
5/4
âˆ’11/8
ï£¹
ï£ºï£ºï£ºï£ºï£»
Exercise 1.8.33
Find the determinant of the matrix below. Specify whether the matrix has
an inverse without trying to compute the inverse.
ï£®
ï£¯ï£¯ï£°
âˆ’2
âˆ’2
âˆ’2
âˆ’2
âˆ’2
âˆ’2
âˆ’1
âˆ’3
âˆ’1
ï£¹
ï£ºï£ºï£»
Row reduce the given matrix to an upper triangular matrix
ï£®
ï£¯ï£¯ï£°
âˆ’2
âˆ’2
âˆ’2
âˆ’2
âˆ’2
âˆ’2
âˆ’1
âˆ’3
âˆ’1
ï£¹
ï£ºï£ºï£»
âˆ¼
ï£®
ï£¯ï£¯ï£°
âˆ’2
âˆ’2
âˆ’2
âˆ’4
âˆ’2
âˆ’2
âˆ’4
ï£¹
ï£ºï£ºï£»
As a result, the determinant is âˆ’32 which is not 0. Therefore, the given matrix is invertible.
Exercise 1.8.34
ï£®
ï£°
âˆ’2
âˆ’6
âˆ’2
ï£¹
ï£»;
ï£®
ï£°Aâˆ’1 = 1
ï£®
ï£°
âˆ’72
âˆ’24
ï£¹
ï£»
ï£¹
ï£»
Page 40 of 246

Exercise 1.8.35
Show that det(A) = 0 where
ï£®
ï£°
a
b
âˆ’a
c
âˆ’b
âˆ’c
ï£¹
ï£»
Note that A = âˆ’AT. Then we get
=
det((âˆ’1)AT)
=
(âˆ’1)3 det(AT)
=
(âˆ’1)3 det(A)
=
âˆ’det(A), i.e.,
2 det(A) = 0
â†’
det(A) = 0.
OR Calculate the determinant with respect to any column or any row of your choice.
Exercise 1.8.36
Find the inverse of the following matrix A =
ï£®
ï£°
ï£¹
ï£».
Aâˆ’1 = 1
ï£®
ï£°
âˆ’6
âˆ’3
ï£¹
ï£»
Exercise 1.8.37
1.) An n Ã— n matrix A is called orthogonal if AAT = I. If A is orthogonal show that
det(A) = Â±1.
By the properties of determinant,
det(AAT) = det(A) det(AT) = det(A) det(A) = det(A)2 = det(I) = 1.
So, det(A) = Â±1.
2.) An n Ã— n matrix A is called skew-symmetric if AT = âˆ’A. Show that if A is skewsymmetric and n is an odd positive integer, then A is not invertible.
By the properties of determinant,
det(AT) = det(âˆ’A) â‡’det(A) = det(âˆ’A) â‡’det(A) = (âˆ’1)n det(A) â‡’det(A) = âˆ’det(A).
So, we get det(A) = 0 which implies that A is not invertible. Note that âˆ’A means that
every row of A is multiplied by âˆ’1.
3.) Let A and B be two non-singular symmetric matrices that commute. Show that Aâˆ’1B and
Aâˆ’1Bâˆ’1 are symmetric.
Exercise 1.8.38
Specify whether the matrix has an inverse without trying to compute the
inverse
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
âˆ’1
âˆ’1
âˆ’1
âˆ’1
ï£¹
ï£ºï£ºï£ºï£ºï£»
Page 41 of 246

We use the definition of determinant. We calculate the determinant across the 2nd rows and
3rd column.

âˆ’1
âˆ’1
âˆ’1
âˆ’1

=
(âˆ’1)

âˆ’1
âˆ’1
âˆ’1

=
(âˆ’1)
ï£«
ï£­(âˆ’1)

âˆ’1
âˆ’1

ï£¶
ï£¸
=
(âˆ’1)

(âˆ’1)

(âˆ’1)

âˆ’1
âˆ’1


=
(âˆ’1)(âˆ’1)(âˆ’1)[(1) âˆ’(1)]
=
Since we have the determinant is 0, the matrix is not invertible.
Exercise 1.8.39 Find the inverse of the matrix A using the inverse formula (cofactor-adjoint)
where A =
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’2
ï£¹
ï£»
Aâˆ’1 =
ï£®
ï£°
âˆ’1
âˆ’1
âˆ’2
âˆ’1
âˆ’1
ï£¹
ï£»
Exercise 1.8.40
Compute the determinant of the matrix
ï£«
ï£¬
ï£¬
ï£­
ï£¶
ï£·
ï£·
ï£¸
by using row operations (Hint: Recall the determinant of an upper triangular matrix).
Exercise 1.8.41
LetA =
ï£®
ï£¯ï£¯ï£°
a
a âˆ’1
2a
(a âˆ’1)(a2 âˆ’4)
a
a
ï£¹
ï£ºï£ºï£». Determine those values of a for
which A is invertible.
Triangular. if and only if a Ì¸= 0 and a Ì¸= 1 and a Ì¸= 2 and a Ì¸= âˆ’2.
Exercise 1.8.42
ï£®
ï£°
a
b
c
d
e
f
g
h
i
ï£¹
ï£»and assume that det(A) = 2. Find
1.) det(âˆ’2A)
2.) det
  1
2Aâˆ’1
3.) det (2A2)
4.) det
5.) det
ï£®
ï£°
a
g
d
b
h
e
c + 2a
i + 2g
f + 2d
ï£¹
ï£»
det(C) = det(BT) = det(B) = (âˆ’1) det(A) = âˆ’2
Page 42 of 246

Exercise 1.8.43
Let
A =
ï£®
ï£°
âˆ’1
ï£¹
ï£»,
B =
ï£®
ï£°
âˆ’2
âˆ’4
ï£¹
ï£».
Verify directly that A(AB) = A2B.
Exercise 1.8.44
Find the determinant of the matrix A =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£ºï£ºï£»
We apply the row operations to A to have
ï£®
ï£¯ï£¯ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£ºï£ºï£»
â‡’
det A = 1
Exercise 1.8.45
Find x, assuming
det
ï£®
ï£°
x2
x
âˆ’5
ï£¹
ï£»= 0
Calculate the determinant according to the third row: x = 0 or x = 2
Exercise 1.8.46 Let A and B be 4 Ã— 4 matrices with det(A) = âˆ’1 and det(B) = 2. Find the
determinant det(Bâˆ’1AB).
We have
det(Bâˆ’1AB)
=
det(Bâˆ’1) det(A) det(B)
=
det(B) det(A) det(B)
=
=
âˆ’1
Exercise 1.8.47
State whether the following are true or false. If true, explain why, if false,
give a numerical example to illustrate.
1.) If A and B are 2 by 2 matrices, then det(A + B) is always equal to det A + det B.
False: A =
 1

,
B =
 0

â‡’0 + 0 Ì¸= 1
2.) If a 13 Ã— 13 matrix A satisfies then A2 = 0, then A is not invertible.
True. Assume A invertible, A = Aâˆ’1A2 = 0 â‡’det A = 0 â‡’, A invertible
Page 43 of 246

Exercise 1.8.48
If C =
 0

and D is a 3 Ã— m matrix then the second row of the
matrix CD is
A. not defined unless m = 2.
B. the same as the first row of D.
C. the same as the second row of D.
D. the sum of the first and the third row of D.
E. the sum of twice the second row of D and the third row of D.
F. twice the first row of D.
D
Exercise 1.8.49 Which of the following statements are false?
1.) For all invertible n Ã— n matrices A and B, det(Aâˆ’1BA) = det B
2.) For all invertible n Ã— n matrices A and B, det(Aâˆ’1Bâˆ’1AB) = 1
3.) For all n Ã— n matrices A and B,
 ATBTT = AB
4.) For all invertible n Ã— n matrices A and B, (ABAâˆ’1)âˆ’1 = Aâˆ’1Bâˆ’1A
5.) For all n Ã— n matrices A and B, det(ATB) = det(BTA)
A. (1) and (3)
B. (2) and (3)
C. (3) and (4)
D. (2) and (4)
E. (2) and (5)
F. (1) and (5)
(1), True:
(2), True:
(3), False :
 ATBTT = BA.
(4), False : (ABAâˆ’1)âˆ’1 = ABâˆ’1Aâˆ’1.
(5), True :
Its possible that AB Ì¸= BA and Aâˆ’1Bâˆ’1A Ì¸= ABâˆ’1Aâˆ’1
C
Exercise 1.8.50
Let A and B denote matrices, not necessarily square, and which have more
than 1 row and more than 1 column, and let x denote a column vector (i.e., a k Ã— 1 matrix for
some k).
State whether each of the following is (always) true, or is (possibly) false
â€¢ If you say the statement may be false, you must give an explicit example - with numbers!
(Hint: Try an example with 2 or 3 rows or columns.)
â€¢ If you say the statement is true, you must give a clear explanation - by quoting a theorem
presented in class, any by giving other valid proof.
Page 44 of 246

1.) If A is m Ã— n and rankA = m, then the system Ax = 0 has a unique solution.
False: A =
 1

2.) If AB = 0 then either A = 0 or B = 0.
False: A = B =
 0

3.) If B has a column of zeros then AB has a column of zeros.
True
Write B with column entries where the jth column is zeros.
B = [c1 c2
Â· Â· Â·
0 cj+1
Â· Â· Â·
cn]
Then
AB = [Ac1 Ac2
Â· Â· Â·
A Â· 0 Acj+1
Â· Â· Â·
Acn] = [Ac1 Ac2
Â· Â· Â·
0 Acj+1
Â· Â· Â·
Acn]
That is, if the jth column of B is zero, then the jth column of AB is zero as well.
Exercise 1.8.51
If two n Ã— n matrices A and B satisfy AT = Bâˆ’1 and BT = âˆ’Bâˆ’1 then
(ABA)T is always
A. âˆ’B3
B. B2A
C. âˆ’Bâˆ’3
D. Bâˆ’3
E. B3
F. AB2
C
Exercise 1.8.52
Determine the value(s) of Î» for which the matrix
A =
ï£®
ï£°
Î»
âˆ’1
âˆ’1
Î»
âˆ’1
âˆ’1
Î»
ï£¹
ï£»
is invertible.
Invertible if |A| Ì¸= 0, since already a square matrix. Î» Ì¸= 0 and Î» Ì¸=
âˆš
2 and Î» Ì¸= âˆ’
âˆš
Page 45 of 246

Exercise 1.8.53
Assume that B is a 3 Ã— 3 matrix with the property that B2 = B. Which of
the following statements about the matrix B must be true:
A. AB is invertible
B. det(B) = 0
C. det(B5) = det(B)
D. None of the above must be true
C
Two examples of matrices that satisfy B2 = B are B = I3 and B = 03Ã—3 where 03Ã—3 is the 3Ã—3
matrix with all zero entries. So (A) is false because the 0 matrix satisfies the property but is
not invertible. Similarly (B) is false because the identity matrix satisfies the property but the
determinant of the identity is 1 not 0. (C) is true because
B5 = (BB)(BB)B = (B)(B)B = (BB)B = (B)B = BB = B
so B5 = B and hence in particular det(B5) = det(B).
Exercise 1.8.54
True or False? If A and B are both invertible n Ã— n matrices, then AB is
invertible.
True: One way to see this is to note that if A and B are invertible then each of their determinants
are nonzero. But then
det(AB) = det(A)det(B)
is also nonzero since its a product of two non zero numbers. Hence since det(AB) is nonzero,
it follows that AB is invertible.
Exercise 1.8.55
True or False? Let A and B be n Ã— n matrices. Assume that
AB = In.
Then,
BA = In
True: Since AB = In it follows from the invertible matrix theorem (the theorem that gives
all the many equivalences for a matrix being invertible) that A and similarly B are invertible.
Moreover, the equation AB = In says that B = Aâˆ’1 Hence in this case BA = (Aâˆ’1)A = In.
Exercise 1.8.56
Compute the inverse of the matrix A =
ï£®
ï£°
ï£¹
ï£»
Exercise 1.8.57
If E is a 3 Ã— 3 matrix of the form
E =
ï£®
ï£°
x
y
z
âˆ’3
ï£¹
ï£».
Given det(E) = 5, compute the determinant of the following matrix
F =
ï£®
ï£°
x
y
z
âˆ’3 + 4x
7 + 4y
2 + 4z
ï£¹
ï£».
Page 46 of 246

Exercise 1.8.58
Let the matrices
X =
 1

,
Y =
 âˆ’3

1.) Compute Xâˆ’1
Xâˆ’1 =

âˆ’1
âˆ’1

.
2.) Compute XY Xâˆ’1
XY Xâˆ’1 =
 1
  âˆ’3
 
âˆ’1
âˆ’1

=
 âˆ’2
âˆ’1
 
âˆ’1
âˆ’1

=
 âˆ’11
âˆ’11

3.) Compute det(XY Xâˆ’1)
det
 âˆ’11
âˆ’11

= (âˆ’11)(10) âˆ’(9)(âˆ’11) = âˆ’110 + 99 = âˆ’11
4.) What is the relationship between det(Y ), and det(XY Xâˆ’1) and why?
det(Y ) = det
 âˆ’3

= (âˆ’3)(2) âˆ’(5)(1) = âˆ’6 âˆ’5 = âˆ’11
So det(XY Xâˆ’1) = det(Y ). This is not a coincidence. In fact,
det(XY Xâˆ’1) = det(X) det(Y ) det(Xâˆ’1) = det(X) det(Xâˆ’1) det(Y )
= det(XXâˆ’1) det(Y ) = det(I2) det(Y ) = 1 âˆ—det(Y ) = det(Y )
Exercise 1.8.59
What is the reduced row echelon form of the matrix
ï£®
ï£°
âˆ’1
âˆ’1
ï£¹
ï£»?
A.
ï£®
ï£°
âˆ’1
âˆ’1
ï£¹
ï£»
B.
ï£®
ï£°
âˆ’1
âˆ’1
ï£¹
ï£»
C.
ï£®
ï£°
âˆ’1
ï£¹
ï£»
D.
ï£®
ï£°
âˆ’1
âˆ’1
ï£¹
ï£»
E. none of the preceding.
Page 47 of 246

Exercise 1.8.60
What is the determinant of the matrix
ï£®
ï£¯ï£¯ï£°
ï£¹
ï£ºï£ºï£»
A. âˆ’120
B. âˆ’24
C. 0
D. 24
E. 120
Exercise 1.8.61
What is the first row of the inverse of the matrix
ï£®
ï£°
ï£¹
ï£»
A. [0
âˆ’2
1]
B. [0
âˆ’3
âˆ’6]
C. [0
âˆ’3]
D. [2
0]
E. The inverse does not exist.
Exercise 1.8.62
If

a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p

= 3, find

b
f âˆ’2n
n
5j âˆ’b
a
e âˆ’2m
m
5i âˆ’a
c
g âˆ’2o
o
5k âˆ’c
d
h âˆ’2p
p
5l âˆ’d

Exercise 1.8.63
Find the row echelon form of the following matrices.
A =
ï£®
ï£°
âˆ’4
âˆ’6
âˆ’9
âˆ’8
ï£¹
ï£»,
B =
ï£®
ï£°
âˆ’4
âˆ’3
âˆ’2
ï£¹
ï£»,
C =
ï£®
ï£°
ï£¹
ï£»
The row echelon form
A =
ï£®
ï£°
âˆ’4
âˆ’6
âˆ’9
âˆ’8
ï£¹
ï£»âˆ¼
ï£®
ï£°
âˆ’4
ï£¹
ï£»
B =
ï£®
ï£°
âˆ’4
âˆ’3
âˆ’2
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»
C =
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
âˆ’4
âˆ’8
âˆ’12
âˆ’5
âˆ’10
âˆ’17
ï£¹
ï£»âˆ¼
ï£®
ï£°
17/5
ï£¹
ï£»âˆ¼
ï£®
ï£°
2/5
ï£¹
ï£»
Exercise 1.8.64
Find the reduced row echelon form of the following matrix
ï£®
ï£°
ï£¹
ï£»
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»
âˆ¼
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
ï£¹
ï£»âˆ¼
ï£®
ï£°
âˆ’1
ï£¹
ï£»
Page 48 of 246